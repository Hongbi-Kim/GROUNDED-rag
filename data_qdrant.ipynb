{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_documents_from_jsonl(file_path):\n",
    "    \"\"\"\n",
    "    JSONL íŒŒì¼ì—ì„œ Document ê°ì²´ ë¦¬ìŠ¤íŠ¸ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "                \n",
    "            data = json.loads(line)\n",
    "            doc = Document(\n",
    "                page_content=data[\"page_content\"],\n",
    "                metadata=data[\"metadata\"],\n",
    "                id=data[\"id\"]\n",
    "            )\n",
    "            documents.append(doc)\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, SparseVectorParams, SparseIndexParams\n",
    "from qdrant_client.models import PointStruct\n",
    "from tqdm import tqdm\n",
    "\n",
    "QDRANT_URL = os.getenv('QDRANT_URL', '')\n",
    "QDRANT_api_key = os.getenv('QDRANT_api_key', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collections=[CollectionDescription(name='legal_docs_hybrid')]\n"
     ]
    }
   ],
   "source": [
    "qdrant_client = QdrantClient(\n",
    "    url=QDRANT_URL, \n",
    "    api_key=QDRANT_api_key,\n",
    ")\n",
    "\n",
    "print(qdrant_client.get_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import ClovaXEmbeddings\n",
    "\n",
    "clova_embedder = ClovaXEmbeddings(\n",
    "                model=\"bge-m3\",\n",
    "                api_key=os.getenv(\"CLOVASTUDIO_API_KEY\")\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_documents_from_jsonl(\"documents_merged.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ ë° ì œë¹™ ì±…ì„ì— ê´€í•œ ì¡°ë¡€]\n",
      "ì œ1ì¡°(ëª©ì ) ì´ ì¡°ë¡€ëŠ” ã€Œìì—°ì¬í•´ëŒ€ì±…ë²•ã€ ì œ27ì¡°ì œ2í•­ì˜ ê·œì •ì— ë”°ë¼ ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤Â·ì œë¹™ì— ê´€í•œ ì‚¬í•­ì„ êµ¬ì²´ì ìœ¼ë¡œ ì •í•¨ìœ¼ë¡œì¨ ëˆˆ ë˜ëŠ” ì–¼ìŒìœ¼ë¡œ ì¸í•œ ì£¼ë¯¼ì˜ ë¶ˆí¸ì„ ìµœì†Œí™”í•˜ê³ , ì•ˆì „ì„ ê¾€í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.\n",
      "ì œ2ì¡°(ì •ì˜) ì´ ì¡°ë¡€ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ì˜ ëœ»ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. <ê°œì • 2017.7.31.>1. â€œë„ë¡œâ€ë¼ í•¨ì€ ã€Œë„ë¡œë²•ã€ì— ë”°ë¥¸ ë„ë¡œ, ê·¸ ë°–ì— ì¼ë°˜ êµí†µì— ì‚¬ìš©ë˜ëŠ” ëª¨ë“  ê³³ì„ ë§í•œë‹¤.2. â€œì°¨ë„â€ë¼ í•¨ì€ ì—°ì„ì„ (ì°¨ë„ì™€ ë³´ë„ë¥¼ êµ¬ë¶„í•˜ëŠ” ëŒ ë“±ìœ¼ë¡œ ì´ì–´ì§„ ì„ ì„ ë§í•œë‹¤), ì•ˆì „í‘œì§€, ê·¸ ë°–ì— ì´ì™€ ë¹„ìŠ·í•œ ê³µì‘ë¬¼ë¡œì¨ ê·¸ ê²½ê³„ë¥¼ í‘œì‹œí•˜ì—¬ ëª¨ë“  ì°¨ì˜ êµí†µì— ì‚¬ìš©í•˜ë„ë¡ ëœ ë„ë¡œì˜ ë¶€ë¶„ì„ ë§í•œë‹¤.3. â€œë³´ë„(æ­¥é“)â€ë¼ í•¨ì€ ì—°ì„ì„ , ì•ˆì „í‘œì§€, ê·¸ ë°–ì— ì´ì™€ ë¹„ìŠ·í•œ ê³µì‘ë¬¼ë¡œì¨ ê·¸ ê²½ê³„ë¥¼ í‘œì‹œí•˜ì—¬ ë³´í–‰ì(ìœ ëª¨ì°¨ ë° ì‹ ì²´ì¥ì• ì¸ìš© ì˜ìì°¨ë¥¼ í¬í•¨í•œë‹¤)ì˜ í†µí–‰ì— ì‚¬ìš©í•˜ë„ë¡ ë˜ì–´ìˆëŠ” ë„ë¡œì˜ ë¶€ë¶„ì„ ë§í•œë‹¤. <ê°œì • 2017.3.6.>4. â€œì´ë©´ë„ë¡œâ€ë¼ í•¨ì€ ã€Œë„ë¡œë²•ã€ì— ë”°ë¥¸ ê³ ì†êµ­ë„ã†ì¼ë°˜êµ­ë„ã†ì§€ë°©ë„ã†êµ°ë„ ë° ë†ì–´ì´Œë„ë¡œ(ã€Œë†ì–´ì´Œë„ë¡œì •ë¹„ë²•ã€ì— ë”°ë¥¸ ë„ë¡œë¥¼ ë§í•œë‹¤)ê°€ ì•„ë‹Œ ì¼ë°˜ì˜ êµí†µì— ì‚¬ìš©ë˜ëŠ” ë„ë¡œë¡œì„œ ì°¨ë„ì™€ ë³´ë„ì˜ êµ¬ë¶„ì´ ì—†ëŠ” í­ 12ë¯¸í„° ë¯¸ë§Œì˜ ë„ë¡œë¥¼ ë§í•œë‹¤.5. â€œë³´í–‰ìì „ìš©ë„ë¡œâ€ë¼ í•¨ì€ ë³´í–‰ìë§Œì´ ë‹¤ë‹ ìˆ˜ ìˆë„ë¡ ì•ˆì „í‘œì§€ ë° ê·¸ ë°–ì— ì´ì™€ ë¹„ìŠ·í•œ ê³µì‘ë¬¼ë¡œì¨ í‘œì‹œí•œ ë„ë¡œë¥¼ ë§í•œë‹¤.6. â€œì œì„¤ã†ì œë¹™ì‘ì—…â€ì´ë¼ í•¨ì€ ë„ë¡œìƒì˜ ëˆˆ ë˜ëŠ” ì–¼ìŒì„ ì œê±°í•˜ê±°ë‚˜ ë…¹ê²Œ í•˜ëŠ” ì¬ë£Œ ë° ëª¨ë˜ ë“±ì„ ë¿Œë ¤ì„œ ë³´í–‰ìì™€ ì°¨ëŸ‰ì˜ ì•ˆì „í•œ í†µí–‰ì— ì§€ì¥ì´ ì—†ë„ë¡ í•˜ëŠ” ê²ƒì„ ë§í•œë‹¤.7. â€œê±´ì¶•ë¬¼ê´€ë¦¬ìâ€ë¼ í•¨ì€ ê±´ì¶•ë¬¼ì˜ ì†Œìœ ìã†ì ìœ ì ë˜ëŠ” ê´€ë¦¬ìë¡œì„œ ê·¸ ê±´ì¶•ë¬¼ì˜ ê´€ë¦¬ ì±…ì„ì´ ìˆëŠ” ì‚¬ëŒì„ ë§í•œë‹¤.8. â€œì‹œì„¤ë¬¼ì˜ ì§€ë¶•â€ì´ë¼ í•¨ì€ ã€Œìì—°ì¬í•´ëŒ€ì±…ë²• ì‹œí–‰ë ¹ã€ì œ22ì¡°ì˜8ì— ë”°ë¥¸ ì‹œì„¤ë¬¼ì˜ ì§€ë¶•ì„ ë§í•œë‹¤. <ì‹ ì„¤ 2017.7.31.>\n"
     ]
    }
   ],
   "source": [
    "text = documents[0].page_content\n",
    "print(text)\n",
    "ebbed_text = clova_embedder.embed_query(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.48266602,\n",
       " -0.08874512,\n",
       " -0.23059082,\n",
       " 0.23742676,\n",
       " 0.33496094,\n",
       " -1.7724609,\n",
       " 0.11755371,\n",
       " 0.83740234,\n",
       " -1.6318359,\n",
       " 0.035858154,\n",
       " 0.09539795,\n",
       " -0.43432617,\n",
       " -0.50341797,\n",
       " -0.20532227,\n",
       " -0.42163086,\n",
       " -0.0034179688,\n",
       " -0.40625,\n",
       " 0.2175293,\n",
       " -0.3618164,\n",
       " -0.89453125,\n",
       " -0.4440918,\n",
       " -1.3837891,\n",
       " -0.7114258,\n",
       " 0.13098145,\n",
       " 0.6430664,\n",
       " 0.16040039,\n",
       " 0.9038086,\n",
       " 0.089416504,\n",
       " 0.7705078,\n",
       " 1.5273438,\n",
       " -0.14624023,\n",
       " 0.3251953,\n",
       " -0.6064453,\n",
       " -1.0839844,\n",
       " 0.5263672,\n",
       " -0.87402344,\n",
       " -0.23083496,\n",
       " -0.4819336,\n",
       " -0.9213867,\n",
       " 1.0292969,\n",
       " 0.06188965,\n",
       " -0.33081055,\n",
       " 0.48339844,\n",
       " -0.47802734,\n",
       " 1.1240234,\n",
       " -0.35009766,\n",
       " -1.4990234,\n",
       " -1.1054688,\n",
       " -0.57714844,\n",
       " -1.2695312,\n",
       " -1.2890625,\n",
       " -0.04119873,\n",
       " 1.9384766,\n",
       " -2.2226562,\n",
       " 0.2619629,\n",
       " 1.2373047,\n",
       " -0.61035156,\n",
       " -1.2832031,\n",
       " -2.7460938,\n",
       " 0.05529785,\n",
       " -1.0068359,\n",
       " 0.9091797,\n",
       " -0.5756836,\n",
       " -0.9916992,\n",
       " -0.45996094,\n",
       " 0.42944336,\n",
       " -0.45751953,\n",
       " -0.92529297,\n",
       " 0.08898926,\n",
       " -1.0341797,\n",
       " 0.5732422,\n",
       " 1.1425781,\n",
       " 0.5175781,\n",
       " -0.37426758,\n",
       " 0.0071144104,\n",
       " 0.39453125,\n",
       " 0.51171875,\n",
       " 0.0725708,\n",
       " -0.90283203,\n",
       " 0.48339844,\n",
       " 0.4560547,\n",
       " 0.17797852,\n",
       " -0.16601562,\n",
       " 0.88623047,\n",
       " -0.11401367,\n",
       " 0.8769531,\n",
       " -1.9648438,\n",
       " 0.35375977,\n",
       " 0.27172852,\n",
       " 0.05618286,\n",
       " -0.09698486,\n",
       " 0.5449219,\n",
       " 0.48608398,\n",
       " 0.38720703,\n",
       " -0.81103516,\n",
       " -0.63183594,\n",
       " -0.61816406,\n",
       " -0.11773682,\n",
       " -0.2619629,\n",
       " -0.5961914,\n",
       " 0.6171875,\n",
       " -0.6376953,\n",
       " 0.68847656,\n",
       " -1.2412109,\n",
       " 0.3046875,\n",
       " -0.5625,\n",
       " 0.2626953,\n",
       " 0.55615234,\n",
       " 0.5629883,\n",
       " -1.3808594,\n",
       " -0.26879883,\n",
       " 0.06829834,\n",
       " 0.007537842,\n",
       " 0.46264648,\n",
       " 0.33544922,\n",
       " -0.6923828,\n",
       " 0.1986084,\n",
       " -1.2949219,\n",
       " 0.10296631,\n",
       " 0.10644531,\n",
       " 1.6806641,\n",
       " 1.7373047,\n",
       " 0.7558594,\n",
       " -1.8242188,\n",
       " 0.34643555,\n",
       " -0.5449219,\n",
       " 0.27124023,\n",
       " 0.2397461,\n",
       " 0.20654297,\n",
       " 0.8828125,\n",
       " 0.4440918,\n",
       " 0.048828125,\n",
       " -1.0224609,\n",
       " -1.0029297,\n",
       " -0.7138672,\n",
       " 0.43603516,\n",
       " 0.09362793,\n",
       " 0.7128906,\n",
       " 0.5136719,\n",
       " -1.5771484,\n",
       " 0.025344849,\n",
       " 1.3369141,\n",
       " -0.10284424,\n",
       " -0.66748047,\n",
       " 1.1640625,\n",
       " -0.8125,\n",
       " 1.2783203,\n",
       " -0.3347168,\n",
       " -0.34838867,\n",
       " -0.038269043,\n",
       " 0.19567871,\n",
       " 0.5283203,\n",
       " 0.90283203,\n",
       " 0.77441406,\n",
       " -0.0027160645,\n",
       " -1.7333984,\n",
       " -1.0390625,\n",
       " 0.024169922,\n",
       " 0.24511719,\n",
       " -0.21276855,\n",
       " 0.875,\n",
       " 1.015625,\n",
       " -1.5341797,\n",
       " 0.3125,\n",
       " 1.0566406,\n",
       " 1.0166016,\n",
       " 0.3408203,\n",
       " 1.7666016,\n",
       " 0.43481445,\n",
       " 0.15734863,\n",
       " 0.36645508,\n",
       " -0.52197266,\n",
       " 0.57666016,\n",
       " 0.5654297,\n",
       " 0.49291992,\n",
       " 0.40454102,\n",
       " 0.5908203,\n",
       " 0.32177734,\n",
       " -0.14477539,\n",
       " -0.6435547,\n",
       " 0.033477783,\n",
       " 0.34887695,\n",
       " 0.37890625,\n",
       " 0.4716797,\n",
       " 0.12939453,\n",
       " 1.9833984,\n",
       " 0.8183594,\n",
       " -0.32250977,\n",
       " 0.7783203,\n",
       " 0.4284668,\n",
       " -0.046722412,\n",
       " -0.63378906,\n",
       " -0.5908203,\n",
       " 1.2197266,\n",
       " 0.19396973,\n",
       " -0.27026367,\n",
       " 0.55810547,\n",
       " 0.5786133,\n",
       " 0.49560547,\n",
       " -0.59375,\n",
       " 0.58447266,\n",
       " -0.5678711,\n",
       " 1.0664062,\n",
       " -1.5449219,\n",
       " -1.3574219,\n",
       " -0.7739258,\n",
       " -1.3105469,\n",
       " -0.37158203,\n",
       " 0.7558594,\n",
       " -2.5292969,\n",
       " 0.08404541,\n",
       " -0.03515625,\n",
       " 0.7192383,\n",
       " 0.45507812,\n",
       " -1.6269531,\n",
       " 0.26464844,\n",
       " -0.6875,\n",
       " -1.5029297,\n",
       " 0.9790039,\n",
       " 1.5126953,\n",
       " 0.10290527,\n",
       " -0.03289795,\n",
       " -0.3005371,\n",
       " 0.67578125,\n",
       " 1.1132812,\n",
       " -0.20019531,\n",
       " -0.5722656,\n",
       " 0.04043579,\n",
       " 0.71191406,\n",
       " 0.09832764,\n",
       " -0.58154297,\n",
       " 0.7265625,\n",
       " 0.96240234,\n",
       " -0.9975586,\n",
       " 1.3964844,\n",
       " -0.17370605,\n",
       " 0.68652344,\n",
       " 0.05783081,\n",
       " 0.9536133,\n",
       " 0.85058594,\n",
       " 0.023284912,\n",
       " -1.7890625,\n",
       " -0.48291016,\n",
       " -1.4599609,\n",
       " -0.4675293,\n",
       " 0.52197266,\n",
       " -0.3737793,\n",
       " -0.14831543,\n",
       " -0.9614258,\n",
       " -1.1328125,\n",
       " 0.5708008,\n",
       " -0.24499512,\n",
       " -0.51660156,\n",
       " -0.2548828,\n",
       " 0.076416016,\n",
       " -0.24230957,\n",
       " 0.6669922,\n",
       " -0.14343262,\n",
       " 0.41967773,\n",
       " -0.49804688,\n",
       " 1.0615234,\n",
       " -0.11541748,\n",
       " 0.36499023,\n",
       " 0.7055664,\n",
       " 0.3564453,\n",
       " -0.062042236,\n",
       " -2.1386719,\n",
       " 0.9941406,\n",
       " -0.59472656,\n",
       " 0.5078125,\n",
       " 0.140625,\n",
       " 0.9453125,\n",
       " 0.8154297,\n",
       " -0.7265625,\n",
       " 0.11639404,\n",
       " 0.27685547,\n",
       " 0.24353027,\n",
       " 0.5205078,\n",
       " 2.3242188,\n",
       " 1.0527344,\n",
       " 0.27172852,\n",
       " -0.59033203,\n",
       " 1.3886719,\n",
       " -0.2763672,\n",
       " 0.5966797,\n",
       " -0.15100098,\n",
       " -1.265625,\n",
       " -0.12548828,\n",
       " 1.3486328,\n",
       " -0.9501953,\n",
       " -0.30517578,\n",
       " -0.71728516,\n",
       " 1.2431641,\n",
       " -0.26831055,\n",
       " -0.82421875,\n",
       " 0.04849243,\n",
       " -0.6123047,\n",
       " -4.0507812,\n",
       " 0.640625,\n",
       " 0.96875,\n",
       " 0.24145508,\n",
       " -0.14562988,\n",
       " 0.27001953,\n",
       " -0.5805664,\n",
       " 0.23828125,\n",
       " -0.54296875,\n",
       " 0.28637695,\n",
       " 0.11010742,\n",
       " -0.9248047,\n",
       " -0.17297363,\n",
       " 0.5390625,\n",
       " 0.9584961,\n",
       " -0.04260254,\n",
       " 0.23522949,\n",
       " -0.16015625,\n",
       " -0.080200195,\n",
       " -0.19274902,\n",
       " -0.63964844,\n",
       " -0.15161133,\n",
       " 0.3803711,\n",
       " 0.017456055,\n",
       " -1.2734375,\n",
       " -1.5566406,\n",
       " 0.7128906,\n",
       " 0.734375,\n",
       " -1.0332031,\n",
       " 0.0770874,\n",
       " -0.8769531,\n",
       " 0.24536133,\n",
       " -0.671875,\n",
       " 0.20349121,\n",
       " 0.5024414,\n",
       " -0.25610352,\n",
       " 0.78271484,\n",
       " -2.3339844,\n",
       " 0.012207031,\n",
       " 0.52001953,\n",
       " 0.66015625,\n",
       " 1.1542969,\n",
       " -1.09375,\n",
       " 0.28100586,\n",
       " -0.54296875,\n",
       " -0.9614258,\n",
       " 1.2919922,\n",
       " 0.1217041,\n",
       " 0.4543457,\n",
       " 1.9960938,\n",
       " -0.6948242,\n",
       " -0.6176758,\n",
       " 0.3959961,\n",
       " -0.6386719,\n",
       " -0.31323242,\n",
       " 0.7480469,\n",
       " 0.6972656,\n",
       " 2.1464844,\n",
       " -0.6455078,\n",
       " 0.5385742,\n",
       " -0.8671875,\n",
       " -0.49804688,\n",
       " 0.63183594,\n",
       " 0.3010254,\n",
       " -1.1386719,\n",
       " -0.4428711,\n",
       " 1.1630859,\n",
       " 0.2553711,\n",
       " 0.30273438,\n",
       " -1.1308594,\n",
       " 0.04827881,\n",
       " -0.5185547,\n",
       " -0.609375,\n",
       " -0.92822266,\n",
       " -0.07910156,\n",
       " -0.07324219,\n",
       " 0.34692383,\n",
       " -0.5307617,\n",
       " 0.45214844,\n",
       " -2.4726562,\n",
       " 1.4921875,\n",
       " 0.38134766,\n",
       " 0.04510498,\n",
       " -0.26464844,\n",
       " -0.89746094,\n",
       " -1.4619141,\n",
       " 0.28955078,\n",
       " 0.6933594,\n",
       " 0.16992188,\n",
       " 5.734375,\n",
       " 0.05496216,\n",
       " 0.10443115,\n",
       " -0.013023376,\n",
       " 1.2480469,\n",
       " -0.9921875,\n",
       " 1.78125,\n",
       " 0.83251953,\n",
       " 0.0037326813,\n",
       " -0.45898438,\n",
       " -0.55615234,\n",
       " 1.0332031,\n",
       " 0.2130127,\n",
       " -0.4477539,\n",
       " 0.1352539,\n",
       " 0.11871338,\n",
       " -0.5058594,\n",
       " 0.515625,\n",
       " 0.36816406,\n",
       " -0.15856934,\n",
       " 0.32861328,\n",
       " 1.3466797,\n",
       " 0.45776367,\n",
       " -0.122924805,\n",
       " -0.5864258,\n",
       " -1.1347656,\n",
       " 0.5185547,\n",
       " -1.1357422,\n",
       " -0.9248047,\n",
       " -0.09185791,\n",
       " -0.2199707,\n",
       " -0.24304199,\n",
       " 1.1708984,\n",
       " -1.6962891,\n",
       " -0.76904297,\n",
       " -0.091796875,\n",
       " -0.7675781,\n",
       " -0.35229492,\n",
       " 0.59375,\n",
       " 0.60058594,\n",
       " 1.6699219,\n",
       " -0.22851562,\n",
       " 0.2401123,\n",
       " -0.91845703,\n",
       " -0.3581543,\n",
       " -1.4482422,\n",
       " -0.08459473,\n",
       " -0.68652344,\n",
       " 0.14160156,\n",
       " -0.54248047,\n",
       " -0.15100098,\n",
       " 0.4321289,\n",
       " -0.95751953,\n",
       " 0.640625,\n",
       " -1.8037109,\n",
       " -0.04232788,\n",
       " -0.36328125,\n",
       " -1.2226562,\n",
       " 0.7783203,\n",
       " 0.12445068,\n",
       " 2.2050781,\n",
       " -0.115356445,\n",
       " -1.2119141,\n",
       " -0.7871094,\n",
       " -0.19726562,\n",
       " 0.21875,\n",
       " 0.022338867,\n",
       " -1.3349609,\n",
       " 0.74121094,\n",
       " 0.043701172,\n",
       " -0.80615234,\n",
       " 0.23791504,\n",
       " -0.043121338,\n",
       " 0.62890625,\n",
       " 0.1907959,\n",
       " -0.3330078,\n",
       " 0.9067383,\n",
       " 0.4885254,\n",
       " 0.48828125,\n",
       " -0.56152344,\n",
       " -0.6777344,\n",
       " -0.53222656,\n",
       " -1.09375,\n",
       " 0.17004395,\n",
       " 0.6196289,\n",
       " 0.21057129,\n",
       " 1.0029297,\n",
       " 0.47558594,\n",
       " 0.44213867,\n",
       " 0.3173828,\n",
       " 0.29248047,\n",
       " 0.35546875,\n",
       " 0.5415039,\n",
       " 1.2802734,\n",
       " -0.06185913,\n",
       " 0.59033203,\n",
       " -0.6645508,\n",
       " -0.04660034,\n",
       " -0.42382812,\n",
       " -0.5078125,\n",
       " -0.5834961,\n",
       " 0.36523438,\n",
       " -0.9663086,\n",
       " -0.44921875,\n",
       " 0.98046875,\n",
       " -0.63964844,\n",
       " -0.09320068,\n",
       " 0.3671875,\n",
       " -1.8427734,\n",
       " 0.34765625,\n",
       " 0.39770508,\n",
       " 0.7416992,\n",
       " -0.4177246,\n",
       " 0.58935547,\n",
       " 0.89941406,\n",
       " 0.4182129,\n",
       " -0.26660156,\n",
       " 0.7607422,\n",
       " 1.2177734,\n",
       " 0.38745117,\n",
       " -0.012779236,\n",
       " 1.6875,\n",
       " 0.30664062,\n",
       " 0.6069336,\n",
       " -0.41674805,\n",
       " -0.64453125,\n",
       " -0.005279541,\n",
       " 0.095214844,\n",
       " 0.37451172,\n",
       " 1.453125,\n",
       " -0.19360352,\n",
       " -0.7998047,\n",
       " -1.7382812,\n",
       " -0.5102539,\n",
       " -0.09350586,\n",
       " 0.6245117,\n",
       " 0.36572266,\n",
       " 1.1083984,\n",
       " -0.90527344,\n",
       " 0.13793945,\n",
       " -1.2382812,\n",
       " -0.5888672,\n",
       " -0.94189453,\n",
       " 0.17053223,\n",
       " -0.11035156,\n",
       " 0.9814453,\n",
       " 0.95947266,\n",
       " -1.8017578,\n",
       " -0.5883789,\n",
       " -0.9301758,\n",
       " 0.20800781,\n",
       " 0.33984375,\n",
       " 0.47998047,\n",
       " -1.1425781,\n",
       " 0.62158203,\n",
       " -1.1269531,\n",
       " -0.52734375,\n",
       " 0.57958984,\n",
       " 1.2080078,\n",
       " -0.14038086,\n",
       " -0.96240234,\n",
       " -0.59228516,\n",
       " -0.93652344,\n",
       " 0.09069824,\n",
       " -0.061401367,\n",
       " -0.28173828,\n",
       " 0.72998047,\n",
       " 1.0205078,\n",
       " 0.37304688,\n",
       " -0.81152344,\n",
       " 0.38891602,\n",
       " -0.4243164,\n",
       " -1.3417969,\n",
       " 0.2475586,\n",
       " 0.9296875,\n",
       " 0.57128906,\n",
       " -1.7822266,\n",
       " 0.21655273,\n",
       " 0.040283203,\n",
       " -0.7558594,\n",
       " -0.086364746,\n",
       " 0.6743164,\n",
       " 0.26733398,\n",
       " -0.14916992,\n",
       " 0.48388672,\n",
       " -0.008659363,\n",
       " 1.0322266,\n",
       " -0.60498047,\n",
       " 1.1220703,\n",
       " -0.12213135,\n",
       " 0.15893555,\n",
       " 1.8496094,\n",
       " 0.5708008,\n",
       " -0.5522461,\n",
       " 0.92822266,\n",
       " 0.53027344,\n",
       " 0.12536621,\n",
       " 0.37548828,\n",
       " 0.027770996,\n",
       " 0.03543091,\n",
       " 0.27392578,\n",
       " 0.39697266,\n",
       " 0.42651367,\n",
       " -0.042419434,\n",
       " -0.36328125,\n",
       " -0.39135742,\n",
       " -0.5048828,\n",
       " 0.39892578,\n",
       " -0.01071167,\n",
       " 0.35107422,\n",
       " 0.4248047,\n",
       " 0.7055664,\n",
       " -0.5854492,\n",
       " -0.19177246,\n",
       " -0.5732422,\n",
       " -0.14953613,\n",
       " -0.79003906,\n",
       " 1.8300781,\n",
       " 0.0463562,\n",
       " -0.47045898,\n",
       " -1.1708984,\n",
       " 0.38452148,\n",
       " 1.515625,\n",
       " -1.0615234,\n",
       " 0.07757568,\n",
       " 1.0253906,\n",
       " 0.98046875,\n",
       " 0.5932617,\n",
       " 1.0195312,\n",
       " 0.6850586,\n",
       " 0.28686523,\n",
       " -0.55859375,\n",
       " 1.7421875,\n",
       " -0.43798828,\n",
       " -0.0004336834,\n",
       " -0.4399414,\n",
       " 1.0927734,\n",
       " 0.71728516,\n",
       " 0.86083984,\n",
       " -0.8076172,\n",
       " 0.71777344,\n",
       " -0.049682617,\n",
       " 0.9135742,\n",
       " 0.76708984,\n",
       " 0.084350586,\n",
       " -0.74121094,\n",
       " -1.2128906,\n",
       " -0.1472168,\n",
       " 0.62109375,\n",
       " 0.49682617,\n",
       " -1.2021484,\n",
       " -1.0488281,\n",
       " 0.61328125,\n",
       " 0.15637207,\n",
       " -0.61816406,\n",
       " 0.019454956,\n",
       " 0.5180664,\n",
       " 1.2636719,\n",
       " -0.45483398,\n",
       " -0.010688782,\n",
       " -0.5029297,\n",
       " -0.045196533,\n",
       " 0.23376465,\n",
       " -0.36889648,\n",
       " 0.46313477,\n",
       " -1.703125,\n",
       " 0.23657227,\n",
       " 0.035491943,\n",
       " -1.7597656,\n",
       " -0.22290039,\n",
       " -0.6489258,\n",
       " 0.046844482,\n",
       " -0.5703125,\n",
       " -1.4199219,\n",
       " -1.8183594,\n",
       " -1.0390625,\n",
       " -1.8730469,\n",
       " 1.2314453,\n",
       " 0.7861328,\n",
       " 0.44458008,\n",
       " 0.9902344,\n",
       " -0.14526367,\n",
       " 0.22875977,\n",
       " 1.0136719,\n",
       " 0.7167969,\n",
       " -0.003643036,\n",
       " -0.109313965,\n",
       " -0.50390625,\n",
       " 0.040039062,\n",
       " -1.2744141,\n",
       " 0.1875,\n",
       " 0.39770508,\n",
       " -0.1328125,\n",
       " -0.45996094,\n",
       " -0.3178711,\n",
       " 0.8149414,\n",
       " -0.3330078,\n",
       " 0.8979492,\n",
       " -0.35961914,\n",
       " 0.07019043,\n",
       " 0.4946289,\n",
       " -0.69091797,\n",
       " -0.5605469,\n",
       " -1.0966797,\n",
       " -0.014144897,\n",
       " 0.24780273,\n",
       " -0.5546875,\n",
       " -0.47045898,\n",
       " -0.15234375,\n",
       " 0.16906738,\n",
       " 0.61035156,\n",
       " -1.1083984,\n",
       " 0.12902832,\n",
       " 0.27490234,\n",
       " 0.9941406,\n",
       " -0.87597656,\n",
       " 0.28344727,\n",
       " 0.0011224747,\n",
       " 1.0029297,\n",
       " 0.57421875,\n",
       " 0.7841797,\n",
       " 0.875,\n",
       " -0.40551758,\n",
       " -0.31518555,\n",
       " -0.62646484,\n",
       " 0.5004883,\n",
       " -0.61816406,\n",
       " 0.2685547,\n",
       " -0.87597656,\n",
       " 0.5493164,\n",
       " -1.9042969,\n",
       " -0.55126953,\n",
       " -0.08331299,\n",
       " 0.2705078,\n",
       " 0.72998047,\n",
       " 0.09210205,\n",
       " 0.32666016,\n",
       " -0.7734375,\n",
       " 1.1445312,\n",
       " -1.0605469,\n",
       " 0.37817383,\n",
       " -0.8642578,\n",
       " 0.9814453,\n",
       " 0.34155273,\n",
       " 1.0195312,\n",
       " -0.86376953,\n",
       " -0.052734375,\n",
       " 0.31884766,\n",
       " -0.12512207,\n",
       " -0.31933594,\n",
       " 0.5761719,\n",
       " 0.62353516,\n",
       " 0.2915039,\n",
       " -0.51660156,\n",
       " 0.26831055,\n",
       " 1.1289062,\n",
       " -1.2636719,\n",
       " -1.3652344,\n",
       " -1.3154297,\n",
       " 0.26733398,\n",
       " -0.4802246,\n",
       " 1.5800781,\n",
       " -0.94970703,\n",
       " 0.5234375,\n",
       " -0.28198242,\n",
       " -0.26342773,\n",
       " 0.3227539,\n",
       " -2.6894531,\n",
       " 0.82910156,\n",
       " 0.17504883,\n",
       " -0.6513672,\n",
       " -0.6508789,\n",
       " 0.42871094,\n",
       " -0.2709961,\n",
       " 0.4609375,\n",
       " -0.068847656,\n",
       " -1.7382812,\n",
       " -0.89990234,\n",
       " -0.21887207,\n",
       " -0.008590698,\n",
       " -0.8964844,\n",
       " -1.6699219,\n",
       " -0.072753906,\n",
       " 0.1685791,\n",
       " -0.5800781,\n",
       " -0.20678711,\n",
       " -0.62939453,\n",
       " 0.35351562,\n",
       " 0.6489258,\n",
       " 0.60253906,\n",
       " -1.2519531,\n",
       " 1.0673828,\n",
       " -0.7661133,\n",
       " 0.34399414,\n",
       " -3.28125,\n",
       " 0.085998535,\n",
       " -0.31103516,\n",
       " -0.084106445,\n",
       " -0.67626953,\n",
       " 0.50927734,\n",
       " -0.7167969,\n",
       " 0.015151978,\n",
       " 0.060150146,\n",
       " -0.3269043,\n",
       " 0.35205078,\n",
       " -0.27807617,\n",
       " 0.67822266,\n",
       " 0.2211914,\n",
       " 0.60302734,\n",
       " 1.796875,\n",
       " -1.2255859,\n",
       " -0.9951172,\n",
       " -0.91308594,\n",
       " 0.9375,\n",
       " 0.05871582,\n",
       " 0.44848633,\n",
       " -0.26464844,\n",
       " 0.16711426,\n",
       " 0.93408203,\n",
       " -0.2932129,\n",
       " 1.0058594,\n",
       " -0.6088867,\n",
       " -0.5571289,\n",
       " -1.1689453,\n",
       " -1.0859375,\n",
       " -0.9213867,\n",
       " 0.16821289,\n",
       " 0.32055664,\n",
       " -0.4699707,\n",
       " 1.0664062,\n",
       " 1.0742188,\n",
       " -0.71972656,\n",
       " 0.6191406,\n",
       " -0.33666992,\n",
       " -0.2421875,\n",
       " -0.1862793,\n",
       " -0.71435547,\n",
       " 0.48754883,\n",
       " -0.31469727,\n",
       " 0.64697266,\n",
       " 0.0670166,\n",
       " -1.7421875,\n",
       " -0.8510742,\n",
       " 0.58251953,\n",
       " -0.7583008,\n",
       " -0.19848633,\n",
       " 0.21899414,\n",
       " 1.7158203,\n",
       " -0.37182617,\n",
       " 0.7324219,\n",
       " 0.29248047,\n",
       " -0.796875,\n",
       " 0.028686523,\n",
       " 0.003774643,\n",
       " -1.0410156,\n",
       " 0.43701172,\n",
       " -0.3017578,\n",
       " -0.53027344,\n",
       " -0.5292969,\n",
       " 0.7363281,\n",
       " -0.14953613,\n",
       " 0.33203125,\n",
       " 0.6459961,\n",
       " -1.0556641,\n",
       " -1.2724609,\n",
       " -0.39770508,\n",
       " -0.5439453,\n",
       " -0.20776367,\n",
       " 0.12988281,\n",
       " -0.12438965,\n",
       " 0.35620117,\n",
       " 0.765625,\n",
       " 0.80371094,\n",
       " 0.4230957,\n",
       " 0.1772461,\n",
       " -0.2939453,\n",
       " -0.6621094,\n",
       " -0.65966797,\n",
       " 1.0927734,\n",
       " 0.79248047,\n",
       " -0.28173828,\n",
       " -0.26757812,\n",
       " 0.6484375,\n",
       " -0.9614258,\n",
       " -0.47216797,\n",
       " -0.8256836,\n",
       " -1.4208984,\n",
       " 1.4707031,\n",
       " 0.14782715,\n",
       " 0.6455078,\n",
       " -0.028244019,\n",
       " -0.5419922,\n",
       " 0.12512207,\n",
       " -0.35424805,\n",
       " 0.093444824,\n",
       " -0.40625,\n",
       " 0.03878784,\n",
       " 0.41552734,\n",
       " -0.19116211,\n",
       " 1.0898438,\n",
       " -1.4804688,\n",
       " 0.31640625,\n",
       " 0.67333984,\n",
       " 0.38989258,\n",
       " -0.2709961,\n",
       " 0.41503906,\n",
       " -0.7060547,\n",
       " -0.71972656,\n",
       " -1.0117188,\n",
       " 0.16369629,\n",
       " -0.59765625,\n",
       " 0.24914551,\n",
       " -0.16259766,\n",
       " 0.73779297,\n",
       " 0.74853516,\n",
       " 0.4152832,\n",
       " 0.46606445,\n",
       " -0.8227539,\n",
       " -0.4597168,\n",
       " 0.65185547,\n",
       " 0.39648438,\n",
       " 0.4477539,\n",
       " 1.1708984,\n",
       " -0.4897461,\n",
       " 0.17907715,\n",
       " -1.2822266,\n",
       " -0.7890625,\n",
       " -0.5541992,\n",
       " -0.24584961,\n",
       " -1.1943359,\n",
       " -0.7158203,\n",
       " 1.1044922,\n",
       " -0.3894043,\n",
       " -0.7138672,\n",
       " -0.5214844,\n",
       " 0.6748047,\n",
       " 0.14160156,\n",
       " -1.34375,\n",
       " 1.1474609,\n",
       " -0.5439453,\n",
       " -0.27612305,\n",
       " -0.04660034,\n",
       " -0.06414795,\n",
       " -1.0097656,\n",
       " 0.03149414,\n",
       " -1.0693359,\n",
       " -0.50634766,\n",
       " 1.1914062,\n",
       " -0.546875,\n",
       " -0.04421997,\n",
       " 0.074035645,\n",
       " -0.12524414,\n",
       " -0.6508789,\n",
       " 0.76416016,\n",
       " 0.61279297,\n",
       " -0.52197266,\n",
       " -0.85595703,\n",
       " -0.18798828,\n",
       " -1.2011719,\n",
       " 0.23693848,\n",
       " -0.6972656,\n",
       " -0.13000488,\n",
       " -0.8823242,\n",
       " -0.016601562,\n",
       " 0.0143585205,\n",
       " 0.7836914,\n",
       " -0.027954102,\n",
       " -0.14526367,\n",
       " -1.0371094,\n",
       " -1.4238281,\n",
       " -0.29638672,\n",
       " -0.37109375,\n",
       " 0.8901367,\n",
       " -0.66748047,\n",
       " -0.24072266,\n",
       " 0.9584961,\n",
       " 1.2382812,\n",
       " 0.4572754,\n",
       " 1.2773438,\n",
       " 1.0488281,\n",
       " 0.22363281,\n",
       " -0.25634766,\n",
       " 0.53222656,\n",
       " 0.27783203,\n",
       " 0.043914795,\n",
       " 1.4033203,\n",
       " -0.6772461,\n",
       " 0.75390625,\n",
       " 1.0,\n",
       " 0.69433594,\n",
       " 0.0602417,\n",
       " 0.8256836,\n",
       " 0.29370117,\n",
       " 0.9248047,\n",
       " 0.007598877,\n",
       " 0.09094238,\n",
       " -0.3762207,\n",
       " -0.48461914,\n",
       " -0.7001953,\n",
       " 0.46240234,\n",
       " -0.10882568,\n",
       " -0.17321777,\n",
       " -1.0830078,\n",
       " 1.0205078,\n",
       " -0.9423828,\n",
       " 0.06817627,\n",
       " 0.3779297,\n",
       " 3.2324219,\n",
       " -0.048950195,\n",
       " 0.7397461,\n",
       " 0.10852051,\n",
       " -1.0996094,\n",
       " -0.19885254,\n",
       " -0.44848633,\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ebbed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "from rank_bm25 import BM25Okapi\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "class KiwiBM25Encoder:\n",
    "    \"\"\"Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ê¸°ë°˜ BM25 Sparse ì„ë² ë”©\"\"\"\n",
    "    \n",
    "    def __init__(self, documents: List[str] = None, load_from_dict: dict = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            documents: ìƒˆë¡œ ìƒì„±í•  ê²½ìš° ë¬¸ì„œ ë¦¬ìŠ¤íŠ¸\n",
    "            load_from_dict: ì €ì¥ëœ ë°ì´í„°ë¡œë¶€í„° ë¡œë“œí•  ê²½ìš° ë”•ì…”ë„ˆë¦¬\n",
    "        \"\"\"\n",
    "        if load_from_dict:\n",
    "            # ì €ì¥ëœ ë°ì´í„°ë¡œë¶€í„° ë³µì›\n",
    "            self.tokenized_corpus = load_from_dict['tokenized_corpus']\n",
    "            self.vocabulary = load_from_dict['vocabulary']\n",
    "            self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "            # KiwiëŠ” ë§¤ë²ˆ ìƒˆë¡œ ìƒì„±\n",
    "            self.kiwi = Kiwi()\n",
    "            print(f\"âœ… BM25 ì¸ì½”ë” ë¡œë“œ ì™„ë£Œ (Vocabulary: {len(self.vocabulary)})\")\n",
    "        else:\n",
    "            # ìƒˆë¡œ ìƒì„±\n",
    "            print(\"ğŸ¥ Kiwi ì´ˆê¸°í™” ì¤‘...\")\n",
    "            self.kiwi = Kiwi()\n",
    "            print(\"âœ… Kiwi ì´ˆê¸°í™” ì„±ê³µ!\")\n",
    "            \n",
    "            # ë¬¸ì„œë¥¼ í˜•íƒœì†Œ ë¶„ì„\n",
    "            print(\"ğŸ“ í˜•íƒœì†Œ ë¶„ì„ ì¤‘...\")\n",
    "            self.tokenized_corpus = []\n",
    "            for doc in tqdm(documents, desc=\"í† í¬ë‚˜ì´ì§•\"):\n",
    "                tokens = self._tokenize(doc)\n",
    "                self.tokenized_corpus.append(tokens)\n",
    "            \n",
    "            # BM25 ì´ˆê¸°í™”\n",
    "            print(\"ğŸ” BM25 ì¸ë±ìŠ¤ ìƒì„± ì¤‘...\")\n",
    "            self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "            \n",
    "            # Vocabulary ìƒì„±\n",
    "            self.vocabulary = {}\n",
    "            idx = 0\n",
    "            for doc_tokens in self.tokenized_corpus:\n",
    "                for token in doc_tokens:\n",
    "                    if token not in self.vocabulary:\n",
    "                        self.vocabulary[token] = idx\n",
    "                        idx += 1\n",
    "            \n",
    "            print(f\"âœ… Vocabulary í¬ê¸°: {len(self.vocabulary)}\")\n",
    "    \n",
    "    def _tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"í…ìŠ¤íŠ¸ë¥¼ í˜•íƒœì†Œ ë¶„ì„\"\"\"\n",
    "        result = self.kiwi.tokenize(text)\n",
    "        \n",
    "        tokens = []\n",
    "        for token in result:\n",
    "            if token.tag in ['NNG', 'NNP', 'VV', 'VA', 'MAG', 'SL']:\n",
    "                tokens.append(token.form)\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def encode_query(self, query: str) -> Dict[int, float]:\n",
    "        \"\"\"ì¿¼ë¦¬ë¥¼ sparse vectorë¡œ ë³€í™˜\"\"\"\n",
    "        tokenized_query = self._tokenize(query)\n",
    "        \n",
    "        if not tokenized_query:\n",
    "            return {}\n",
    "        \n",
    "        scores = self.bm25.get_scores(tokenized_query)\n",
    "        \n",
    "        sparse_vector = {}\n",
    "        for token in tokenized_query:\n",
    "            if token in self.vocabulary:\n",
    "                idx = self.vocabulary[token]\n",
    "                if idx < len(scores):\n",
    "                    score = float(scores[idx])\n",
    "                    if score > 0:\n",
    "                        sparse_vector[idx] = score\n",
    "        \n",
    "        return sparse_vector\n",
    "    \n",
    "    def encode_document(self, doc: str, doc_idx: int = None) -> Dict[int, float]:\n",
    "        \"\"\"ë¬¸ì„œë¥¼ sparse vectorë¡œ ë³€í™˜\"\"\"\n",
    "        tokens = self._tokenize(doc)\n",
    "        \n",
    "        tf = {}\n",
    "        for token in tokens:\n",
    "            if token in self.vocabulary:\n",
    "                idx = self.vocabulary[token]\n",
    "                tf[idx] = tf.get(idx, 0.0) + 1.0\n",
    "        \n",
    "        if tf:\n",
    "            max_tf = max(tf.values())\n",
    "            sparse_vector = {k: v / max_tf for k, v in tf.items()}\n",
    "        else:\n",
    "            sparse_vector = {}\n",
    "        \n",
    "        return sparse_vector\n",
    "    \n",
    "    def to_dict(self):\n",
    "        \"\"\"ì €ì¥ ê°€ëŠ¥í•œ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (Kiwi ê°ì²´ ì œì™¸)\"\"\"\n",
    "        return {\n",
    "            'tokenized_corpus': self.tokenized_corpus,\n",
    "            'vocabulary': self.vocabulary\n",
    "        }\n",
    "    \n",
    "    def save(self, filepath: str):\n",
    "        \"\"\"ì¸ì½”ë” ì €ì¥ (Kiwi ê°ì²´ ì œì™¸)\"\"\"\n",
    "        data = self.to_dict()\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        print(f\"ğŸ’¾ BM25 ì¸ì½”ë” ì €ì¥: {filepath}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filepath: str):\n",
    "        \"\"\"ì¸ì½”ë” ë¡œë“œ\"\"\"\n",
    "        with open(filepath, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        print(f\"ğŸ“‚ BM25 ì¸ì½”ë” ë¡œë“œ: {filepath}\")\n",
    "        return KiwiBM25Encoder(load_from_dict=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¥ Kiwi ì´ˆê¸°í™” ì¤‘...\n",
      "âœ… Kiwi ì´ˆê¸°í™” ì„±ê³µ!\n",
      "ğŸ“ í˜•íƒœì†Œ ë¶„ì„ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í† í¬ë‚˜ì´ì§•: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 143/143 [00:01<00:00, 84.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” BM25 ì¸ë±ìŠ¤ ìƒì„± ì¤‘...\n",
      "âœ… Vocabulary í¬ê¸°: 1811\n",
      "ğŸ’¾ BM25 ì¸ì½”ë” ì €ì¥: kiwi_bm25_encoder.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = [doc.page_content for doc in documents]\n",
    "bm25_encoder = KiwiBM25Encoder(corpus)\n",
    "bm25_encoder.save(\"kiwi_bm25_encoder.pkl\")  # ì‹¤ì œë¡œëŠ” .jsonìœ¼ë¡œ ì €ì¥ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_tokenization(bm25_encoder, texts):\n",
    "    \"\"\"\n",
    "    BM25 ì¸ì½”ë”ì˜ í† í°í™” ê²°ê³¼ ë¶„ì„\n",
    "    \n",
    "    Args:\n",
    "        bm25_encoder: KiwiBM25Encoder ì¸ìŠ¤í„´ìŠ¤\n",
    "        texts: ë¶„ì„í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë‹¨ì¼ í…ìŠ¤íŠ¸\n",
    "    \"\"\"\n",
    "    if isinstance(texts, str):\n",
    "        texts = [texts]\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "    print(\"ğŸ” í† í°í™” ë¶„ì„\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    for i, text in enumerate(texts, 1):\n",
    "        print(f\"\\nğŸ“„ í…ìŠ¤íŠ¸ {i}:\")\n",
    "        print(f\"ì›ë¬¸: {text[:100]}{'...' if len(text) > 100 else ''}\")\n",
    "        print(f\"ì›ë¬¸ ê¸¸ì´: {len(text)}ì\")\n",
    "        \n",
    "        # í† í°í™”\n",
    "        tokens = bm25_encoder._tokenize(text)\n",
    "        \n",
    "        print(f\"\\ní† í° ìˆ˜: {len(tokens)}ê°œ\")\n",
    "        print(f\"í† í° ëª©ë¡: {tokens[:20]}{'...' if len(tokens) > 20 else ''}\")\n",
    "        \n",
    "        # í’ˆì‚¬ë³„ ë¶„ë¥˜\n",
    "        result = bm25_encoder.kiwi.tokenize(text)\n",
    "        pos_count = {}\n",
    "        for token in result:\n",
    "            if token.tag in ['NNG', 'NNP', 'VV', 'VA', 'MAG', 'SL']:\n",
    "                pos_count[token.tag] = pos_count.get(token.tag, 0) + 1\n",
    "        \n",
    "        print(f\"\\ní’ˆì‚¬ë³„ ë¶„í¬:\")\n",
    "        for pos, count in sorted(pos_count.items()):\n",
    "            pos_name = {\n",
    "                'NNG': 'ì¼ë°˜ëª…ì‚¬',\n",
    "                'NNP': 'ê³ ìœ ëª…ì‚¬',\n",
    "                'VV': 'ë™ì‚¬',\n",
    "                'VA': 'í˜•ìš©ì‚¬',\n",
    "                'MAG': 'ì¼ë°˜ë¶€ì‚¬',\n",
    "                'SL': 'ì™¸ë˜ì–´'\n",
    "            }.get(pos, pos)\n",
    "            print(f\"  {pos_name}({pos}): {count}ê°œ\")\n",
    "        \n",
    "        print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ” í† í°í™” ë¶„ì„\n",
      "================================================================================\n",
      "\n",
      "ğŸ“„ í…ìŠ¤íŠ¸ 1:\n",
      "ì›ë¬¸: ì œ1ì¡°(ëª©ì ) ì´ ì¡°ë¡€ëŠ” ã€Œê±´ì¶•ë²•ã€, ã€Œê±´ì¶•ë²• ì‹œí–‰ë ¹ã€ ë° ã€Œê±´ì¶•ë²• ì‹œí–‰ê·œì¹™ã€ì—ì„œ ì¡°ë¡€ë¡œ ì •í•˜ë„ë¡ ìœ„ì„ëœ ì‚¬í•­ê³¼ ê·¸ ì‹œí–‰ì— í•„ìš”í•œ ì‚¬í•­ì„ ì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.\n",
      "ì›ë¬¸ ê¸¸ì´: 89ì\n",
      "\n",
      "í† í° ìˆ˜: 22ê°œ\n",
      "í† í° ëª©ë¡: ['ì¡°', 'ëª©ì ', 'ì¡°ë¡€', 'ê±´ì¶•ë²•', 'ê±´ì¶•', 'ë²•', 'ì‹œí–‰ë ¹', 'ë°', 'ê±´ì¶•', 'ë²•', 'ì‹œí–‰', 'ê·œì¹™', 'ì¡°ë¡€', 'ì •í•˜', 'ìœ„ì„', 'ì‚¬í•­', 'ì‹œí–‰', 'í•„ìš”', 'ì‚¬í•­', 'ì •í•˜']...\n",
      "\n",
      "í’ˆì‚¬ë³„ ë¶„í¬:\n",
      "  ì¼ë°˜ë¶€ì‚¬(MAG): 1ê°œ\n",
      "  ì¼ë°˜ëª…ì‚¬(NNG): 18ê°œ\n",
      "  ë™ì‚¬(VV): 3ê°œ\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "text = \"ì œ1ì¡°(ëª©ì ) ì´ ì¡°ë¡€ëŠ” ã€Œê±´ì¶•ë²•ã€, ã€Œê±´ì¶•ë²• ì‹œí–‰ë ¹ã€ ë° ã€Œê±´ì¶•ë²• ì‹œí–‰ê·œì¹™ã€ì—ì„œ ì¡°ë¡€ë¡œ ì •í•˜ë„ë¡ ìœ„ì„ëœ ì‚¬í•­ê³¼ ê·¸ ì‹œí–‰ì— í•„ìš”í•œ ì‚¬í•­ì„ ì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.\"\n",
    "\n",
    "analyze_tokenization(bm25_encoder, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "5 validation errors for CreateCollection\nvectors.VectorParams.size\n  Field required [type=missing, input_value={'dense': VectorParams(si...e=None), modifier=None)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nvectors.VectorParams.distance\n  Field required [type=missing, input_value={'dense': VectorParams(si...e=None), modifier=None)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nvectors.VectorParams.dense\n  Extra inputs are not permitted [type=extra_forbidden, input_value=VectorParams(size=1024, d...multivector_config=None), input_type=VectorParams]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nvectors.VectorParams.sparse\n  Extra inputs are not permitted [type=extra_forbidden, input_value=SparseVectorParams(index=...pe=None), modifier=None), input_type=SparseVectorParams]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nvectors.dict[str,VectorParams].sparse\n  Input should be a valid dictionary or instance of VectorParams [type=model_type, input_value=SparseVectorParams(index=...pe=None), modifier=None), input_type=SparseVectorParams]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m collection_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_regulations\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ì»¬ë ‰ì…˜ ìƒì„± (ë²¡í„° ì°¨ì›ì€ ì„ë² ë”© ëª¨ë¸ì— ë”°ë¼ ì¡°ì •)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mqdrant_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvectors_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdense\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mVectorParams\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDistance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOSINE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msparse\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSparseVectorParams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSparseIndexParams\u001b[49m\u001b[43m(\u001b[49m\u001b[43mon_disk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag/lib/python3.9/site-packages/qdrant_client/qdrant_client.py:2382\u001b[0m, in \u001b[0;36mQdrantClient.create_collection\u001b[0;34m(self, collection_name, vectors_config, sparse_vectors_config, shard_number, sharding_method, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, init_from, timeout, strict_mode_config, **kwargs)\u001b[0m\n\u001b[1;32m   2332\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create empty collection with given parameters\u001b[39;00m\n\u001b[1;32m   2333\u001b[0m \n\u001b[1;32m   2334\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2378\u001b[0m \u001b[38;5;124;03m    Operation result\u001b[39;00m\n\u001b[1;32m   2379\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2380\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 2382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvectors_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvectors_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshard_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshard_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2386\u001b[0m \u001b[43m    \u001b[49m\u001b[43msharding_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharding_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreplication_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplication_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_consistency_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_consistency_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_disk_payload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_disk_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhnsw_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhnsw_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2391\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizers_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizers_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwal_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwal_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2394\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_from\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2395\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2396\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_vectors_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_vectors_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict_mode_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict_mode_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2398\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2399\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag/lib/python3.9/site-packages/qdrant_client/qdrant_remote.py:2799\u001b[0m, in \u001b[0;36mQdrantRemote.create_collection\u001b[0;34m(self, collection_name, vectors_config, shard_number, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, init_from, timeout, sparse_vectors_config, sharding_method, strict_mode_config, **kwargs)\u001b[0m\n\u001b[1;32m   2796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init_from, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   2797\u001b[0m     init_from \u001b[38;5;241m=\u001b[39m GrpcToRest\u001b[38;5;241m.\u001b[39mconvert_init_from(init_from)\n\u001b[0;32m-> 2799\u001b[0m create_collection_request \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvectors_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshard_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshard_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreplication_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplication_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwrite_consistency_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_consistency_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_disk_payload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_disk_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhnsw_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhnsw_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2806\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizers_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizers_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwal_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwal_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2809\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_from\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_from\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2810\u001b[0m \u001b[43m    \u001b[49m\u001b[43msparse_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_vectors_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2811\u001b[0m \u001b[43m    \u001b[49m\u001b[43msharding_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharding_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2812\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict_mode_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict_mode_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2813\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2815\u001b[0m result: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhttp\u001b[38;5;241m.\u001b[39mcollections_api\u001b[38;5;241m.\u001b[39mcreate_collection(\n\u001b[1;32m   2816\u001b[0m     collection_name\u001b[38;5;241m=\u001b[39mcollection_name,\n\u001b[1;32m   2817\u001b[0m     create_collection\u001b[38;5;241m=\u001b[39mcreate_collection_request,\n\u001b[1;32m   2818\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   2819\u001b[0m )\u001b[38;5;241m.\u001b[39mresult\n\u001b[1;32m   2821\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreate collection returned None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/rag/lib/python3.9/site-packages/pydantic/main.py:253\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(self, **data)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[1;32m    252\u001b[0m __tracebackhide__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m validated_self \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[1;32m    255\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    259\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    260\u001b[0m     )\n",
      "\u001b[0;31mValidationError\u001b[0m: 5 validation errors for CreateCollection\nvectors.VectorParams.size\n  Field required [type=missing, input_value={'dense': VectorParams(si...e=None), modifier=None)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nvectors.VectorParams.distance\n  Field required [type=missing, input_value={'dense': VectorParams(si...e=None), modifier=None)}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing\nvectors.VectorParams.dense\n  Extra inputs are not permitted [type=extra_forbidden, input_value=VectorParams(size=1024, d...multivector_config=None), input_type=VectorParams]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nvectors.VectorParams.sparse\n  Extra inputs are not permitted [type=extra_forbidden, input_value=SparseVectorParams(index=...pe=None), modifier=None), input_type=SparseVectorParams]\n    For further information visit https://errors.pydantic.dev/2.11/v/extra_forbidden\nvectors.dict[str,VectorParams].sparse\n  Input should be a valid dictionary or instance of VectorParams [type=model_type, input_value=SparseVectorParams(index=...pe=None), modifier=None), input_type=SparseVectorParams]\n    For further information visit https://errors.pydantic.dev/2.11/v/model_type"
     ]
    }
   ],
   "source": [
    "collection_name = \"local_regulations\"\n",
    "\n",
    "# ì»¬ë ‰ì…˜ ìƒì„± (ë²¡í„° ì°¨ì›ì€ ì„ë² ë”© ëª¨ë¸ì— ë”°ë¼ ì¡°ì •)\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config={\"dense\": VectorParams(size=1024, distance=Distance.COSINE),\n",
    "                    \"sparse\": SparseVectorParams(index=SparseIndexParams(on_disk=False,))\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ë¬¸ì„œ ì¸ë±ì‹±\n",
    "print(f\"\\nğŸ“š {len(documents)}ê°œ ë¬¸ì„œ ì¸ë±ì‹± ì¤‘...\")\n",
    "points = []\n",
    "batch_size = 50\n",
    "\n",
    "for idx, doc in enumerate(tqdm(documents, desc=\"ì¸ë±ì‹±\")):\n",
    "    # Dense ì„ë² ë”© (Clova)\n",
    "    dense_vector = clova_embedder.embed_query(doc.page_content)\n",
    "    \n",
    "    # Sparse ì„ë² ë”© (Mecab BM25)\n",
    "    sparse_vector = bm25_encoder.encode_document(doc.page_content, idx)\n",
    "    \n",
    "    # Point ìƒì„±\n",
    "    point = PointStruct(\n",
    "        id=idx,\n",
    "        vector={\n",
    "            \"dense\": dense_vector,\n",
    "            \"sparse\": sparse_vector\n",
    "        },\n",
    "        payload={\n",
    "            \"page_content\": doc.page_content,\n",
    "            \"metadata\": doc.metadata,\n",
    "            \"doc_id\": doc.id\n",
    "        }\n",
    "    )\n",
    "    points.append(point)\n",
    "    \n",
    "    # ë°°ì¹˜ ì—…ë¡œë“œ\n",
    "    if len(points) >= batch_size:\n",
    "        qdrant_client.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=points\n",
    "        )\n",
    "        points = []\n",
    "\n",
    "# ë‚¨ì€ points ì—…ë¡œë“œ\n",
    "if points:\n",
    "    qdrant_client.upsert(\n",
    "        collection_name=collection_name,\n",
    "        points=points\n",
    "    )\n",
    "\n",
    "print(f\"âœ… ì¸ë±ì‹± ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¥ Kiwi ì´ˆê¸°í™” ì¤‘...\n",
      "âœ… Kiwi ì´ˆê¸°í™” ì„±ê³µ!\n",
      "ğŸ“ í˜•íƒœì†Œ ë¶„ì„ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í† í¬ë‚˜ì´ì§•: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” BM25 ì¸ë±ìŠ¤ ìƒì„± ì¤‘...\n",
      "âœ… Vocabulary í¬ê¸°: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoder = KiwiBM25Encoder(documents=[\n",
    "        \"\"\"ì œ4ì¡°(ì œì„¤Â·ì œë¹™ ì‹œê¸°) ê±´ì¶•ë¬¼ê´€ë¦¬ìëŠ” ë‹¤ìŒ ê° í˜¸ì™€ ê°™ì´ ì œì„¤Â·ì œë¹™ì„ ë§ˆì³ì•¼ í•œë‹¤.\n",
    "        1. ë³´ë„, ì´ë©´ë„ë¡œ, ë³´í–‰ìì „ìš©ë„ë¡œ: ë‹¤ìŒ ê° ëª©ì˜ êµ¬ë¶„ì— ë”°ë¥¸ ê¸°í•œê¹Œì§€\n",
    "        ê°€. 1ì¼ ë‚´ë¦° ëˆˆì˜ ì–‘ì´ 10ì„¼í‹°ë¯¸í„° ë¯¸ë§Œì¸ ê²½ìš°\n",
    "        1) ì£¼ê°„ì— ëˆˆì´ ê·¸ì¹œ ê²½ìš°: ëˆˆì´ ê·¸ì¹œ ë•Œë¶€í„° 4ì‹œê°„ ì´ë‚´\"\"\",\n",
    "        \n",
    "        \"\"\"ì œ11ì¡°ì˜6(ìœ„ì›íšŒì˜ ìš´ì˜)â‘  ìœ„ì›íšŒ íšŒì˜ëŠ” ë„ì§€ì‚¬ì˜ ìš”êµ¬ê°€ ìˆê±°ë‚˜ \n",
    "        ìœ„ì›ì¥ì´ í•„ìš”í•˜ë‹¤ê³  ì¸ì •í•˜ëŠ” ê²½ìš°ì— ìœ„ì›ì¥ì´ ì†Œì§‘í•œë‹¤.\n",
    "        â‘¡ íšŒì˜ëŠ” ì¬ì ìœ„ì› ê³¼ë°˜ìˆ˜ì˜ ì¶œì„ê³¼ ì¶œì„ìœ„ì› ê³¼ë°˜ìˆ˜ì˜ ì°¬ì„±ìœ¼ë¡œ ì˜ê²°í•œë‹¤.\"\"\"\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "í† í°í™” í…ŒìŠ¤íŠ¸\n",
      "============================================================\n",
      "\n",
      "ğŸ“ ì§ˆë¬¸: ì œ1ì¡°ì œ1í•­ì— ì˜í•˜ë©´ ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ ì˜ë¬´ëŠ”?\n",
      "   í† í°: ['ì œ1ì¡°ì œ1í•­', 'ì œ1í•­', 'ì˜í•˜', 'ê±´ì¶•ë¬¼', 'ê´€ë¦¬ì', 'ì œì„¤', 'ì˜ë¬´']\n",
      "   ë²•ë¥  ì—”í‹°í‹°: ['ì œ1ì¡°ì œ1í•­', 'ì œ1í•­']\n",
      "   í† í° ìˆ˜: 7\n",
      "   ì¡°í•­ ì°¸ì¡°: [{'text': 'ì œ1ì¡°ì œ1í•­', 'article': '1', 'sub_article': None, 'paragraph': '1', 'item': None, 'position': (0, 6)}]\n",
      "   Sparse Vector ì°¨ì›: 3\n",
      "\n",
      "ğŸ“ ì§ˆë¬¸: 10ì„¼í‹°ë¯¸í„° ë¯¸ë§Œ ëˆˆì´ ì™”ì„ ë•Œ ì œì„¤ ê¸°í•œì€?\n",
      "   í† í°: ['10ì„¼í‹°ë¯¸í„°', 'ë¯¸ë§Œ', 'ì œì„¤', 'ê¸°í•œ']\n",
      "   ë²•ë¥  ì—”í‹°í‹°: ['10ì„¼í‹°ë¯¸í„°']\n",
      "   í† í° ìˆ˜: 4\n",
      "   Sparse Vector ì°¨ì›: 4\n",
      "\n",
      "ğŸ“ ì§ˆë¬¸: ìœ„ì›íšŒ íšŒì˜ëŠ” ì–¸ì œ ì†Œì§‘ë˜ë‚˜ìš”?\n",
      "   í† í°: ['ìœ„ì›íšŒ', 'íšŒì˜', 'ì–¸ì œ', 'ì†Œì§‘']\n",
      "   ë²•ë¥  ì—”í‹°í‹°: []\n",
      "   í† í° ìˆ˜: 4\n",
      "   Sparse Vector ì°¨ì›: 3\n",
      "\n",
      "ğŸ“ ì§ˆë¬¸: ì¬ì ìœ„ì› ê³¼ë°˜ìˆ˜\n",
      "   í† í°: ['ì¬ì ', 'ìœ„ì›', 'ê³¼ë°˜ìˆ˜']\n",
      "   ë²•ë¥  ì—”í‹°í‹°: []\n",
      "   í† í° ìˆ˜: 3\n",
      "   Sparse Vector ì°¨ì›: 3\n"
     ]
    }
   ],
   "source": [
    "# í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ë“¤\n",
    "test_queries = [\n",
    "    \"ì œ1ì¡°ì œ1í•­ì— ì˜í•˜ë©´ ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ ì˜ë¬´ëŠ”?\",\n",
    "    \"10ì„¼í‹°ë¯¸í„° ë¯¸ë§Œ ëˆˆì´ ì™”ì„ ë•Œ ì œì„¤ ê¸°í•œì€?\",\n",
    "    \"ìœ„ì›íšŒ íšŒì˜ëŠ” ì–¸ì œ ì†Œì§‘ë˜ë‚˜ìš”?\",\n",
    "    \"ì¬ì ìœ„ì› ê³¼ë°˜ìˆ˜\"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"í† í°í™” í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nğŸ“ ì§ˆë¬¸: {query}\")\n",
    "    analysis = encoder.analyze_tokenization(query)\n",
    "    print(f\"   í† í°: {analysis['tokens']}\")\n",
    "    print(f\"   ë²•ë¥  ì—”í‹°í‹°: {analysis['legal_entities']}\")\n",
    "    print(f\"   í† í° ìˆ˜: {analysis['token_count']}\")\n",
    "    \n",
    "    # ì¡°í•­ ì°¸ì¡° ì¶”ì¶œ\n",
    "    refs = encoder.extract_article_references(query)\n",
    "    if refs:\n",
    "        print(f\"   ì¡°í•­ ì°¸ì¡°: {refs}\")\n",
    "    \n",
    "    # Sparse vector ìƒì„±\n",
    "    sparse_vec = encoder.encode_query(query)\n",
    "    print(f\"   Sparse Vector ì°¨ì›: {len(sparse_vec)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ìµœì¢…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë²•ë ¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "from rank_bm25 import BM25Okapi\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import (\n",
    "    Distance, \n",
    "    VectorParams, \n",
    "    SparseVectorParams,\n",
    "    SparseIndexParams,\n",
    "    PointStruct,\n",
    "    SparseVector,\n",
    "    NamedVector,\n",
    "    NamedSparseVector\n",
    ")\n",
    "from langchain_core.documents import Document\n",
    "import json\n",
    "import os\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 1. Kiwi BM25 ì¸ì½”ë”\n",
    "# ============================================\n",
    "\n",
    "class KiwiBM25Encoder:\n",
    "    \"\"\"Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ê¸°ë°˜ BM25 Sparse ì„ë² ë”©\"\"\"\n",
    "    \n",
    "    def __init__(self, documents: List[str] = None, load_from_dict: dict = None):\n",
    "        if load_from_dict:\n",
    "            self.tokenized_corpus = load_from_dict['tokenized_corpus']\n",
    "            self.vocabulary = load_from_dict['vocabulary']\n",
    "            self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "            self.kiwi = Kiwi()\n",
    "            self._build_idf_cache()\n",
    "            print(f\"âœ… BM25 ì¸ì½”ë” ë¡œë“œ ì™„ë£Œ (Vocabulary: {len(self.vocabulary)})\")\n",
    "        else:\n",
    "            print(\"ğŸ¥ Kiwi ì´ˆê¸°í™” ì¤‘...\")\n",
    "            self.kiwi = Kiwi()\n",
    "            print(\"âœ… Kiwi ì´ˆê¸°í™” ì„±ê³µ!\")\n",
    "            \n",
    "            print(\"ğŸ“ í˜•íƒœì†Œ ë¶„ì„ ì¤‘...\")\n",
    "            self.tokenized_corpus = []\n",
    "            for doc in tqdm(documents, desc=\"í† í¬ë‚˜ì´ì§•\"):\n",
    "                tokens = self._tokenize(doc)\n",
    "                self.tokenized_corpus.append(tokens)\n",
    "            \n",
    "            print(\"ğŸ” BM25 ì¸ë±ìŠ¤ ìƒì„± ì¤‘...\")\n",
    "            self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "            \n",
    "            self.vocabulary = {}\n",
    "            idx = 0\n",
    "            for doc_tokens in self.tokenized_corpus:\n",
    "                for token in doc_tokens:\n",
    "                    if token not in self.vocabulary:\n",
    "                        self.vocabulary[token] = idx\n",
    "                        idx += 1\n",
    "            \n",
    "            self._build_idf_cache()\n",
    "            print(f\"âœ… Vocabulary í¬ê¸°: {len(self.vocabulary)}\")\n",
    "    \n",
    "    def _build_idf_cache(self):\n",
    "        \"\"\"ê° í† í°ì˜ IDF ê°’ì„ ë¯¸ë¦¬ ê³„ì‚°\"\"\"\n",
    "        self.idf_cache = {}\n",
    "        total_docs = len(self.tokenized_corpus)\n",
    "        \n",
    "        for token, idx in self.vocabulary.items():\n",
    "            doc_freq = sum(1 for doc in self.tokenized_corpus if token in doc)\n",
    "            idf = np.log((total_docs - doc_freq + 0.5) / (doc_freq + 0.5) + 1.0)\n",
    "            self.idf_cache[idx] = max(0.0, idf)\n",
    "    \n",
    "    def _tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"í…ìŠ¤íŠ¸ë¥¼ í˜•íƒœì†Œ ë¶„ì„\"\"\"\n",
    "        result = self.kiwi.tokenize(text)\n",
    "        tokens = []\n",
    "        for token in result:\n",
    "            if token.tag in ['NNG', 'NNP', 'VV', 'VA', 'MAG', 'SL']:\n",
    "                tokens.append(token.form)\n",
    "        return tokens\n",
    "    \n",
    "    def encode_query(self, query: str) -> Dict[int, float]:\n",
    "        \"\"\"ì¿¼ë¦¬ë¥¼ sparse vectorë¡œ ë³€í™˜\"\"\"\n",
    "        tokenized_query = self._tokenize(query)\n",
    "        \n",
    "        if not tokenized_query:\n",
    "            return {}\n",
    "        \n",
    "        token_freq = {}\n",
    "        for token in tokenized_query:\n",
    "            if token in self.vocabulary:\n",
    "                token_freq[token] = token_freq.get(token, 0) + 1\n",
    "        \n",
    "        if not token_freq:\n",
    "            return {}\n",
    "        \n",
    "        sparse_vector = {}\n",
    "        for token, freq in token_freq.items():\n",
    "            idx = self.vocabulary[token]\n",
    "            idf = self.idf_cache.get(idx, 0.0)\n",
    "            \n",
    "            tf = freq / len(tokenized_query)\n",
    "            score = tf * idf\n",
    "            \n",
    "            if score > 0:\n",
    "                sparse_vector[idx] = float(score)\n",
    "        \n",
    "        return sparse_vector\n",
    "    \n",
    "    def encode_document(self, doc: str, doc_idx: int = None) -> Dict[int, float]:\n",
    "        \"\"\"ë¬¸ì„œë¥¼ sparse vectorë¡œ ë³€í™˜\"\"\"\n",
    "        tokens = self._tokenize(doc)\n",
    "        \n",
    "        if not tokens:\n",
    "            return {}\n",
    "        \n",
    "        tf = {}\n",
    "        for token in tokens:\n",
    "            if token in self.vocabulary:\n",
    "                idx = self.vocabulary[token]\n",
    "                tf[idx] = tf.get(idx, 0.0) + 1.0\n",
    "        \n",
    "        if not tf:\n",
    "            return {}\n",
    "        \n",
    "        max_tf = max(tf.values())\n",
    "        sparse_vector = {k: v / max_tf for k, v in tf.items()}\n",
    "        \n",
    "        return sparse_vector\n",
    "    \n",
    "    def save(self, filepath: str):\n",
    "        \"\"\"JSONìœ¼ë¡œ ì €ì¥\"\"\"\n",
    "        data = {\n",
    "            'tokenized_corpus': self.tokenized_corpus,\n",
    "            'vocabulary': self.vocabulary\n",
    "        }\n",
    "        \n",
    "        json_filepath = filepath.replace('.pkl', '.json')\n",
    "        with open(json_filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"ğŸ’¾ BM25 ì¸ì½”ë” ì €ì¥: {json_filepath}\")\n",
    "        return json_filepath\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filepath: str):\n",
    "        \"\"\"JSONì—ì„œ ë¡œë“œ\"\"\"\n",
    "        json_filepath = filepath.replace('.pkl', '.json')\n",
    "        \n",
    "        if not os.path.exists(json_filepath):\n",
    "            raise FileNotFoundError(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_filepath}\")\n",
    "        \n",
    "        with open(json_filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        print(f\"ğŸ“‚ BM25 ì¸ì½”ë” ë¡œë“œ: {json_filepath}\")\n",
    "        return KiwiBM25Encoder(load_from_dict=data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ë²•ë¥ ë¬¸ì„œ íŠ¹í™”\n",
    "from kiwipiepy import Kiwi\n",
    "from rank_bm25 import BM25Okapi\n",
    "from typing import List, Dict, Tuple, Set\n",
    "from tqdm import tqdm\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import (\n",
    "    Distance, \n",
    "    VectorParams, \n",
    "    SparseVectorParams,\n",
    "    SparseIndexParams,\n",
    "    PointStruct,\n",
    "    SparseVector,\n",
    "    NamedVector,\n",
    "    NamedSparseVector\n",
    ")\n",
    "from langchain_core.documents import Document\n",
    "import json\n",
    "import os\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import re\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 1. Kiwi BM25 ì¸ì½”ë” (ë²•ë¥  ë¬¸ì„œ íŠ¹í™”)\n",
    "# ============================================\n",
    "\n",
    "class KiwiBM25Encoder:\n",
    "    \"\"\"Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ê¸°ë°˜ BM25 Sparse ì„ë² ë”© (ë²•ë¥  ë¬¸ì„œ íŠ¹í™”)\"\"\"\n",
    "    \n",
    "    def __init__(self, documents: List[str] = None, load_from_dict: dict = None):\n",
    "        if load_from_dict:\n",
    "            self.tokenized_corpus = load_from_dict['tokenized_corpus']\n",
    "            self.vocabulary = load_from_dict['vocabulary']\n",
    "            self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "            self.kiwi = Kiwi()\n",
    "            self._init_legal_patterns()  # ğŸ†• ë²•ë¥  íŒ¨í„´ ì´ˆê¸°í™”\n",
    "            self._build_idf_cache()\n",
    "            print(f\"âœ… BM25 ì¸ì½”ë” ë¡œë“œ ì™„ë£Œ (Vocabulary: {len(self.vocabulary)})\")\n",
    "        else:\n",
    "            print(\"ğŸ¥ Kiwi ì´ˆê¸°í™” ì¤‘...\")\n",
    "            self.kiwi = Kiwi()\n",
    "            self._init_legal_patterns()  # ğŸ†• ë²•ë¥  íŒ¨í„´ ì´ˆê¸°í™”\n",
    "            print(\"âœ… Kiwi ì´ˆê¸°í™” ì„±ê³µ!\")\n",
    "            \n",
    "            print(\"ğŸ“ í˜•íƒœì†Œ ë¶„ì„ ì¤‘...\")\n",
    "            self.tokenized_corpus = []\n",
    "            for doc in tqdm(documents, desc=\"í† í¬ë‚˜ì´ì§•\"):\n",
    "                tokens = self._tokenize(doc)\n",
    "                self.tokenized_corpus.append(tokens)\n",
    "            \n",
    "            print(\"ğŸ” BM25 ì¸ë±ìŠ¤ ìƒì„± ì¤‘...\")\n",
    "            self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "            \n",
    "            self.vocabulary = {}\n",
    "            idx = 0\n",
    "            for doc_tokens in self.tokenized_corpus:\n",
    "                for token in doc_tokens:\n",
    "                    if token not in self.vocabulary:\n",
    "                        self.vocabulary[token] = idx\n",
    "                        idx += 1\n",
    "            \n",
    "            self._build_idf_cache()\n",
    "            print(f\"âœ… Vocabulary í¬ê¸°: {len(self.vocabulary)}\")\n",
    "    \n",
    "    # ğŸ†• ë²•ë¥  ë¬¸ì„œ íŠ¹í™” íŒ¨í„´ ë° ìš©ì–´ ì •ì˜\n",
    "    def _init_legal_patterns(self):\n",
    "        \"\"\"ë²•ë¥  ë¬¸ì„œ íŠ¹í™” íŒ¨í„´ ë° ìš©ì–´ ì´ˆê¸°í™”\"\"\"\n",
    "        # ë²•ë¥  ìš©ì–´ íŒ¨í„´\n",
    "        self.legal_patterns = {\n",
    "            # ì¡°í•­ ì°¸ì¡°: ì œ1ì¡°, ì œ2ì¡°ì˜3, ì œ10ì¡°ì œ1í•­ì œ2í˜¸ ë“±\n",
    "            'article': re.compile(\n",
    "                r'ì œ\\s*\\d+\\s*ì¡°(?:ì˜\\s*\\d+)?(?:ì œ\\s*\\d+\\s*í•­)?(?:ì œ\\s*\\d+\\s*í˜¸)?'\n",
    "            ),\n",
    "            # í•­: ì œ1í•­, ì œ2í•­ ë“±\n",
    "            'paragraph': re.compile(r'ì œ\\s*\\d+\\s*í•­'),\n",
    "            # í˜¸: ì œ1í˜¸, ì œ2í˜¸ ë“±\n",
    "            'item': re.compile(r'ì œ\\s*\\d+\\s*í˜¸'),\n",
    "            # ëª©: ê°€ëª©, ë‚˜ëª© ë“±\n",
    "            'subitem': re.compile(r'[ê°€-í•˜]\\s*ëª©'),\n",
    "            # ë³„í‘œ: ë³„í‘œ 1, ë³„í‘œ2 ë“±\n",
    "            'appendix': re.compile(r'ë³„í‘œ\\s*\\d+'),\n",
    "            # ë³„ì§€: ë³„ì§€ ì œ1í˜¸ì„œì‹ ë“±\n",
    "            'attachment': re.compile(r'ë³„ì§€\\s*(?:ì œ\\s*\\d+\\s*í˜¸\\s*)?ì„œì‹'),\n",
    "            # ê¸°ê°„: 3ì¼ ì´ë‚´, 30ì¼ ì´ìƒ, 4ì‹œê°„ ì´ë‚´ ë“±\n",
    "            'period': re.compile(\n",
    "                r'\\d+\\s*(?:ì¼|ê°œì›”|ë…„|ì‹œê°„|ë¶„|ì£¼)(?:\\s*(?:ì´ë‚´|ì´ìƒ|ë¯¸ë§Œ|ì´ˆê³¼|ì´í•˜))?'\n",
    "            ),\n",
    "            # ê¸ˆì•¡: 100ë§Œì›, 1ì²œë§Œì› ë“±\n",
    "            'amount': re.compile(r'\\d+(?:ë§Œ|ì²œ|ì–µ)?\\s*ì›'),\n",
    "            # ë¹„ìœ¨/ë°°ìˆ˜: 100ë¶„ì˜ 50, 2ë¶„ì˜ 1 ë“±\n",
    "            'ratio': re.compile(r'\\d+\\s*ë¶„ì˜\\s*\\d+'),\n",
    "            # ë‹¨ìœ„: ì„¼í‹°ë¯¸í„°, ë¯¸í„° ë“±\n",
    "            'unit': re.compile(\n",
    "                r'\\d+(?:\\.\\d+)?\\s*(?:ì„¼í‹°ë¯¸í„°|ë¯¸í„°|í‚¬ë¡œë¯¸í„°|ì œê³±ë¯¸í„°|í‰ë°©ë¯¸í„°|cm|m|km)'\n",
    "            ),\n",
    "            # ì—°ë„/ë‚ ì§œ: 2024ë…„, 2024. 1. 6. ë“±\n",
    "            'date': re.compile(r'\\d{4}\\s*ë…„|\\d{4}\\.\\s*\\d{1,2}\\.\\s*\\d{1,2}\\.'),\n",
    "        }\n",
    "        \n",
    "        # ë²•ë¥  ì „ë¬¸ ìš©ì–´ (ë³µí•©ëª…ì‚¬ - ë¶„ë¦¬í•˜ì§€ ì•Šê³  í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ ìœ ì§€)\n",
    "        self.legal_terms = {\n",
    "            'ê±´ì¶•ë¬¼ê´€ë¦¬ì', 'ë…¹ìƒ‰ê±´ì¶•ë¬¼', 'ë…¹ìƒ‰ê±´ì¶•ì„¼í„°', 'ì—ë„ˆì§€íš¨ìœ¨ë“±ê¸‰',\n",
    "            'ê±´ì¶•í—ˆê°€', 'ì‚¬ìš©ìŠ¹ì¸', 'ê³¼íƒœë£Œ', 'í–‰ì •ì²˜ë¶„', 'ì´í–‰ê°•ì œê¸ˆ',\n",
    "            'ì¬ì ìœ„ì›', 'ì¶œì„ìœ„ì›', 'ì„œë©´ì‹¬ì˜', 'ì œì²™', 'ê¸°í”¼', 'íšŒí”¼',\n",
    "            'ê³µí¬ì¼ì', 'ì‹œí–‰ì¼ì', 'ì œê°œì •', 'ì „ë¶€ê°œì •', 'ì¼ë¶€ê°œì •',\n",
    "            'ìì¹˜ë²•ê·œ', 'ì¡°ë¡€', 'ê·œì¹™', 'í›ˆë ¹', 'ì˜ˆê·œ', 'ê³ ì‹œ',\n",
    "            'ë³´í–‰ìì „ìš©ë„ë¡œ', 'ì´ë©´ë„ë¡œ', 'ì‹œì„¤ë¬¼', 'ì§€ë¶•',\n",
    "            'ì œì„¤', 'ì œë¹™', 'ê°•ì„¤', 'ì ì„¤', 'ê³ ì§€ëŒ€', 'ì‚°ê°„ì§€ì—­'\n",
    "        }\n",
    "        \n",
    "        # ë¶ˆìš©ì–´ (ë²•ë¥  ë¬¸ì„œì—ì„œ ì˜ë¯¸ ì—†ëŠ” ì¡°ì‚¬ ë“±)\n",
    "        self.stopwords = {\n",
    "            'ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì€', 'ëŠ”', 'ì˜', 'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ë¡œ',\n",
    "            'ì™€', 'ê³¼', 'ë„', 'ë§Œ', 'ê¹Œì§€', 'ë¶€í„°', 'í•˜ì—¬', 'í•˜ê³ ', 'ìˆë‹¤', 'í•œë‹¤'\n",
    "        }\n",
    "    \n",
    "    # ğŸ†• ë²•ë¥  íŠ¹í™” ì—”í‹°í‹° ì¶”ì¶œ\n",
    "    def _extract_legal_entities(self, text: str) -> List[Tuple[str, int, int]]:\n",
    "        \"\"\"\n",
    "        ë²•ë¥  íŠ¹í™” ì—”í‹°í‹° ì¶”ì¶œ\n",
    "        \n",
    "        Returns:\n",
    "            List of (normalized_entity, start_pos, end_pos)\n",
    "        \"\"\"\n",
    "        entities = []\n",
    "        \n",
    "        for pattern_name, pattern in self.legal_patterns.items():\n",
    "            for match in pattern.finditer(text):\n",
    "                # ê³µë°± ì œê±°í•œ ì •ê·œí™”ëœ í˜•íƒœ\n",
    "                normalized = re.sub(r'\\s+', '', match.group())\n",
    "                entities.append((normalized, match.start(), match.end()))\n",
    "        \n",
    "        return sorted(entities, key=lambda x: x[1])  # ìœ„ì¹˜ìˆœ ì •ë ¬\n",
    "    \n",
    "    # ğŸ†• ìœ„ì¹˜ ê²¹ì¹¨ í™•ì¸\n",
    "    def _is_overlapping(self, pos1: Tuple[int, int], pos2: Tuple[int, int]) -> bool:\n",
    "        \"\"\"ë‘ ìœ„ì¹˜ê°€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸\"\"\"\n",
    "        return not (pos1[1] <= pos2[0] or pos2[1] <= pos1[0])\n",
    "    \n",
    "    # ğŸ”„ ìˆ˜ì •ëœ í† í¬ë‚˜ì´ì €\n",
    "    def _tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        ë²•ë¥  ë¬¸ì„œì— íŠ¹í™”ëœ í† í°í™”\n",
    "        \n",
    "        ê°œì„ ì‚¬í•­:\n",
    "        - ì¡°í•­ ë²ˆí˜¸ (ì œ1ì¡°, ì œ1í•­ ë“±) ë³´ì¡´\n",
    "        - ìˆ«ì í¬í•¨ ë²•ë¥  ìš©ì–´ ë³´ì¡´\n",
    "        - ê¸°ê°„, ê¸ˆì•¡, ë‹¨ìœ„ ë“± ìˆ˜ì¹˜ ì •ë³´ ë³´ì¡´\n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "        \n",
    "        # 1. ë²•ë¥  íŠ¹í™” ì—”í‹°í‹° ì¶”ì¶œ\n",
    "        legal_entities = self._extract_legal_entities(text)\n",
    "        entity_positions = [(e[1], e[2]) for e in legal_entities]\n",
    "        \n",
    "        # ë²•ë¥  ì—”í‹°í‹°ë¥¼ í† í°ìœ¼ë¡œ ì¶”ê°€\n",
    "        for entity_text, _, _ in legal_entities:\n",
    "            tokens.append(entity_text)\n",
    "        \n",
    "        # 2. í˜•íƒœì†Œ ë¶„ì„ (Kiwi)\n",
    "        morphs = self.kiwi.tokenize(text)\n",
    "        \n",
    "        for morph in morphs:\n",
    "            # ì´ë¯¸ ë²•ë¥  ì—”í‹°í‹°ë¡œ ì¶”ì¶œëœ ë¶€ë¶„ì€ ìŠ¤í‚µ\n",
    "            morph_pos = (morph.start, morph.start + morph.len)\n",
    "            if any(self._is_overlapping(morph_pos, entity_pos) \n",
    "                   for entity_pos in entity_positions):\n",
    "                continue\n",
    "            \n",
    "            # ë²•ë¥  ì „ë¬¸ ìš©ì–´ ì²´í¬ (ë³µí•©ëª…ì‚¬ ë³´ì¡´)\n",
    "            if morph.form in self.legal_terms:\n",
    "                tokens.append(morph.form)\n",
    "                continue\n",
    "            \n",
    "            # í’ˆì‚¬ íƒœê·¸ ê¸°ë°˜ í•„í„°ë§\n",
    "            # NNG: ì¼ë°˜ëª…ì‚¬, NNP: ê³ ìœ ëª…ì‚¬, NNB: ì˜ì¡´ëª…ì‚¬\n",
    "            # VV: ë™ì‚¬, VA: í˜•ìš©ì‚¬, MAG: ì¼ë°˜ë¶€ì‚¬\n",
    "            # SL: ì™¸êµ­ì–´, SH: í•œì, SN: ìˆ«ì\n",
    "            if morph.tag in ['NNG', 'NNP', 'NNB', 'VV', 'VA', 'MAG', 'SL', 'SH', 'SN']:\n",
    "                # ë¶ˆìš©ì–´ ì œê±° ë° ìµœì†Œ ê¸¸ì´ ì²´í¬\n",
    "                if morph.form not in self.stopwords and len(morph.form) > 1:\n",
    "                    tokens.append(morph.form)\n",
    "            \n",
    "            # ğŸ†• ë‹¨ë… ìˆ«ìë„ í¬í•¨ (ì¡°í•­ ë²ˆí˜¸ ë“±ì—ì„œ ì¤‘ìš”)\n",
    "            elif morph.tag == 'SN' and morph.form.isdigit():\n",
    "                tokens.append(morph.form)\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def _build_idf_cache(self):\n",
    "        \"\"\"ê° í† í°ì˜ IDF ê°’ì„ ë¯¸ë¦¬ ê³„ì‚°\"\"\"\n",
    "        self.idf_cache = {}\n",
    "        total_docs = len(self.tokenized_corpus)\n",
    "        \n",
    "        for token, idx in self.vocabulary.items():\n",
    "            doc_freq = sum(1 for doc in self.tokenized_corpus if token in doc)\n",
    "            idf = np.log((total_docs - doc_freq + 0.5) / (doc_freq + 0.5) + 1.0)\n",
    "            self.idf_cache[idx] = max(0.0, idf)\n",
    "    \n",
    "    def encode_query(self, query: str) -> Dict[int, float]:\n",
    "        \"\"\"ì¿¼ë¦¬ë¥¼ sparse vectorë¡œ ë³€í™˜\"\"\"\n",
    "        tokenized_query = self._tokenize(query)\n",
    "        \n",
    "        if not tokenized_query:\n",
    "            return {}\n",
    "        \n",
    "        token_freq = {}\n",
    "        for token in tokenized_query:\n",
    "            if token in self.vocabulary:\n",
    "                token_freq[token] = token_freq.get(token, 0) + 1\n",
    "        \n",
    "        if not token_freq:\n",
    "            return {}\n",
    "        \n",
    "        sparse_vector = {}\n",
    "        for token, freq in token_freq.items():\n",
    "            idx = self.vocabulary[token]\n",
    "            idf = self.idf_cache.get(idx, 0.0)\n",
    "            \n",
    "            tf = freq / len(tokenized_query)\n",
    "            score = tf * idf\n",
    "            \n",
    "            if score > 0:\n",
    "                sparse_vector[idx] = float(score)\n",
    "        \n",
    "        return sparse_vector\n",
    "    \n",
    "    def encode_document(self, doc: str, doc_idx: int = None) -> Dict[int, float]:\n",
    "        \"\"\"ë¬¸ì„œë¥¼ sparse vectorë¡œ ë³€í™˜\"\"\"\n",
    "        tokens = self._tokenize(doc)\n",
    "        \n",
    "        if not tokens:\n",
    "            return {}\n",
    "        \n",
    "        tf = {}\n",
    "        for token in tokens:\n",
    "            if token in self.vocabulary:\n",
    "                idx = self.vocabulary[token]\n",
    "                tf[idx] = tf.get(idx, 0.0) + 1.0\n",
    "        \n",
    "        if not tf:\n",
    "            return {}\n",
    "        \n",
    "        max_tf = max(tf.values())\n",
    "        sparse_vector = {k: v / max_tf for k, v in tf.items()}\n",
    "        \n",
    "        return sparse_vector\n",
    "    \n",
    "    # ğŸ†• ë””ë²„ê¹… ë° ë¶„ì„ìš© ë©”ì„œë“œ\n",
    "    def analyze_tokenization(self, text: str) -> Dict:\n",
    "        \"\"\"\n",
    "        í† í°í™” ê²°ê³¼ ë¶„ì„ (ë””ë²„ê¹…ìš©)\n",
    "        \n",
    "        Returns:\n",
    "            {\n",
    "                'original': str,\n",
    "                'tokens': List[str],\n",
    "                'legal_entities': List[str],\n",
    "                'token_count': int,\n",
    "                'entity_count': int\n",
    "            }\n",
    "        \"\"\"\n",
    "        tokens = self._tokenize(text)\n",
    "        entities = self._extract_legal_entities(text)\n",
    "        \n",
    "        return {\n",
    "            'original': text,\n",
    "            'tokens': tokens,\n",
    "            'legal_entities': [e[0] for e in entities],\n",
    "            'token_count': len(tokens),\n",
    "            'entity_count': len(entities),\n",
    "            'vocabulary_coverage': sum(1 for t in tokens if t in self.vocabulary)\n",
    "        }\n",
    "    \n",
    "    # ğŸ†• ì¡°í•­ ì°¸ì¡° ì¶”ì¶œ (ë§í¬ ì¶”ì ìš©)\n",
    "    def extract_article_references(self, text: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        ì¡°í•­ ì°¸ì¡° ì •ë³´ ì¶”ì¶œ\n",
    "        \n",
    "        Returns:\n",
    "            [{'text': 'ì œ1ì¡°ì œ2í•­', 'article': '1', 'paragraph': '2', ...}, ...]\n",
    "        \"\"\"\n",
    "        references = []\n",
    "        \n",
    "        # ë³µí•© ì°¸ì¡° íŒ¨í„´\n",
    "        complex_pattern = re.compile(\n",
    "            r'ì œ\\s*(\\d+)\\s*ì¡°(?:ì˜\\s*(\\d+))?'\n",
    "            r'(?:ì œ\\s*(\\d+)\\s*í•­)?'\n",
    "            r'(?:ì œ\\s*(\\d+)\\s*í˜¸)?'\n",
    "        )\n",
    "        \n",
    "        for match in complex_pattern.finditer(text):\n",
    "            article = match.group(1)\n",
    "            sub_article = match.group(2)\n",
    "            paragraph = match.group(3)\n",
    "            item = match.group(4)\n",
    "            \n",
    "            ref = {\n",
    "                'text': re.sub(r'\\s+', '', match.group()),\n",
    "                'article': article,\n",
    "                'sub_article': sub_article,\n",
    "                'paragraph': paragraph,\n",
    "                'item': item,\n",
    "                'position': (match.start(), match.end())\n",
    "            }\n",
    "            references.append(ref)\n",
    "        \n",
    "        return references\n",
    "    \n",
    "    def save(self, filepath: str):\n",
    "        \"\"\"JSONìœ¼ë¡œ ì €ì¥\"\"\"\n",
    "        data = {\n",
    "            'tokenized_corpus': self.tokenized_corpus,\n",
    "            'vocabulary': self.vocabulary\n",
    "        }\n",
    "        \n",
    "        json_filepath = filepath.replace('.pkl', '.json')\n",
    "        with open(json_filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"ğŸ’¾ BM25 ì¸ì½”ë” ì €ì¥: {json_filepath}\")\n",
    "        return json_filepath\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filepath: str):\n",
    "        \"\"\"JSONì—ì„œ ë¡œë“œ\"\"\"\n",
    "        json_filepath = filepath.replace('.pkl', '.json')\n",
    "        \n",
    "        if not os.path.exists(json_filepath):\n",
    "            raise FileNotFoundError(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_filepath}\")\n",
    "        \n",
    "        with open(json_filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        print(f\"ğŸ“‚ BM25 ì¸ì½”ë” ë¡œë“œ: {json_filepath}\")\n",
    "        return KiwiBM25Encoder(load_from_dict=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ í´ë˜ìŠ¤\n",
    "# ============================================\n",
    "import time\n",
    "class HybridSearchEngine:\n",
    "    \"\"\"\n",
    "    Sparse (Kiwi BM25) + Dense (Clova) í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        clova_embedder,\n",
    "        client: QdrantClient,\n",
    "        collection_name: str = \"legal_docs_hybrid\",\n",
    "        bm25_encoder_file: str = \"kiwi_bm25_encoder.pkl\",\n",
    "        bm25_encoder: KiwiBM25Encoder = None  # ğŸ†• ì§ì ‘ ì „ë‹¬ ì˜µì…˜\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            clova_embedder: Clova ì„ë² ë”\n",
    "            client: Qdrant í´ë¼ì´ì–¸íŠ¸\n",
    "            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„\n",
    "            bm25_encoder_file: BM25 ì¸ì½”ë” ì €ì¥ íŒŒì¼\n",
    "            bm25_encoder: ì§ì ‘ ì „ë‹¬í•  BM25 ì¸ì½”ë” (ì˜µì…˜)\n",
    "        \"\"\"\n",
    "        self.clova_embedder = clova_embedder\n",
    "        self.client = client\n",
    "        self.collection_name = collection_name\n",
    "        self.bm25_encoder_file = bm25_encoder_file\n",
    "\n",
    "        # ğŸ†• BM25 ì¸ì½”ë” ì´ˆê¸°í™” ë¡œì§\n",
    "        if bm25_encoder is not None:\n",
    "            # ì§ì ‘ ì „ë‹¬ëœ ê²½ìš°\n",
    "            self.bm25_encoder = bm25_encoder\n",
    "            print(\"âœ… BM25 ì¸ì½”ë” ì§ì ‘ ì „ë‹¬ë¨\")\n",
    "        else:\n",
    "            # íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„\n",
    "            self.bm25_encoder = self._load_or_create_bm25_encoder()\n",
    "        print(\"ğŸ”§ HybridSearchEngine ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "    \n",
    "    def _load_or_create_bm25_encoder(self):\n",
    "        \"\"\"\n",
    "        BM25 ì¸ì½”ë” ë¡œë“œ ë˜ëŠ” ìƒì„±\n",
    "        \n",
    "        Returns:\n",
    "            KiwiBM25Encoder ì¸ìŠ¤í„´ìŠ¤\n",
    "        \"\"\"\n",
    "        json_file = self.bm25_encoder_file.replace('.pkl', '.json')\n",
    "        \n",
    "        # 1. ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ ì‹œë„\n",
    "        if os.path.exists(json_file):\n",
    "            try:\n",
    "                print(f\"ğŸ“‚ BM25 ì¸ì½”ë” ë¡œë“œ ì¤‘: {json_file}\")\n",
    "                encoder = KiwiBM25Encoder.load(self.bm25_encoder_file)\n",
    "                print(f\"âœ… BM25 ì¸ì½”ë” ë¡œë“œ ì™„ë£Œ (Vocabulary: {len(encoder.vocabulary)})\")\n",
    "                return encoder\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸  BM25 ì¸ì½”ë” ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "                print(\"   Qdrantì—ì„œ ë¬¸ì„œë¥¼ ê°€ì ¸ì™€ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "        # 2. íŒŒì¼ì´ ì—†ê±°ë‚˜ ë¡œë“œ ì‹¤íŒ¨ ì‹œ Qdrantì—ì„œ ë¬¸ì„œ ê°€ì ¸ì™€ì„œ ìƒì„±\n",
    "        print(f\"ğŸ”¨ Qdrant ì»¬ë ‰ì…˜ '{self.collection_name}'ì—ì„œ ë¬¸ì„œ ë¡œë“œ ì¤‘...\")\n",
    "        \n",
    "        try:\n",
    "            documents = self._load_documents_from_qdrant()\n",
    "            \n",
    "            if not documents:\n",
    "                raise ValueError(\n",
    "                    f\"ì»¬ë ‰ì…˜ '{self.collection_name}'ì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. \"\n",
    "                    \"ë¨¼ì € index()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\"\n",
    "                )\n",
    "            \n",
    "            print(f\"ğŸ“š {len(documents)}ê°œ ë¬¸ì„œë¡œ BM25 ì¸ì½”ë” ìƒì„± ì¤‘...\")\n",
    "            encoder = KiwiBM25Encoder(documents=documents)\n",
    "            \n",
    "            # ì €ì¥\n",
    "            encoder.save(self.bm25_encoder_file)\n",
    "            print(f\"ğŸ’¾ BM25 ì¸ì½”ë” ì €ì¥: {json_file}\")\n",
    "            \n",
    "            return encoder\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                f\"BM25 ì¸ì½”ë” ìƒì„± ì‹¤íŒ¨: {e}\\n\"\n",
    "                f\"í•´ê²° ë°©ë²•:\\n\"\n",
    "                f\"1. ë¨¼ì € search_engine.index(documents)ë¥¼ ì‹¤í–‰í•˜ê±°ë‚˜\\n\"\n",
    "                f\"2. bm25_encoderë¥¼ ì§ì ‘ ìƒì„±í•˜ì—¬ ì „ë‹¬í•˜ì„¸ìš”.\"\n",
    "            )\n",
    "\n",
    "    def _load_documents_from_qdrant(self, batch_size: int = 100) -> List[str]:\n",
    "        \"\"\"\n",
    "        Qdrantì—ì„œ ëª¨ë“  ë¬¸ì„œì˜ page_content ë¡œë“œ\n",
    "        \n",
    "        Args:\n",
    "            batch_size: í•œ ë²ˆì— ê°€ì ¸ì˜¬ ë¬¸ì„œ ìˆ˜\n",
    "            \n",
    "        Returns:\n",
    "            page_content ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        documents = []\n",
    "        offset = None\n",
    "        \n",
    "        print(\"  ë¬¸ì„œ ë¡œë“œ ì¤‘...\", end='')\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                response = self.client.scroll(\n",
    "                    collection_name=self.collection_name,\n",
    "                    limit=batch_size,\n",
    "                    offset=offset,\n",
    "                    with_payload=True,\n",
    "                    with_vectors=False  # ë²¡í„°ëŠ” í•„ìš” ì—†ìŒ\n",
    "                )\n",
    "                \n",
    "                points, offset = response\n",
    "\n",
    "                for point in points:\n",
    "                    if 'page_content' in point.payload:\n",
    "                        documents.append(point.payload['page_content'])\n",
    "                \n",
    "                print(f\"\\r  ë¬¸ì„œ ë¡œë“œ ì¤‘... {len(documents)}ê°œ\", end='')\n",
    "                \n",
    "                if offset is None:\n",
    "                    break\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"\\nâš ï¸  ë¬¸ì„œ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "                break\n",
    "        \n",
    "        print(f\"\\n  âœ… ì´ {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\")\n",
    "        return documents\n",
    "    \n",
    "\n",
    "    def index(self, documents: List[Document], force_rebuild: bool = False):\n",
    "        \"\"\"\n",
    "        ë¬¸ì„œ ì¸ë±ì‹±\n",
    "        \n",
    "        Args:\n",
    "            documents: ì¸ë±ì‹±í•  Document ë¦¬ìŠ¤íŠ¸\n",
    "            force_rebuild: Trueë©´ ê°•ì œë¡œ ì¬ìƒì„±\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ì¸ë±ì‹± ì‹œì‘\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # ========================================\n",
    "        # 1ë‹¨ê³„: BM25 ì¸ì½”ë” ì¤€ë¹„\n",
    "        # ========================================\n",
    "        print(\"\\n1ï¸âƒ£ Kiwi BM25 ì¸ì½”ë” ì¤€ë¹„ ì¤‘...\")\n",
    "        \n",
    "        corpus = [doc.page_content for doc in documents]\n",
    "        json_file = self.bm25_encoder_file.replace('.pkl', '.json')\n",
    "        \n",
    "        if os.path.exists(json_file) and not force_rebuild:\n",
    "            print(\"  ğŸ“‚ ê¸°ì¡´ BM25 ì¸ì½”ë” ë¡œë“œ\")\n",
    "            self.bm25_encoder = KiwiBM25Encoder.load(self.bm25_encoder_file)\n",
    "        else:\n",
    "            print(\"  ğŸ†• ìƒˆ BM25 ì¸ì½”ë” ìƒì„±\")\n",
    "            self.bm25_encoder = KiwiBM25Encoder(corpus)\n",
    "            self.bm25_encoder.save(self.bm25_encoder_file)\n",
    "        \n",
    "        # ========================================\n",
    "        # 2ë‹¨ê³„: Qdrant ì»¬ë ‰ì…˜ ìƒì„±\n",
    "        # ========================================\n",
    "        print(f\"\\n2ï¸âƒ£ Qdrant ì»¬ë ‰ì…˜ '{self.collection_name}' ìƒì„± ì¤‘...\")\n",
    "        \n",
    "        try:\n",
    "            self.client.delete_collection(self.collection_name)\n",
    "            print(\"  ğŸ—‘ï¸  ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        self.client.create_collection(\n",
    "            collection_name=self.collection_name,\n",
    "            vectors_config={\n",
    "                \"dense\": VectorParams(size=1024, distance=Distance.COSINE)\n",
    "            },\n",
    "            sparse_vectors_config={\n",
    "                \"sparse\": SparseVectorParams(\n",
    "                    index=SparseIndexParams(on_disk=False)\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "        print(\"  âœ… ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ\")\n",
    "        \n",
    "        # ========================================\n",
    "        # 3ë‹¨ê³„: ë¬¸ì„œ ì¸ë±ì‹±\n",
    "        # ========================================\n",
    "        print(f\"\\n3ï¸âƒ£ {len(documents)}ê°œ ë¬¸ì„œ ì¸ë±ì‹± ì¤‘...\")\n",
    "        print(\"    (ê° ë¬¸ì„œ: Clova ì„ë² ë”© â†’ Kiwi BM25 â†’ Qdrant ì €ì¥)\")\n",
    "        \n",
    "        points = []\n",
    "        batch_size = 50\n",
    "        \n",
    "        for idx, doc in enumerate(tqdm(documents, desc=\"ì¸ë±ì‹±\")):\n",
    "            # Dense ì„ë² ë”© (Clova - API í˜¸ì¶œ)\n",
    "            dense_vector = self.clova_embedder.embed_query(doc.page_content)\n",
    "            time.sleep(1)\n",
    "            # Sparse ì„ë² ë”© (Kiwi - ë¡œì»¬)\n",
    "            sparse_vector = self.bm25_encoder.encode_document(doc.page_content)\n",
    "            \n",
    "            if sparse_vector:\n",
    "                sparse_vec = SparseVector(\n",
    "                    indices=list(sparse_vector.keys()),\n",
    "                    values=list(sparse_vector.values())\n",
    "                )\n",
    "            else:\n",
    "                sparse_vec = SparseVector(indices=[], values=[])\n",
    "            \n",
    "            point = PointStruct(\n",
    "                id=idx,\n",
    "                vector={\n",
    "                    \"dense\": dense_vector,\n",
    "                    \"sparse\": sparse_vec\n",
    "                },\n",
    "                payload={\n",
    "                    \"page_content\": doc.page_content,\n",
    "                    \"metadata\": doc.metadata,\n",
    "                    \"doc_id\": doc.id\n",
    "                }\n",
    "            )\n",
    "            points.append(point)\n",
    "            \n",
    "            if len(points) >= batch_size:\n",
    "                self.client.upsert(collection_name=self.collection_name, points=points)\n",
    "                points = []\n",
    "        \n",
    "        if points:\n",
    "            self.client.upsert(collection_name=self.collection_name, points=points)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(\"âœ… ì¸ë±ì‹± ì™„ë£Œ!\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"ğŸ“Š í†µê³„:\")\n",
    "        print(f\"  - ë¬¸ì„œ ìˆ˜: {len(documents)}ê°œ\")\n",
    "        print(f\"  - Vocabulary: {len(self.bm25_encoder.vocabulary)}ê°œ\")\n",
    "        print(f\"  - ì»¬ë ‰ì…˜: {self.collection_name}\")\n",
    "        print(\"=\"*80)\n",
    "    \n",
    "    def search(\n",
    "        self,\n",
    "        query: str,\n",
    "        top_k: int = 5,\n",
    "        dense_weight: float = 0.7,\n",
    "        sparse_weight: float = 0.3,\n",
    "        verbose: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰\n",
    "        \n",
    "        Args:\n",
    "            query: ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜\n",
    "            dense_weight: Dense ê°€ì¤‘ì¹˜\n",
    "            sparse_weight: Sparse ê°€ì¤‘ì¹˜\n",
    "            verbose: ìƒì„¸ ì •ë³´ ì¶œë ¥\n",
    "        \n",
    "        Returns:\n",
    "            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        # ğŸ†• BM25 ì¸ì½”ë” í™•ì¸ (lazy loading)\n",
    "        if self.bm25_encoder is None:\n",
    "            print(\"âš ï¸  BM25 ì¸ì½”ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒì„± ì¤‘...\")\n",
    "            self.bm25_encoder = self._load_or_create_bm25_encoder()\n",
    "            \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'\")\n",
    "            print(f\"{'='*80}\")\n",
    "        \n",
    "        # ========================================\n",
    "        # 1ë‹¨ê³„: Dense ì¿¼ë¦¬ ë²¡í„° (Clova)\n",
    "        # ========================================\n",
    "        if verbose:\n",
    "            print(\"\\n1ï¸âƒ£ Dense ë²¡í„° ìƒì„± (Clova)...\")\n",
    "        \n",
    "        dense_query = self.clova_embedder.embed_query(query)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  âœ… Dense ë²¡í„°: {len(dense_query)} ì°¨ì›\")\n",
    "        \n",
    "        # ========================================\n",
    "        # 2ë‹¨ê³„: Sparse ì¿¼ë¦¬ ë²¡í„° (Kiwi BM25)\n",
    "        # ========================================\n",
    "        if verbose:\n",
    "            print(\"\\n2ï¸âƒ£ Sparse ë²¡í„° ìƒì„± (Kiwi BM25)...\")\n",
    "        \n",
    "        sparse_query = self.bm25_encoder.encode_query(query)\n",
    "        \n",
    "        if verbose:\n",
    "            tokens = self.bm25_encoder._tokenize(query)\n",
    "            print(f\"  ğŸ“ í˜•íƒœì†Œ: {tokens}\")\n",
    "            print(f\"  âœ… Sparse ë²¡í„°: {len(sparse_query)} ê°œ (non-zero)\")\n",
    "        \n",
    "        # ========================================\n",
    "        # 3ë‹¨ê³„: Dense ê²€ìƒ‰\n",
    "        # ========================================\n",
    "        if verbose:\n",
    "            print(f\"\\n3ï¸âƒ£ Dense ê²€ìƒ‰ (ê°€ì¤‘ì¹˜: {dense_weight})...\")\n",
    "        \n",
    "        dense_results = self.client.search(\n",
    "            collection_name=self.collection_name,\n",
    "            query_vector=NamedVector(name=\"dense\", vector=dense_query),\n",
    "            limit=top_k * 3,\n",
    "            with_payload=True\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  âœ… {len(dense_results)}ê°œ ê²°ê³¼\")\n",
    "        \n",
    "        # ========================================\n",
    "        # 4ë‹¨ê³„: Sparse ê²€ìƒ‰\n",
    "        # ========================================\n",
    "        if sparse_query:\n",
    "            if verbose:\n",
    "                print(f\"\\n4ï¸âƒ£ Sparse ê²€ìƒ‰ (ê°€ì¤‘ì¹˜: {sparse_weight})...\")\n",
    "            \n",
    "            sparse_query_vec = NamedSparseVector(\n",
    "                name=\"sparse\",\n",
    "                vector=SparseVector(\n",
    "                    indices=list(sparse_query.keys()),\n",
    "                    values=list(sparse_query.values())\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            sparse_results = self.client.search(\n",
    "                collection_name=self.collection_name,\n",
    "                query_vector=sparse_query_vec,\n",
    "                limit=top_k * 3,\n",
    "                with_payload=True\n",
    "            )\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  âœ… {len(sparse_results)}ê°œ ê²°ê³¼\")\n",
    "        else:\n",
    "            sparse_results = []\n",
    "            if verbose:\n",
    "                print(f\"\\n4ï¸âƒ£ Sparse ê²€ìƒ‰ ê±´ë„ˆëœ€ (ìœ íš¨ í† í° ì—†ìŒ)\")\n",
    "        \n",
    "        # ========================================\n",
    "        # 5ë‹¨ê³„: RRFë¡œ ê²°ê³¼ ê²°í•©\n",
    "        # ========================================\n",
    "        if verbose:\n",
    "            print(f\"\\n5ï¸âƒ£ RRFë¡œ ê²°ê³¼ ê²°í•©...\")\n",
    "        \n",
    "        rrf_scores = {}\n",
    "        k = 10\n",
    "        \n",
    "        for rank, point in enumerate(dense_results, 1):\n",
    "            rrf_scores[point.id] = rrf_scores.get(point.id, 0) + (dense_weight / (k + rank))\n",
    "        \n",
    "        for rank, point in enumerate(sparse_results, 1):\n",
    "            rrf_scores[point.id] = rrf_scores.get(point.id, 0) + (sparse_weight / (k + rank))\n",
    "        \n",
    "        sorted_ids = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        \n",
    "        if not sorted_ids:\n",
    "            if verbose:\n",
    "                print(\"  âš ï¸  ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\")\n",
    "            return []\n",
    "        \n",
    "        result_ids = [id for id, _ in sorted_ids]\n",
    "        final_results = self.client.retrieve(\n",
    "            collection_name=self.collection_name,\n",
    "            ids=result_ids,\n",
    "            with_payload=True\n",
    "        )\n",
    "        \n",
    "        score_map = dict(sorted_ids)\n",
    "        results_with_scores = []\n",
    "\n",
    "        for point in final_results:\n",
    "            result_dict = {\n",
    "                'id': point.id,\n",
    "                'score': score_map[point.id],\n",
    "                'payload': point.payload\n",
    "            }\n",
    "            results_with_scores.append(result_dict)\n",
    "\n",
    "        # score ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "        results_with_scores.sort(key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"  âœ… ìµœì¢… {len(results_with_scores)}ê°œ ê²°ê³¼\")\n",
    "            print(f\"{'='*80}\")\n",
    "\n",
    "        return results_with_scores \n",
    "    \n",
    "    def print_results(self, results, top_n: int = None):\n",
    "        \"\"\"ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\"\"\"\n",
    "        if top_n:\n",
    "            results = results[:top_n]\n",
    "        \n",
    "        if not results:\n",
    "            print(\"\\nâŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼ (Top {len(results)}):\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n{i}. Score: {result['score']:.4f}\")\n",
    "            print(f\"   Document ID: {result['payload']['doc_id']}\")\n",
    "            print(f\"   ì§€ìì²´: {result['payload']['metadata'].get('ì§€ìì²´ê¸°ê´€ëª…', 'N/A')}\")\n",
    "            print(f\"   ë²•ê·œëª…: {result['payload']['metadata'].get('ìì¹˜ë²•ê·œëª…', 'N/A')}\")\n",
    "            \n",
    "            links = result['payload']['metadata'].get('links', [])\n",
    "            if links and links[0]:\n",
    "                print(f\"   ê´€ë ¨ ë²•ë ¹: {', '.join(list(links[0].keys())[:3])}\")\n",
    "            \n",
    "            print(f\"   ë‚´ìš©: {result['payload']['page_content'][:200]}...\")\n",
    "            print(\"-\"*80)\n",
    "    \n",
    "    def compare_weights(self, query: str, top_k: int = 3):\n",
    "        \"\"\"ë‹¤ì–‘í•œ ê°€ì¤‘ì¹˜ë¡œ ê²€ìƒ‰ ê²°ê³¼ ë¹„êµ\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"âš–ï¸  ê°€ì¤‘ì¹˜ ë¹„êµ: '{query}'\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        weight_combinations = [\n",
    "            (1.0, 0.0, \"Dense only\"),\n",
    "            (0.0, 1.0, \"Sparse only\"),\n",
    "            (0.8, 0.2, \"Dense ìš°ì„ \"),\n",
    "            (0.7, 0.3, \"Dense ì¤‘ì‹¬\"),\n",
    "            (0.5, 0.5, \"ê· í˜•\"),\n",
    "            (0.3, 0.7, \"Sparse ì¤‘ì‹¬\"),\n",
    "        ]\n",
    "        \n",
    "        for dense_w, sparse_w, desc in weight_combinations:\n",
    "            print(f\"\\n{desc} (D:{dense_w}, S:{sparse_w})\")\n",
    "            results = self.search(\n",
    "                query=query,\n",
    "                top_k=top_k,\n",
    "                dense_weight=dense_w,\n",
    "                sparse_weight=sparse_w,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            for i, result in enumerate(results, 1):\n",
    "                print(f\"  {i}. {result['score']:.4f} | {result['payload']['doc_id']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# 3. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n",
    "# ============================================\n",
    "\n",
    "def load_documents_from_jsonl(file_path: str) -> List[Document]:\n",
    "    \"\"\"JSONL íŒŒì¼ì—ì„œ Document ë¡œë“œ\"\"\"\n",
    "    documents = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            data = json.loads(line)\n",
    "            doc = Document(\n",
    "                page_content=data[\"page_content\"],\n",
    "                metadata=data[\"metadata\"],\n",
    "                id=data[\"id\"]\n",
    "            )\n",
    "            documents.append(doc)\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ ì‹œì‘\n",
      "================================================================================\n",
      "\n",
      "ğŸ“š ë¬¸ì„œ ë¡œë“œ ì¤‘...\n",
      "âœ… 1285ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\n",
      "\n",
      "ğŸ¤– Clova ì„ë² ë” ì´ˆê¸°í™”...\n",
      "âœ… Clova ì´ˆê¸°í™” ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ì´ˆê¸°í™”\n",
    "# ========================================\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ ì‹œì‘\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. ë¬¸ì„œ ë¡œë“œ\n",
    "print(\"\\nğŸ“š ë¬¸ì„œ ë¡œë“œ ì¤‘...\")\n",
    "documents = load_documents_from_jsonl(\"documents/local/documents_merged.jsonl\")\n",
    "print(f\"âœ… {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "# 2. Clova ì„ë² ë”\n",
    "print(\"\\nğŸ¤– Clova ì„ë² ë” ì´ˆê¸°í™”...\")\n",
    "clova_embedder = ClovaXEmbeddings(\n",
    "    model=\"bge-m3\",\n",
    "    api_key=os.getenv(\"CLOVASTUDIO_API_KEY\")\n",
    ")\n",
    "print(\"âœ… Clova ì´ˆê¸°í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“¦ Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”...\n",
      "âœ… Qdrant ì´ˆê¸°í™” ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# 3. Qdrant í´ë¼ì´ì–¸íŠ¸\n",
    "print(\"\\nğŸ“¦ Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”...\")\n",
    "client = QdrantClient(\n",
    "    url=QDRANT_URL, \n",
    "    api_key=QDRANT_api_key,\n",
    ")\n",
    "print(\"âœ… Qdrant ì´ˆê¸°í™” ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ ê²€ìƒ‰ ì—”ì§„ ìƒì„±...\n",
      "ğŸ“‚ BM25 ì¸ì½”ë” ë¡œë“œ ì¤‘: kiwi_bm25_encoder.json\n",
      "ğŸ“‚ BM25 ì¸ì½”ë” ë¡œë“œ: kiwi_bm25_encoder.json\n",
      "âœ… BM25 ì¸ì½”ë” ë¡œë“œ ì™„ë£Œ (Vocabulary: 2396)\n",
      "âœ… BM25 ì¸ì½”ë” ë¡œë“œ ì™„ë£Œ (Vocabulary: 2396)\n",
      "ğŸ”§ HybridSearchEngine ì´ˆê¸°í™” ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# 4. ê²€ìƒ‰ ì—”ì§„ ìƒì„±\n",
    "print(\"\\nğŸ”§ ê²€ìƒ‰ ì—”ì§„ ìƒì„±...\")\n",
    "search_engine = HybridSearchEngine(\n",
    "    clova_embedder=clova_embedder,\n",
    "    client=client,\n",
    "    collection_name=\"docs_hybrid\",\n",
    "    bm25_encoder_file=\"kiwi_bm25_encoder.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = load_documents_from_jsonl(\"documents/local/documents_merged.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = documents[:110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ì¸ë±ì‹± ì‹œì‘\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£ Kiwi BM25 ì¸ì½”ë” ì¤€ë¹„ ì¤‘...\n",
      "  ğŸ“‚ ê¸°ì¡´ BM25 ì¸ì½”ë” ë¡œë“œ\n",
      "ğŸ“‚ BM25 ì¸ì½”ë” ë¡œë“œ: kiwi_bm25_encoder.json\n",
      "âœ… BM25 ì¸ì½”ë” ë¡œë“œ ì™„ë£Œ (Vocabulary: 2396)\n",
      "\n",
      "2ï¸âƒ£ Qdrant ì»¬ë ‰ì…˜ 'docs_hybrid' ìƒì„± ì¤‘...\n",
      "  ğŸ—‘ï¸  ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ\n",
      "  âœ… ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ\n",
      "\n",
      "3ï¸âƒ£ 110ê°œ ë¬¸ì„œ ì¸ë±ì‹± ì¤‘...\n",
      "    (ê° ë¬¸ì„œ: Clova ì„ë² ë”© â†’ Kiwi BM25 â†’ Qdrant ì €ì¥)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì¸ë±ì‹±: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 110/110 [02:23<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "âœ… ì¸ë±ì‹± ì™„ë£Œ!\n",
      "================================================================================\n",
      "ğŸ“Š í†µê³„:\n",
      "  - ë¬¸ì„œ ìˆ˜: 110ê°œ\n",
      "  - Vocabulary: 2396ê°œ\n",
      "  - ì»¬ë ‰ì…˜: docs_hybrid\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ì¸ë±ì‹±\n",
    "# ========================================\n",
    "# search_engine.index(documents, force_rebuild=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: 'ê±´ì¶•ë¬¼ ì œì„¤ ì œë¹™ ì±…ì„ì€ ëˆ„êµ¬ì—ê²Œ ìˆë‚˜ìš”?'\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£ Dense ë²¡í„° ìƒì„± (Clova)...\n",
      "  âœ… Dense ë²¡í„°: 1024 ì°¨ì›\n",
      "\n",
      "2ï¸âƒ£ Sparse ë²¡í„° ìƒì„± (Kiwi BM25)...\n",
      "  ğŸ“ í˜•íƒœì†Œ: ['ê±´ì¶•ë¬¼', 'ì œì„¤', 'ì œë¹™', 'ì±…ì„']\n",
      "  âœ… Sparse ë²¡í„°: 4 ê°œ (non-zero)\n",
      "\n",
      "3ï¸âƒ£ Dense ê²€ìƒ‰ (ê°€ì¤‘ì¹˜: 0.7)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/6fdvg69n75b6lgybytxszz8c0000gn/T/ipykernel_45757/1802878770.py:300: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  dense_results = self.client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… 15ê°œ ê²°ê³¼\n",
      "\n",
      "4ï¸âƒ£ Sparse ê²€ìƒ‰ (ê°€ì¤‘ì¹˜: 0.3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/6fdvg69n75b6lgybytxszz8c0000gn/T/ipykernel_45757/1802878770.py:325: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  sparse_results = self.client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… 15ê°œ ê²°ê³¼\n",
      "\n",
      "5ï¸âƒ£ RRFë¡œ ê²°ê³¼ ê²°í•©...\n",
      "  âœ… ìµœì¢… 5ê°œ ê²°ê³¼\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ (Top 3):\n",
      "================================================================================\n",
      "\n",
      "1. Score: 0.0886\n",
      "   Document ID: 2019610_chapter1_chunk2\n",
      "   ì§€ìì²´: ê²½ê¸°ë„ ê°€í‰êµ°\n",
      "   ë²•ê·œëª…: ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ ë° ì œë¹™ ì±…ì„ì— ê´€í•œ ì¡°ë¡€\n",
      "   ê´€ë ¨ ë²•ë ¹: Attachment\n",
      "   ë‚´ìš©: [ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ ë° ì œë¹™ ì±…ì„ì— ê´€í•œ ì¡°ë¡€]\n",
      "ì œ3ì¡°(ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ã†ì œë¹™ ì±…ì„) ê±´ì¶•ë¬¼ê´€ë¦¬ìëŠ” ê´€ë¦¬í•˜ê³  ìˆëŠ” ê±´ì¶•ë¬¼ì˜ ëŒ€ì§€ì— ì ‘í•œ ë³´ë„, ì´ë©´ë„ë¡œ, ë³´í–‰ìì „ìš©ë„ë¡œ, ì‹œì„¤ë¬¼ì˜ ì§€ë¶•ì— ëŒ€í•œ ì œì„¤ã†ì œë¹™ì‘ì—…ì„ í•˜ì—¬ì•¼ í•œë‹¤. <ì‹ ì„¤ 2017.7.31.>\n",
      "ì œ4ì¡°(ì œì„¤ã†ì œë¹™ì‘ì—…ì˜ ì±…ì„ìˆœìœ„) ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ã†ì œë¹™ ì±…ì„ìˆœìœ„ëŠ” ë‹¤ìŒ ê° ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Score: 0.0798\n",
      "   Document ID: 2019610_chapter1_chunk1\n",
      "   ì§€ìì²´: ê²½ê¸°ë„ ê°€í‰êµ°\n",
      "   ë²•ê·œëª…: ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ ë° ì œë¹™ ì±…ì„ì— ê´€í•œ ì¡°ë¡€\n",
      "   ê´€ë ¨ ë²•ë ¹: ìì—°ì¬í•´ëŒ€ì±…ë²•, ë„ë¡œë²•, ë†ì–´ì´Œë„ë¡œì •ë¹„ë²•\n",
      "   ë‚´ìš©: [ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ ë° ì œë¹™ ì±…ì„ì— ê´€í•œ ì¡°ë¡€]\n",
      "ì œ1ì¡°(ëª©ì ) ì´ ì¡°ë¡€ëŠ” ã€Œìì—°ì¬í•´ëŒ€ì±…ë²•ã€ ì œ27ì¡°ì œ2í•­ì˜ ê·œì •ì— ë”°ë¼ ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤Â·ì œë¹™ì— ê´€í•œ ì‚¬í•­ì„ êµ¬ì²´ì ìœ¼ë¡œ ì •í•¨ìœ¼ë¡œì¨ ëˆˆ ë˜ëŠ” ì–¼ìŒìœ¼ë¡œ ì¸í•œ ì£¼ë¯¼ì˜ ë¶ˆí¸ì„ ìµœì†Œí™”í•˜ê³ , ì•ˆì „ì„ ê¾€í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.\n",
      "ì œ2ì¡°(ì •ì˜) ì´ ì¡°ë¡€ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìš©ì–´ì˜ ëœ»ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. <ê°œì • ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Score: 0.0773\n",
      "   Document ID: 2019610_chapter1_chunk4\n",
      "   ì§€ìì²´: ê²½ê¸°ë„ ê°€í‰êµ°\n",
      "   ë²•ê·œëª…: ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ ë° ì œë¹™ ì±…ì„ì— ê´€í•œ ì¡°ë¡€\n",
      "   ë‚´ìš©: [ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ ë° ì œë¹™ ì±…ì„ì— ê´€í•œ ì¡°ë¡€]\n",
      "ì œ8ì¡°(ì œì„¤ã†ì œë¹™ì‘ì—…ì˜ ë„êµ¬ ë¹„ì¹˜ã†ê´€ë¦¬) ê±´ì¶•ë¬¼ê´€ë¦¬ìëŠ” ì œì„¤ã†ì œë¹™ì‘ì—…ì— í•„ìš”í•œ ì‘ì—…ë„êµ¬ë¥¼ ê±´ì¶•ë¬¼ ë‚´ì— ë§¤ë…„ 12ì›” 1ì¼ë¶€í„° ë‹¤ìŒí•´ 3ì›” 15ì¼ê¹Œì§€ ë¹„ì¹˜Â·ê´€ë¦¬í•˜ì—¬ì•¼ í•œë‹¤. <ê°œì • 2017.7.31.>\n",
      "ì œ9ì¡°(ì‹œí–‰ê·œì¹™) ì´ ì¡°ë¡€ì˜ ì‹œí–‰ì— í•„ìš”í•œ ì‚¬í•­ì€ ê·œì¹™ìœ¼ë¡œ ì •í•œë‹¤. <ê°œì • 2017....\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: 'ê±´ì¶•ë²• ì‹œí–‰ë ¹ ì œ5ì¡°'\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£ Dense ë²¡í„° ìƒì„± (Clova)...\n",
      "  âœ… Dense ë²¡í„°: 1024 ì°¨ì›\n",
      "\n",
      "2ï¸âƒ£ Sparse ë²¡í„° ìƒì„± (Kiwi BM25)...\n",
      "  ğŸ“ í˜•íƒœì†Œ: ['ì œ5ì¡°', 'ê±´ì¶•', 'ì‹œí–‰ë ¹']\n",
      "  âœ… Sparse ë²¡í„°: 2 ê°œ (non-zero)\n",
      "\n",
      "3ï¸âƒ£ Dense ê²€ìƒ‰ (ê°€ì¤‘ì¹˜: 0.7)...\n",
      "  âœ… 15ê°œ ê²°ê³¼\n",
      "\n",
      "4ï¸âƒ£ Sparse ê²€ìƒ‰ (ê°€ì¤‘ì¹˜: 0.3)...\n",
      "  âœ… 15ê°œ ê²°ê³¼\n",
      "\n",
      "5ï¸âƒ£ RRFë¡œ ê²°ê³¼ ê²°í•©...\n",
      "  âœ… ìµœì¢… 5ê°œ ê²°ê³¼\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ (Top 3):\n",
      "================================================================================\n",
      "\n",
      "1. Score: 0.0705\n",
      "   Document ID: 2019611_chapter1_chunk1\n",
      "   ì§€ìì²´: ê²½ê¸°ë„ ê°€í‰êµ°\n",
      "   ë²•ê·œëª…: ê°€í‰êµ° ê±´ì¶• ì¡°ë¡€\n",
      "   ê´€ë ¨ ë²•ë ¹: ê±´ì¶•ë²•, ê±´ì¶•ë²• ì‹œí–‰ë ¹, ê±´ì¶•ë²• ì‹œí–‰ê·œì¹™\n",
      "   ë‚´ìš©: [ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ê±´ì¶• ì¡°ë¡€]\n",
      "ì œ1ì¥ ì´ì¹™\n",
      "ì œ1ì¡°(ëª©ì ) ì´ ì¡°ë¡€ëŠ” ã€Œê±´ì¶•ë²•ã€,ã€Œê±´ì¶•ë²• ì‹œí–‰ë ¹ã€ë°ã€Œê±´ì¶•ë²• ì‹œí–‰ê·œì¹™ã€ì—ì„œ ì¡°ë¡€ë¡œ ì •í•˜ë„ë¡ ìœ„ì„ëœ ì‚¬í•­ê³¼ ê·¸ ì‹œí–‰ì— í•„ìš”í•œ ì‚¬í•­ì„ ì •í•¨ì„ ëª©ì ìœ¼ë¡œ í•œë‹¤.<ê°œì • 2014.4.18.>\n",
      "ì œ2ì¡°(ì ìš© ë²”ìœ„) ì´ ì¡°ë¡€ëŠ” ê°€í‰êµ°(ì´í•˜ â€œêµ°â€ì´ë¼ í•œë‹¤) í–‰ì •êµ¬ì—­ ì•ˆ ê±´ì¶•ë¬¼ ë° ê·¸ ëŒ€ì§€ì— ì ìš©í•œë‹¤.<ê°œì • 2014.4....\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Score: 0.0697\n",
      "   Document ID: 2019668_chapter5_chunk10\n",
      "   ì§€ìì²´: ê²½ê¸°ë„ ê°€í‰êµ°\n",
      "   ë²•ê·œëª…: ê°€í‰êµ° êµ°ê³„íš ì¡°ë¡€\n",
      "   ê´€ë ¨ ë²•ë ¹: êµ­í† ì˜ ê³„íš ë° ì´ìš©ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹, ê±´ì¶•ë²• ì‹œí–‰ë ¹, Attachment\n",
      "   ë‚´ìš©: [ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° êµ°ê³„íš ì¡°ë¡€]\n",
      "ì œ5ì¥ ì§€ì—­Â·ì§€êµ¬Â·êµ¬ì—­ ì•ˆì—ì„œì˜ ì œí•œ\n",
      "ì œ47ì¡°ì˜2(ë³µí•©ìš©ë„ì§€êµ¬ì—ì„œì˜ ê±´ì¶•ì œí•œ) ì˜ ì œ81ì¡°ì— ë”°ë¼ ë³µí•©ìš©ë„ì§€êµ¬ì—ì„œ ë‹¤ìŒ ê° í˜¸ì— í•´ë‹¹í•˜ëŠ” ê±´ì¶•ë¬¼ì„ ê±´ì¶•í•  ìˆ˜ ìˆë‹¤.1. ì¼ë°˜ì£¼ê±°ì§€ì—­: ì¤€ì£¼ê±°ì§€ì—­ì—ì„œ í—ˆìš©ë˜ëŠ” ê±´ì¶•ë¬¼. ë‹¤ë§Œ, ë‹¤ìŒ ê° ëª©ì˜ ê±´ì¶•ë¬¼ì€ ì œì™¸í•œë‹¤.ê°€. ã€Œê±´ì¶•ë²• ì‹œí–‰ë ¹ã€ ë³„í‘œ 1 ì œ4í˜¸ì˜ ì œ2ì¢… ê·¼ë¦°ìƒí™œì‹œì„¤ ì¤‘...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Score: 0.0687\n",
      "   Document ID: 2019668_chapter5_chunk9\n",
      "   ì§€ìì²´: ê²½ê¸°ë„ ê°€í‰êµ°\n",
      "   ë²•ê·œëª…: ê°€í‰êµ° êµ°ê³„íš ì¡°ë¡€\n",
      "   ê´€ë ¨ ë²•ë ¹: êµ­í† ì˜ ê³„íš ë° ì´ìš©ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹, Attachment\n",
      "   ë‚´ìš©: [ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° êµ°ê³„íš ì¡°ë¡€]\n",
      "ì œ5ì¥ ì§€ì—­Â·ì§€êµ¬Â·êµ¬ì—­ ì•ˆì—ì„œì˜ ì œí•œ\n",
      "ì œ47ì¡°(íŠ¹ì •ìš©ë„ì œí•œì§€êµ¬ ì•ˆì—ì„œì˜ ê±´ì¶•ì œí•œ) ì˜ ì œ80ì¡°ì— ë”°ë¼ íŠ¹ì •ìš©ë„ì œí•œì§€êµ¬ ì•ˆì—ì„œëŠ” ë‹¤ìŒ ê° í˜¸ì— í•´ë‹¹í•˜ëŠ” ê±´ì¶•ë¬¼ì„ ê±´ì¶•í•  ìˆ˜ ì—†ë‹¤. ë‹¤ë§Œ, êµ°ê³„íšìœ„ì›íšŒì˜ ìë¬¸ì„ ê±°ì¹œ ê²½ìš°ì—ëŠ” ê·¸ëŸ¬í•˜ì§€ ì•„ë‹ˆí•˜ë‹¤. <ê°œì • 2012.11.5><ê°œì • 2022.11.9.>1. ã€Œê±´ì¶•ë²• ì‹œí–‰ë ¹ã€ ë³„...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: 'ì§€ì—­ê±´ì¶•ë¬¼ê´€ë¦¬ì§€ì›ì„¼í„° ì„¤ì¹˜ ìš´ì˜'\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£ Dense ë²¡í„° ìƒì„± (Clova)...\n",
      "  âœ… Dense ë²¡í„°: 1024 ì°¨ì›\n",
      "\n",
      "2ï¸âƒ£ Sparse ë²¡í„° ìƒì„± (Kiwi BM25)...\n",
      "  ğŸ“ í˜•íƒœì†Œ: ['ì§€ì—­', 'ê±´ì¶•ë¬¼', 'ê´€ë¦¬', 'ì§€ì›', 'ì„¼í„°', 'ì„¤ì¹˜', 'ìš´ì˜']\n",
      "  âœ… Sparse ë²¡í„°: 7 ê°œ (non-zero)\n",
      "\n",
      "3ï¸âƒ£ Dense ê²€ìƒ‰ (ê°€ì¤‘ì¹˜: 0.7)...\n",
      "  âœ… 15ê°œ ê²°ê³¼\n",
      "\n",
      "4ï¸âƒ£ Sparse ê²€ìƒ‰ (ê°€ì¤‘ì¹˜: 0.3)...\n",
      "  âœ… 15ê°œ ê²°ê³¼\n",
      "\n",
      "5ï¸âƒ£ RRFë¡œ ê²°ê³¼ ê²°í•©...\n",
      "  âœ… ìµœì¢… 5ê°œ ê²°ê³¼\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ (Top 3):\n",
      "================================================================================\n",
      "\n",
      "1. Score: 0.0886\n",
      "   Document ID: 2019611_chapter7_chunk4\n",
      "   ì§€ìì²´: ê²½ê¸°ë„ ê°€í‰êµ°\n",
      "   ë²•ê·œëª…: ê°€í‰êµ° ê±´ì¶• ì¡°ë¡€\n",
      "   ê´€ë ¨ ë²•ë ¹: ê±´ì¶•ë²•, ê±´ì¶•ë²• ì‹œí–‰ë ¹, ê±´ì¶•ë¬¼ê´€ë¦¬ë²•\n",
      "   ë‚´ìš©: [ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ê±´ì¶• ì¡°ë¡€]\n",
      "ì œ7ì¥ ë³´ì¹™\n",
      "ì œ37ì¡°(ì§€ì—­ê±´ì¶•ì•ˆì „ì„¼í„°ì˜ ì„¤ì¹˜Â·ìš´ì˜)â‘  êµ°ìˆ˜ëŠ” ë²• ì œ87ì¡°ì˜2ì— ë”°ë¼ ê±´ì¶•ë¬¼ ì•ˆì „ì— ê´€í•œ ê¸°ìˆ ì  ê²€í† ì™€ ê³µì‚¬ì¥ ë° ë¯¼ê°„ ê±´ì¶•ë¬¼ì˜ ì•ˆì „ê´€ë¦¬ë¥¼ ìœ„í•˜ì—¬ ì§€ì—­ê±´ì¶•ì•ˆì „ì„¼í„°(ì´í•˜ â€œê±´ì¶•ì•ˆì „ì„¼í„°â€ë¼ í•œë‹¤)ë¥¼ ì„¤ì¹˜í•˜ì—¬ ìš´ì˜í•  ìˆ˜ ìˆë‹¤.â‘¡ ì˜ ì œ119ì¡°ì˜3ì— ë”°ë¥¸ ê±´ì¶•ì•ˆì „ì„¼í„°ì˜ ì—…ë¬´ëŠ” ë‹¤ìŒ ê° í˜¸ì™€ ê°™ë‹¤.1. ê±´ì¶•ë¶„ì•¼ì˜...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Score: 0.0856\n",
      "   Document ID: 2205553_chapter1_chunk6\n",
      "   ì§€ìì²´: ê²½ê¸°ë„ ê°€í‰êµ°\n",
      "   ë²•ê·œëª…: ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ ì¡°ë¡€\n",
      "   ê´€ë ¨ ë²•ë ¹: ê±´ì¶•ë¬¼ê´€ë¦¬ë²• ì‹œí–‰ë ¹, ê±´ì¶•ë¬¼ê´€ë¦¬ë²•\n",
      "   ë‚´ìš©: [ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ ì¡°ë¡€]\n",
      "ì œ11ì¡°(ê±´ì¶•ë¬¼ í•´ì²´ê³µì‚¬ê°ë¦¬ìì˜ êµì²´) ì˜ ì œ23ì¡°ì œ4í˜¸ì— ë”°ë¥¸ ê°ë¦¬ì êµì²´ ëŒ€ìƒì„ â€œì¡°ë¡€ë¡œ ì •í•˜ëŠ” ê²½ìš°â€ëŠ” ë‹¤ìŒ ê° í˜¸ì™€ ê°™ë‹¤.1. í•´ì²´ê³µì‚¬ê°ë¦¬ìê°€ ê°ë¦¬ì™€ ê´€ë ¨í•˜ì—¬ ê´€ë¦¬ì ë“±ì—ê²Œ ê³„ì•½í•œ ëŒ€ê°€ ì´ì™¸ì˜ ê¸ˆí’ˆì„ ìš”êµ¬ ë˜ëŠ” ìˆ˜ìˆ˜í•˜ëŠ” ê²½ìš°2. í•´ì²´ê³µì‚¬ê°ë¦¬ìì˜ ì§ë¬´íƒœë§Œã†í’ˆìœ„ì†ìƒ ë° ê·¸ ë°–ì˜ ì‚¬ìœ ë¡œ í•´ì²´ê³µì‚¬ê°ë¦¬ìë¡œ ì í•©í•˜ì§€...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Score: 0.0705\n",
      "   Document ID: 2169395_chapter1_chunk3\n",
      "   ì§€ìì²´: ê²½ê¸°ë„ ê°€í‰êµ°\n",
      "   ë²•ê·œëª…: ê°€í‰êµ° ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì› ì¡°ë¡€\n",
      "   ê´€ë ¨ ë²•ë ¹: ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ë²•, ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ë²• ì‹œí–‰ë ¹, Attachment\n",
      "   ë‚´ìš©: [ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì› ì¡°ë¡€]\n",
      "ì œ5ì¡°(ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì‹œë²”ì‚¬ì—… ì‹¤ì‹œ) êµ°ìˆ˜ëŠ” ë²• ì œ24ì¡°ì— ë”°ë¼ ë…¹ìƒ‰ê±´ì¶•ë¬¼ì— ëŒ€í•œ ì£¼ë¯¼ì˜ ì¸ì‹ì„ ë†’ì´ê³  ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„±ì˜ ì´‰ì§„ì„ ìœ„í•˜ì—¬ ë‹¤ìŒ ê° í˜¸ì˜ ì‚¬ì—…ì„ ì‹œë²”ì‚¬ì—…ìœ¼ë¡œ ì§€ì •í•  ìˆ˜ ìˆë‹¤.1. ê³µê³µê¸°ê´€ì´ ì‹œí–‰í•˜ëŠ” ì‚¬ì—…2. ê¸°ì¡´ì£¼íƒì„ ë…¹ìƒ‰ê±´ì¶•ë¬¼ë¡œ ì „í™˜í•˜ëŠ” ì‚¬ì—…3. ê¸°ì¡´ ì£¼íƒ ì™¸ì˜ ê±´ì¶•ë¬¼ì„ ë…¹ìƒ‰ê±´ì¶•ë¬¼ë¡œ ì „...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      "âš–ï¸  ê°€ì¤‘ì¹˜ ë¹„êµ í…ŒìŠ¤íŠ¸\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "âš–ï¸  ê°€ì¤‘ì¹˜ ë¹„êµ: 'ê±´ì¶•ë¬¼ ì œì„¤ ì±…ì„'\n",
      "================================================================================\n",
      "\n",
      "Dense only (D:1.0, S:0.0)\n",
      "  1. 0.0909 | 2019610_chapter1_chunk2\n",
      "  2. 0.0833 | 2019610_chapter1_chunk1\n",
      "  3. 0.0769 | 2019610_chapter1_chunk4\n",
      "\n",
      "Sparse only (D:0.0, S:1.0)\n",
      "  1. 0.0909 | 2019610_chapter1_chunk4\n",
      "  2. 0.0833 | 2019610_chapter1_chunk3\n",
      "  3. 0.0769 | 2019610_chapter1_chunk2\n",
      "\n",
      "Dense ìš°ì„  (D:0.8, S:0.2)\n",
      "  1. 0.0881 | 2019610_chapter1_chunk2\n",
      "  2. 0.0810 | 2019610_chapter1_chunk1\n",
      "  3. 0.0797 | 2019610_chapter1_chunk4\n",
      "\n",
      "Dense ì¤‘ì‹¬ (D:0.7, S:0.3)\n",
      "  1. 0.0867 | 2019610_chapter1_chunk2\n",
      "  2. 0.0811 | 2019610_chapter1_chunk4\n",
      "  3. 0.0798 | 2019610_chapter1_chunk1\n",
      "\n",
      "ê· í˜• (D:0.5, S:0.5)\n",
      "  1. 0.0839 | 2019610_chapter1_chunk2\n",
      "  2. 0.0839 | 2019610_chapter1_chunk4\n",
      "  3. 0.0774 | 2019610_chapter1_chunk1\n",
      "\n",
      "Sparse ì¤‘ì‹¬ (D:0.3, S:0.7)\n",
      "  1. 0.0867 | 2019610_chapter1_chunk4\n",
      "  2. 0.0811 | 2019610_chapter1_chunk2\n",
      "  3. 0.0798 | 2019610_chapter1_chunk3\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ” ê²€ìƒ‰ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "test_queries = [\n",
    "    \"ê±´ì¶•ë¬¼ ì œì„¤ ì œë¹™ ì±…ì„ì€ ëˆ„êµ¬ì—ê²Œ ìˆë‚˜ìš”?\",\n",
    "    \"ê±´ì¶•ë²• ì‹œí–‰ë ¹ ì œ5ì¡°\",\n",
    "    \"ì§€ì—­ê±´ì¶•ë¬¼ê´€ë¦¬ì§€ì›ì„¼í„° ì„¤ì¹˜ ìš´ì˜\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    results = search_engine.search(\n",
    "        query=query,\n",
    "        top_k=5,\n",
    "        dense_weight=0.7,\n",
    "        sparse_weight=0.3\n",
    "    )\n",
    "    \n",
    "    search_engine.print_results(results, top_n=3)\n",
    "\n",
    "# ========================================\n",
    "# ê°€ì¤‘ì¹˜ ë¹„êµ (ì„ íƒ)\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âš–ï¸  ê°€ì¤‘ì¹˜ ë¹„êµ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "search_engine.compare_weights(\n",
    "    query=\"ê±´ì¶•ë¬¼ ì œì„¤ ì±…ì„\",\n",
    "    top_k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# ê°€ì¤‘ì¹˜ ë¹„êµ (ì„ íƒ)\n",
    "# ========================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âš–ï¸  ê°€ì¤‘ì¹˜ ë¹„êµ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "search_engine.compare_weights(\n",
    "    query=\"ê±´ì¶•ë¬¼ ì œì„¤ ì±…ì„\",\n",
    "    top_k=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë°ì´í„° ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "from rank_bm25 import BM25Okapi\n",
    "from typing import List, Dict\n",
    "from tqdm import tqdm\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import (\n",
    "    Distance, \n",
    "    VectorParams, \n",
    "    SparseVectorParams,\n",
    "    SparseIndexParams,\n",
    "    PointStruct,\n",
    "    SparseVector,\n",
    "    NamedVector,\n",
    "    NamedSparseVector\n",
    ")\n",
    "from langchain_core.documents import Document\n",
    "import json\n",
    "import os\n",
    "import hashlib\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# ============================================\n",
    "# 1. Kiwi BM25 ì¸ì½”ë” (ë²•ë¥  ë¬¸ì„œ íŠ¹í™”)\n",
    "# ============================================\n",
    "\n",
    "class KiwiBM25Encoder:\n",
    "    \"\"\"Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ê¸°ë°˜ BM25 Sparse ì„ë² ë”© (ë²•ë¥  ë¬¸ì„œ íŠ¹í™”)\"\"\"\n",
    "    \n",
    "    def __init__(self, documents: List[str] = None, load_from_dict: dict = None):\n",
    "        if load_from_dict:\n",
    "            self.tokenized_corpus = load_from_dict['tokenized_corpus']\n",
    "            self.vocabulary = load_from_dict['vocabulary']\n",
    "            self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "            self.kiwi = Kiwi()\n",
    "            self._init_legal_patterns()  # ğŸ†• ë²•ë¥  íŒ¨í„´ ì´ˆê¸°í™”\n",
    "            self._build_idf_cache()\n",
    "            print(f\"âœ… BM25 ì¸ì½”ë” ë¡œë“œ ì™„ë£Œ (Vocabulary: {len(self.vocabulary)})\")\n",
    "        else:\n",
    "            print(\"ğŸ¥ Kiwi ì´ˆê¸°í™” ì¤‘...\")\n",
    "            self.kiwi = Kiwi()\n",
    "            self._init_legal_patterns()  # ğŸ†• ë²•ë¥  íŒ¨í„´ ì´ˆê¸°í™”\n",
    "            print(\"âœ… Kiwi ì´ˆê¸°í™” ì„±ê³µ!\")\n",
    "            \n",
    "            print(\"ğŸ“ í˜•íƒœì†Œ ë¶„ì„ ì¤‘...\")\n",
    "            self.tokenized_corpus = []\n",
    "            for doc in tqdm(documents, desc=\"í† í¬ë‚˜ì´ì§•\"):\n",
    "                tokens = self._tokenize(doc)\n",
    "                self.tokenized_corpus.append(tokens)\n",
    "            \n",
    "            print(\"ğŸ” BM25 ì¸ë±ìŠ¤ ìƒì„± ì¤‘...\")\n",
    "            self.bm25 = BM25Okapi(self.tokenized_corpus)\n",
    "            \n",
    "            self.vocabulary = {}\n",
    "            idx = 0\n",
    "            for doc_tokens in self.tokenized_corpus:\n",
    "                for token in doc_tokens:\n",
    "                    if token not in self.vocabulary:\n",
    "                        self.vocabulary[token] = idx\n",
    "                        idx += 1\n",
    "            \n",
    "            self._build_idf_cache()\n",
    "            print(f\"âœ… Vocabulary í¬ê¸°: {len(self.vocabulary)}\")\n",
    "    \n",
    "    # ğŸ†• ë²•ë¥  ë¬¸ì„œ íŠ¹í™” íŒ¨í„´ ë° ìš©ì–´ ì •ì˜\n",
    "    def _init_legal_patterns(self):\n",
    "        \"\"\"ë²•ë¥  ë¬¸ì„œ íŠ¹í™” íŒ¨í„´ ë° ìš©ì–´ ì´ˆê¸°í™”\"\"\"\n",
    "        # ë²•ë¥  ìš©ì–´ íŒ¨í„´\n",
    "        self.legal_patterns = {\n",
    "            # ì¡°í•­ ì°¸ì¡°: ì œ1ì¡°, ì œ2ì¡°ì˜3, ì œ10ì¡°ì œ1í•­ì œ2í˜¸ ë“±\n",
    "            'article': re.compile(\n",
    "                r'ì œ\\s*\\d+\\s*ì¡°(?:ì˜\\s*\\d+)?(?:ì œ\\s*\\d+\\s*í•­)?(?:ì œ\\s*\\d+\\s*í˜¸)?'\n",
    "            ),\n",
    "            # í•­: ì œ1í•­, ì œ2í•­ ë“±\n",
    "            'paragraph': re.compile(r'ì œ\\s*\\d+\\s*í•­'),\n",
    "            # í˜¸: ì œ1í˜¸, ì œ2í˜¸ ë“±\n",
    "            'item': re.compile(r'ì œ\\s*\\d+\\s*í˜¸'),\n",
    "            # ëª©: ê°€ëª©, ë‚˜ëª© ë“±\n",
    "            'subitem': re.compile(r'[ê°€-í•˜]\\s*ëª©'),\n",
    "            # ë³„í‘œ: ë³„í‘œ 1, ë³„í‘œ2 ë“±\n",
    "            'appendix': re.compile(r'ë³„í‘œ\\s*\\d+'),\n",
    "            # ë³„ì§€: ë³„ì§€ ì œ1í˜¸ì„œì‹ ë“±\n",
    "            'attachment': re.compile(r'ë³„ì§€\\s*(?:ì œ\\s*\\d+\\s*í˜¸\\s*)?ì„œì‹'),\n",
    "            # ê¸°ê°„: 3ì¼ ì´ë‚´, 30ì¼ ì´ìƒ, 4ì‹œê°„ ì´ë‚´ ë“±\n",
    "            'period': re.compile(\n",
    "                r'\\d+\\s*(?:ì¼|ê°œì›”|ë…„|ì‹œê°„|ë¶„|ì£¼)(?:\\s*(?:ì´ë‚´|ì´ìƒ|ë¯¸ë§Œ|ì´ˆê³¼|ì´í•˜))?'\n",
    "            ),\n",
    "            # ê¸ˆì•¡: 100ë§Œì›, 1ì²œë§Œì› ë“±\n",
    "            'amount': re.compile(r'\\d+(?:ë§Œ|ì²œ|ì–µ)?\\s*ì›'),\n",
    "            # ë¹„ìœ¨/ë°°ìˆ˜: 100ë¶„ì˜ 50, 2ë¶„ì˜ 1 ë“±\n",
    "            'ratio': re.compile(r'\\d+\\s*ë¶„ì˜\\s*\\d+'),\n",
    "            # ë‹¨ìœ„: ì„¼í‹°ë¯¸í„°, ë¯¸í„° ë“±\n",
    "            'unit': re.compile(\n",
    "                r'\\d+(?:\\.\\d+)?\\s*(?:ì„¼í‹°ë¯¸í„°|ë¯¸í„°|í‚¬ë¡œë¯¸í„°|ì œê³±ë¯¸í„°|í‰ë°©ë¯¸í„°|cm|m|km)'\n",
    "            ),\n",
    "            # ì—°ë„/ë‚ ì§œ: 2024ë…„, 2024. 1. 6. ë“±\n",
    "            'date': re.compile(r'\\d{4}\\s*ë…„|\\d{4}\\.\\s*\\d{1,2}\\.\\s*\\d{1,2}\\.'),\n",
    "        }\n",
    "        \n",
    "        # ë²•ë¥  ì „ë¬¸ ìš©ì–´ (ë³µí•©ëª…ì‚¬ - ë¶„ë¦¬í•˜ì§€ ì•Šê³  í•˜ë‚˜ì˜ í† í°ìœ¼ë¡œ ìœ ì§€)\n",
    "        self.legal_terms = {\n",
    "            'ê±´ì¶•ë¬¼ê´€ë¦¬ì', 'ë…¹ìƒ‰ê±´ì¶•ë¬¼', 'ë…¹ìƒ‰ê±´ì¶•ì„¼í„°', 'ì—ë„ˆì§€íš¨ìœ¨ë“±ê¸‰',\n",
    "            'ê±´ì¶•í—ˆê°€', 'ì‚¬ìš©ìŠ¹ì¸', 'ê³¼íƒœë£Œ', 'í–‰ì •ì²˜ë¶„', 'ì´í–‰ê°•ì œê¸ˆ',\n",
    "            'ì¬ì ìœ„ì›', 'ì¶œì„ìœ„ì›', 'ì„œë©´ì‹¬ì˜', 'ì œì²™', 'ê¸°í”¼', 'íšŒí”¼',\n",
    "            'ê³µí¬ì¼ì', 'ì‹œí–‰ì¼ì', 'ì œê°œì •', 'ì „ë¶€ê°œì •', 'ì¼ë¶€ê°œì •',\n",
    "            'ìì¹˜ë²•ê·œ', 'ì¡°ë¡€', 'ê·œì¹™', 'í›ˆë ¹', 'ì˜ˆê·œ', 'ê³ ì‹œ',\n",
    "            'ë³´í–‰ìì „ìš©ë„ë¡œ', 'ì´ë©´ë„ë¡œ', 'ì‹œì„¤ë¬¼', 'ì§€ë¶•',\n",
    "            'ì œì„¤', 'ì œë¹™', 'ê°•ì„¤', 'ì ì„¤', 'ê³ ì§€ëŒ€', 'ì‚°ê°„ì§€ì—­'\n",
    "        }\n",
    "        \n",
    "        # ë¶ˆìš©ì–´ (ë²•ë¥  ë¬¸ì„œì—ì„œ ì˜ë¯¸ ì—†ëŠ” ì¡°ì‚¬ ë“±)\n",
    "        self.stopwords = {\n",
    "            'ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì€', 'ëŠ”', 'ì˜', 'ì—', 'ì—ì„œ', 'ìœ¼ë¡œ', 'ë¡œ',\n",
    "            'ì™€', 'ê³¼', 'ë„', 'ë§Œ', 'ê¹Œì§€', 'ë¶€í„°', 'í•˜ì—¬', 'í•˜ê³ ', 'ìˆë‹¤', 'í•œë‹¤'\n",
    "        }\n",
    "    \n",
    "    # ğŸ†• ë²•ë¥  íŠ¹í™” ì—”í‹°í‹° ì¶”ì¶œ\n",
    "    def _extract_legal_entities(self, text: str) -> List[Tuple[str, int, int]]:\n",
    "        \"\"\"\n",
    "        ë²•ë¥  íŠ¹í™” ì—”í‹°í‹° ì¶”ì¶œ\n",
    "        \n",
    "        Returns:\n",
    "            List of (normalized_entity, start_pos, end_pos)\n",
    "        \"\"\"\n",
    "        entities = []\n",
    "        \n",
    "        for pattern_name, pattern in self.legal_patterns.items():\n",
    "            for match in pattern.finditer(text):\n",
    "                # ê³µë°± ì œê±°í•œ ì •ê·œí™”ëœ í˜•íƒœ\n",
    "                normalized = re.sub(r'\\s+', '', match.group())\n",
    "                entities.append((normalized, match.start(), match.end()))\n",
    "        \n",
    "        return sorted(entities, key=lambda x: x[1])  # ìœ„ì¹˜ìˆœ ì •ë ¬\n",
    "    \n",
    "    # ğŸ†• ìœ„ì¹˜ ê²¹ì¹¨ í™•ì¸\n",
    "    def _is_overlapping(self, pos1: Tuple[int, int], pos2: Tuple[int, int]) -> bool:\n",
    "        \"\"\"ë‘ ìœ„ì¹˜ê°€ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸\"\"\"\n",
    "        return not (pos1[1] <= pos2[0] or pos2[1] <= pos1[0])\n",
    "    \n",
    "    # ğŸ”„ ìˆ˜ì •ëœ í† í¬ë‚˜ì´ì €\n",
    "    def _tokenize(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        ë²•ë¥  ë¬¸ì„œì— íŠ¹í™”ëœ í† í°í™”\n",
    "        \n",
    "        ê°œì„ ì‚¬í•­:\n",
    "        - ì¡°í•­ ë²ˆí˜¸ (ì œ1ì¡°, ì œ1í•­ ë“±) ë³´ì¡´\n",
    "        - ìˆ«ì í¬í•¨ ë²•ë¥  ìš©ì–´ ë³´ì¡´\n",
    "        - ê¸°ê°„, ê¸ˆì•¡, ë‹¨ìœ„ ë“± ìˆ˜ì¹˜ ì •ë³´ ë³´ì¡´\n",
    "        \"\"\"\n",
    "        tokens = []\n",
    "        \n",
    "        # 1. ë²•ë¥  íŠ¹í™” ì—”í‹°í‹° ì¶”ì¶œ\n",
    "        legal_entities = self._extract_legal_entities(text)\n",
    "        entity_positions = [(e[1], e[2]) for e in legal_entities]\n",
    "        \n",
    "        # ë²•ë¥  ì—”í‹°í‹°ë¥¼ í† í°ìœ¼ë¡œ ì¶”ê°€\n",
    "        for entity_text, _, _ in legal_entities:\n",
    "            tokens.append(entity_text)\n",
    "        \n",
    "        # 2. í˜•íƒœì†Œ ë¶„ì„ (Kiwi)\n",
    "        morphs = self.kiwi.tokenize(text)\n",
    "        \n",
    "        for morph in morphs:\n",
    "            # ì´ë¯¸ ë²•ë¥  ì—”í‹°í‹°ë¡œ ì¶”ì¶œëœ ë¶€ë¶„ì€ ìŠ¤í‚µ\n",
    "            morph_pos = (morph.start, morph.start + morph.len)\n",
    "            if any(self._is_overlapping(morph_pos, entity_pos) \n",
    "                   for entity_pos in entity_positions):\n",
    "                continue\n",
    "            \n",
    "            # ë²•ë¥  ì „ë¬¸ ìš©ì–´ ì²´í¬ (ë³µí•©ëª…ì‚¬ ë³´ì¡´)\n",
    "            if morph.form in self.legal_terms:\n",
    "                tokens.append(morph.form)\n",
    "                continue\n",
    "            \n",
    "            # í’ˆì‚¬ íƒœê·¸ ê¸°ë°˜ í•„í„°ë§\n",
    "            # NNG: ì¼ë°˜ëª…ì‚¬, NNP: ê³ ìœ ëª…ì‚¬, NNB: ì˜ì¡´ëª…ì‚¬\n",
    "            # VV: ë™ì‚¬, VA: í˜•ìš©ì‚¬, MAG: ì¼ë°˜ë¶€ì‚¬\n",
    "            # SL: ì™¸êµ­ì–´, SH: í•œì, SN: ìˆ«ì\n",
    "            if morph.tag in ['NNG', 'NNP', 'NNB', 'VV', 'VA', 'MAG', 'SL', 'SH', 'SN']:\n",
    "                # ë¶ˆìš©ì–´ ì œê±° ë° ìµœì†Œ ê¸¸ì´ ì²´í¬\n",
    "                if morph.form not in self.stopwords and len(morph.form) > 1:\n",
    "                    tokens.append(morph.form)\n",
    "            \n",
    "            # ğŸ†• ë‹¨ë… ìˆ«ìë„ í¬í•¨ (ì¡°í•­ ë²ˆí˜¸ ë“±ì—ì„œ ì¤‘ìš”)\n",
    "            elif morph.tag == 'SN' and morph.form.isdigit():\n",
    "                tokens.append(morph.form)\n",
    "        \n",
    "        return tokens\n",
    "    \n",
    "    def _build_idf_cache(self):\n",
    "        \"\"\"ê° í† í°ì˜ IDF ê°’ì„ ë¯¸ë¦¬ ê³„ì‚°\"\"\"\n",
    "        self.idf_cache = {}\n",
    "        total_docs = len(self.tokenized_corpus)\n",
    "        \n",
    "        for token, idx in self.vocabulary.items():\n",
    "            doc_freq = sum(1 for doc in self.tokenized_corpus if token in doc)\n",
    "            idf = np.log((total_docs - doc_freq + 0.5) / (doc_freq + 0.5) + 1.0)\n",
    "            self.idf_cache[idx] = max(0.0, idf)\n",
    "    \n",
    "    def encode_query(self, query: str) -> Dict[int, float]:\n",
    "        \"\"\"ì¿¼ë¦¬ë¥¼ sparse vectorë¡œ ë³€í™˜\"\"\"\n",
    "        tokenized_query = self._tokenize(query)\n",
    "        \n",
    "        if not tokenized_query:\n",
    "            return {}\n",
    "        \n",
    "        token_freq = {}\n",
    "        for token in tokenized_query:\n",
    "            if token in self.vocabulary:\n",
    "                token_freq[token] = token_freq.get(token, 0) + 1\n",
    "        \n",
    "        if not token_freq:\n",
    "            return {}\n",
    "        \n",
    "        sparse_vector = {}\n",
    "        for token, freq in token_freq.items():\n",
    "            idx = self.vocabulary[token]\n",
    "            idf = self.idf_cache.get(idx, 0.0)\n",
    "            \n",
    "            tf = freq / len(tokenized_query)\n",
    "            score = tf * idf\n",
    "            \n",
    "            if score > 0:\n",
    "                sparse_vector[idx] = float(score)\n",
    "        \n",
    "        return sparse_vector\n",
    "    \n",
    "    def encode_document(self, doc: str, doc_idx: int = None) -> Dict[int, float]:\n",
    "        \"\"\"ë¬¸ì„œë¥¼ sparse vectorë¡œ ë³€í™˜\"\"\"\n",
    "        tokens = self._tokenize(doc)\n",
    "        \n",
    "        if not tokens:\n",
    "            return {}\n",
    "        \n",
    "        tf = {}\n",
    "        for token in tokens:\n",
    "            if token in self.vocabulary:\n",
    "                idx = self.vocabulary[token]\n",
    "                tf[idx] = tf.get(idx, 0.0) + 1.0\n",
    "        \n",
    "        if not tf:\n",
    "            return {}\n",
    "        \n",
    "        max_tf = max(tf.values())\n",
    "        sparse_vector = {k: v / max_tf for k, v in tf.items()}\n",
    "        \n",
    "        return sparse_vector\n",
    "    \n",
    "    # ğŸ†• ë””ë²„ê¹… ë° ë¶„ì„ìš© ë©”ì„œë“œ\n",
    "    def analyze_tokenization(self, text: str) -> Dict:\n",
    "        \"\"\"\n",
    "        í† í°í™” ê²°ê³¼ ë¶„ì„ (ë””ë²„ê¹…ìš©)\n",
    "        \n",
    "        Returns:\n",
    "            {\n",
    "                'original': str,\n",
    "                'tokens': List[str],\n",
    "                'legal_entities': List[str],\n",
    "                'token_count': int,\n",
    "                'entity_count': int\n",
    "            }\n",
    "        \"\"\"\n",
    "        tokens = self._tokenize(text)\n",
    "        entities = self._extract_legal_entities(text)\n",
    "        \n",
    "        return {\n",
    "            'original': text,\n",
    "            'tokens': tokens,\n",
    "            'legal_entities': [e[0] for e in entities],\n",
    "            'token_count': len(tokens),\n",
    "            'entity_count': len(entities),\n",
    "            'vocabulary_coverage': sum(1 for t in tokens if t in self.vocabulary)\n",
    "        }\n",
    "    \n",
    "    # ğŸ†• ì¡°í•­ ì°¸ì¡° ì¶”ì¶œ (ë§í¬ ì¶”ì ìš©)\n",
    "    def extract_article_references(self, text: str) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        ì¡°í•­ ì°¸ì¡° ì •ë³´ ì¶”ì¶œ\n",
    "        \n",
    "        Returns:\n",
    "            [{'text': 'ì œ1ì¡°ì œ2í•­', 'article': '1', 'paragraph': '2', ...}, ...]\n",
    "        \"\"\"\n",
    "        references = []\n",
    "        \n",
    "        # ë³µí•© ì°¸ì¡° íŒ¨í„´\n",
    "        complex_pattern = re.compile(\n",
    "            r'ì œ\\s*(\\d+)\\s*ì¡°(?:ì˜\\s*(\\d+))?'\n",
    "            r'(?:ì œ\\s*(\\d+)\\s*í•­)?'\n",
    "            r'(?:ì œ\\s*(\\d+)\\s*í˜¸)?'\n",
    "        )\n",
    "        \n",
    "        for match in complex_pattern.finditer(text):\n",
    "            article = match.group(1)\n",
    "            sub_article = match.group(2)\n",
    "            paragraph = match.group(3)\n",
    "            item = match.group(4)\n",
    "            \n",
    "            ref = {\n",
    "                'text': re.sub(r'\\s+', '', match.group()),\n",
    "                'article': article,\n",
    "                'sub_article': sub_article,\n",
    "                'paragraph': paragraph,\n",
    "                'item': item,\n",
    "                'position': (match.start(), match.end())\n",
    "            }\n",
    "            references.append(ref)\n",
    "        \n",
    "        return references\n",
    "    \n",
    "    def save(self, filepath: str):\n",
    "        \"\"\"JSONìœ¼ë¡œ ì €ì¥\"\"\"\n",
    "        data = {\n",
    "            'tokenized_corpus': self.tokenized_corpus,\n",
    "            'vocabulary': self.vocabulary\n",
    "        }\n",
    "        \n",
    "        json_filepath = filepath.replace('.pkl', '.json')\n",
    "        with open(json_filepath, 'w', encoding='utf-8') as f:\n",
    "            json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"ğŸ’¾ BM25 ì¸ì½”ë” ì €ì¥: {json_filepath}\")\n",
    "        return json_filepath\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filepath: str):\n",
    "        \"\"\"JSONì—ì„œ ë¡œë“œ\"\"\"\n",
    "        json_filepath = filepath.replace('.pkl', '.json')\n",
    "        \n",
    "        if not os.path.exists(json_filepath):\n",
    "            raise FileNotFoundError(f\"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {json_filepath}\")\n",
    "        \n",
    "        with open(json_filepath, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        print(f\"ğŸ“‚ BM25 ì¸ì½”ë” ë¡œë“œ: {json_filepath}\")\n",
    "        return KiwiBM25Encoder(load_from_dict=data)\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ í´ë˜ìŠ¤\n",
    "# ============================================\n",
    "import time\n",
    "class HybridSearchEngine:\n",
    "    \"\"\"\n",
    "    Sparse (Kiwi BM25) + Dense (Clova) í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        clova_embedder,\n",
    "        client: QdrantClient,\n",
    "        collection_name: str = \"legal_docs_hybrid\",\n",
    "        bm25_encoder_file: str = \"kiwi_bm25_encoder.pkl\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            clova_embedder: Clova ì„ë² ë”\n",
    "            client: Qdrant í´ë¼ì´ì–¸íŠ¸\n",
    "            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„\n",
    "            bm25_encoder_file: BM25 ì¸ì½”ë” ì €ì¥ íŒŒì¼\n",
    "        \"\"\"\n",
    "        self.clova_embedder = clova_embedder\n",
    "        self.client = client\n",
    "        self.collection_name = collection_name\n",
    "        self.bm25_encoder_file = bm25_encoder_file\n",
    "        self.bm25_encoder = None\n",
    "        \n",
    "        print(\"ğŸ”§ HybridSearchEngine ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "    \n",
    "    def index(self, documents: List[Document], force_rebuild: bool = False):\n",
    "        \"\"\"\n",
    "        ë¬¸ì„œ ì¸ë±ì‹±\n",
    "        \n",
    "        Args:\n",
    "            documents: ì¸ë±ì‹±í•  Document ë¦¬ìŠ¤íŠ¸\n",
    "            force_rebuild: Trueë©´ ê°•ì œë¡œ ì¬ìƒì„±\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"ğŸš€ í•˜ì´ë¸Œë¦¬ë“œ ì¸ë±ì‹± ì‹œì‘\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # ========================================\n",
    "        # 1ë‹¨ê³„: BM25 ì¸ì½”ë” ì¤€ë¹„\n",
    "        # ========================================\n",
    "        print(\"\\n1ï¸âƒ£ Kiwi BM25 ì¸ì½”ë” ì¤€ë¹„ ì¤‘...\")\n",
    "        \n",
    "        corpus = [doc.page_content for doc in documents]\n",
    "        json_file = self.bm25_encoder_file.replace('.pkl', '.json')\n",
    "        \n",
    "        if os.path.exists(json_file) and not force_rebuild:\n",
    "            print(\"  ğŸ“‚ ê¸°ì¡´ BM25 ì¸ì½”ë” ë¡œë“œ\")\n",
    "            self.bm25_encoder = KiwiBM25Encoder.load(self.bm25_encoder_file)\n",
    "        else:\n",
    "            print(\"  ğŸ†• ìƒˆ BM25 ì¸ì½”ë” ìƒì„±\")\n",
    "            self.bm25_encoder = KiwiBM25Encoder(corpus)\n",
    "            self.bm25_encoder.save(self.bm25_encoder_file)\n",
    "        \n",
    "        # ========================================\n",
    "        # 2ë‹¨ê³„: Qdrant ì»¬ë ‰ì…˜ ìƒì„±\n",
    "        # ========================================\n",
    "        print(f\"\\n2ï¸âƒ£ Qdrant ì»¬ë ‰ì…˜ '{self.collection_name}' ìƒì„± ì¤‘...\")\n",
    "        \n",
    "        try:\n",
    "            self.client.delete_collection(self.collection_name)\n",
    "            print(\"  ğŸ—‘ï¸  ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        self.client.create_collection(\n",
    "            collection_name=self.collection_name,\n",
    "            vectors_config={\n",
    "                \"dense\": VectorParams(size=1024, distance=Distance.COSINE)\n",
    "            },\n",
    "            sparse_vectors_config={\n",
    "                \"sparse\": SparseVectorParams(\n",
    "                    index=SparseIndexParams(on_disk=False)\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "        print(\"  âœ… ì»¬ë ‰ì…˜ ìƒì„± ì™„ë£Œ\")\n",
    "        \n",
    "        # ========================================\n",
    "        # 3ë‹¨ê³„: ë¬¸ì„œ ì¸ë±ì‹±\n",
    "        # ========================================\n",
    "        print(f\"\\n3ï¸âƒ£ {len(documents)}ê°œ ë¬¸ì„œ ì¸ë±ì‹± ì¤‘...\")\n",
    "        print(\"    (ê° ë¬¸ì„œ: Clova ì„ë² ë”© â†’ Kiwi BM25 â†’ Qdrant ì €ì¥)\")\n",
    "        \n",
    "        points = []\n",
    "        batch_size = 50\n",
    "        \n",
    "        for idx, doc in enumerate(tqdm(documents, desc=\"ì¸ë±ì‹±\")):\n",
    "            # Dense ì„ë² ë”© (Clova - API í˜¸ì¶œ)\n",
    "            dense_vector = self.clova_embedder.embed_query(doc.page_content)\n",
    "            time.sleep(1)\n",
    "            # Sparse ì„ë² ë”© (Kiwi - ë¡œì»¬)\n",
    "            sparse_vector = self.bm25_encoder.encode_document(doc.page_content)\n",
    "            \n",
    "            if sparse_vector:\n",
    "                sparse_vec = SparseVector(\n",
    "                    indices=list(sparse_vector.keys()),\n",
    "                    values=list(sparse_vector.values())\n",
    "                )\n",
    "            else:\n",
    "                sparse_vec = SparseVector(indices=[], values=[])\n",
    "            \n",
    "            point = PointStruct(\n",
    "                id=idx,\n",
    "                vector={\n",
    "                    \"dense\": dense_vector,\n",
    "                    \"sparse\": sparse_vec\n",
    "                },\n",
    "                payload={\n",
    "                    \"page_content\": doc.page_content,\n",
    "                    \"metadata\": doc.metadata,\n",
    "                    \"doc_id\": doc.id\n",
    "                }\n",
    "            )\n",
    "            points.append(point)\n",
    "            \n",
    "            if len(points) >= batch_size:\n",
    "                self.client.upsert(collection_name=self.collection_name, points=points)\n",
    "                points = []\n",
    "        \n",
    "        if points:\n",
    "            self.client.upsert(collection_name=self.collection_name, points=points)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(\"âœ… ì¸ë±ì‹± ì™„ë£Œ!\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"ğŸ“Š í†µê³„:\")\n",
    "        print(f\"  - ë¬¸ì„œ ìˆ˜: {len(documents)}ê°œ\")\n",
    "        print(f\"  - Vocabulary: {len(self.bm25_encoder.vocabulary)}ê°œ\")\n",
    "        print(f\"  - ì»¬ë ‰ì…˜: {self.collection_name}\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "    def add_documents(self, new_documents: List[Document], skip_duplicates: bool = True):\n",
    "        \"\"\"\n",
    "        ê¸°ì¡´ ì»¬ë ‰ì…˜ì— ìƒˆ ë¬¸ì„œ ì¶”ê°€\n",
    "        \n",
    "        Args:\n",
    "            new_documents: ì¶”ê°€í•  Document ë¦¬ìŠ¤íŠ¸\n",
    "            skip_duplicates: Trueë©´ ì¤‘ë³µ ë¬¸ì„œ ê±´ë„ˆë›°ê¸°\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"â• ë¬¸ì„œ ì¶”ê°€ ì‹œì‘\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        # BM25 ì¸ì½”ë” ë¡œë“œ\n",
    "        if self.bm25_encoder is None:\n",
    "            json_file = self.bm25_encoder_file.replace('.pkl', '.json')\n",
    "            if not os.path.exists(json_file):\n",
    "                raise ValueError(\n",
    "                    \"BM25 ì¸ì½”ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € index()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\"\n",
    "                )\n",
    "            print(\"ğŸ“‚ BM25 ì¸ì½”ë” ë¡œë“œ ì¤‘...\")\n",
    "            self.bm25_encoder = KiwiBM25Encoder.load(self.bm25_encoder_file)\n",
    "        \n",
    "        # ì»¬ë ‰ì…˜ ì¡´ì¬ í™•ì¸\n",
    "        collections = self.client.get_collections().collections\n",
    "        if not any(c.name == self.collection_name for c in collections):\n",
    "            raise ValueError(\n",
    "                f\"ì»¬ë ‰ì…˜ '{self.collection_name}'ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. \"\n",
    "                \"ë¨¼ì € index()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\"\n",
    "            )\n",
    "        \n",
    "        # í˜„ì¬ ìµœëŒ€ ID ë° ê¸°ì¡´ ë¬¸ì„œ í™•ì¸\n",
    "        collection_info = self.client.get_collection(self.collection_name)\n",
    "        current_max_id = collection_info.points_count\n",
    "        \n",
    "        # ì¤‘ë³µ ì²´í¬\n",
    "        if skip_duplicates:\n",
    "            print(\"\\nğŸ” ì¤‘ë³µ ë¬¸ì„œ ì²´í¬ ì¤‘...\")\n",
    "            \n",
    "            # ê¸°ì¡´ ë¬¸ì„œì˜ doc_id ìˆ˜ì§‘\n",
    "            existing_doc_ids = set()\n",
    "            scroll_result = self.client.scroll(\n",
    "                collection_name=self.collection_name,\n",
    "                limit=10000,  # í•œ ë²ˆì— ê°€ì ¸ì˜¬ ìµœëŒ€ ê°œìˆ˜\n",
    "                with_payload=True\n",
    "            )\n",
    "            \n",
    "            for point in scroll_result[0]:\n",
    "                if 'doc_id' in point.payload:\n",
    "                    existing_doc_ids.add(point.payload['doc_id'])\n",
    "            \n",
    "            print(f\"  ğŸ“‹ ê¸°ì¡´ ë¬¸ì„œ ID: {len(existing_doc_ids)}ê°œ\")\n",
    "            \n",
    "            # ìƒˆ ë¬¸ì„œ í•„í„°ë§\n",
    "            filtered_documents = []\n",
    "            duplicate_count = 0\n",
    "            \n",
    "            for doc in new_documents:\n",
    "                doc_id = doc.id if hasattr(doc, 'id') else None\n",
    "                \n",
    "                if doc_id and doc_id in existing_doc_ids:\n",
    "                    duplicate_count += 1\n",
    "                else:\n",
    "                    filtered_documents.append(doc)\n",
    "            \n",
    "            print(f\"  âœ… ì¤‘ë³µ ì œì™¸: {duplicate_count}ê°œ\")\n",
    "            print(f\"  â• ì¶”ê°€í•  ë¬¸ì„œ: {len(filtered_documents)}ê°œ\")\n",
    "            \n",
    "            new_documents = filtered_documents\n",
    "        \n",
    "        if not new_documents:\n",
    "            print(\"\\nâš ï¸  ì¶”ê°€í•  ìƒˆ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nğŸ“Š í˜„ì¬ ìƒíƒœ:\")\n",
    "        print(f\"  - ê¸°ì¡´ ë¬¸ì„œ ìˆ˜: {current_max_id}ê°œ\")\n",
    "        print(f\"  - ì¶”ê°€í•  ë¬¸ì„œ ìˆ˜: {len(new_documents)}ê°œ\")\n",
    "        \n",
    "        # ìƒˆ ë¬¸ì„œ ì¸ë±ì‹±\n",
    "        print(f\"\\nğŸ“ {len(new_documents)}ê°œ ë¬¸ì„œ ì¶”ê°€ ì¤‘...\")\n",
    "        \n",
    "        points = []\n",
    "        batch_size = 50\n",
    "        \n",
    "        for idx, doc in enumerate(tqdm(new_documents, desc=\"ì¶”ê°€\")):\n",
    "            new_id = current_max_id + idx\n",
    "            \n",
    "            # Dense ì„ë² ë”©\n",
    "            dense_vector = self.clova_embedder.embed_query(doc.page_content)\n",
    "            time.sleep(1)\n",
    "            \n",
    "            # Sparse ì„ë² ë”©\n",
    "            sparse_vector = self.bm25_encoder.encode_document(doc.page_content)\n",
    "            \n",
    "            if sparse_vector:\n",
    "                sparse_vec = SparseVector(\n",
    "                    indices=list(sparse_vector.keys()),\n",
    "                    values=list(sparse_vector.values())\n",
    "                )\n",
    "            else:\n",
    "                sparse_vec = SparseVector(indices=[], values=[])\n",
    "            \n",
    "            point = PointStruct(\n",
    "                id=new_id,\n",
    "                vector={\n",
    "                    \"dense\": dense_vector,\n",
    "                    \"sparse\": sparse_vec\n",
    "                },\n",
    "                payload={\n",
    "                    \"page_content\": doc.page_content,\n",
    "                    \"metadata\": doc.metadata,\n",
    "                    \"doc_id\": doc.id if hasattr(doc, 'id') else str(new_id)\n",
    "                }\n",
    "            )\n",
    "            points.append(point)\n",
    "            \n",
    "            if len(points) >= batch_size:\n",
    "                self.client.upsert(collection_name=self.collection_name, points=points)\n",
    "                points = []\n",
    "        \n",
    "        if points:\n",
    "            self.client.upsert(collection_name=self.collection_name, points=points)\n",
    "        \n",
    "        # ìµœì¢… ìƒíƒœ\n",
    "        final_info = self.client.get_collection(self.collection_name)\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*80)\n",
    "        print(\"âœ… ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ!\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"ğŸ“Š ìµœì¢… ìƒíƒœ:\")\n",
    "        print(f\"  - ì „ì²´ ë¬¸ì„œ ìˆ˜: {final_info.points_count}ê°œ\")\n",
    "        print(f\"  - ì‹¤ì œ ì¶”ê°€ëœ ë¬¸ì„œ: {len(new_documents)}ê°œ\")\n",
    "        print(\"=\"*80)\n",
    "\n",
    "    def search(\n",
    "        self,\n",
    "        query: str,\n",
    "        top_k: int = 5,\n",
    "        dense_weight: float = 0.7,\n",
    "        sparse_weight: float = 0.3,\n",
    "        verbose: bool = True\n",
    "    ):\n",
    "        \"\"\"\n",
    "        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰\n",
    "        \n",
    "        Args:\n",
    "            query: ê²€ìƒ‰ ì¿¼ë¦¬\n",
    "            top_k: ë°˜í™˜í•  ê²°ê³¼ ìˆ˜\n",
    "            dense_weight: Dense ê°€ì¤‘ì¹˜\n",
    "            sparse_weight: Sparse ê°€ì¤‘ì¹˜\n",
    "            verbose: ìƒì„¸ ì •ë³´ ì¶œë ¥\n",
    "        \n",
    "        Returns:\n",
    "            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        # BM25 ì¸ì½”ë” í™•ì¸\n",
    "        if self.bm25_encoder is None:\n",
    "            json_file = self.bm25_encoder_file.replace('.pkl', '.json')\n",
    "            if os.path.exists(json_file):\n",
    "                print(\"ğŸ“‚ BM25 ì¸ì½”ë” ë¡œë“œ ì¤‘...\")\n",
    "                self.bm25_encoder = KiwiBM25Encoder.load(self.bm25_encoder_file)\n",
    "            else:\n",
    "                raise ValueError(\"BM25 ì¸ì½”ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € index()ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.\")\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\n{'='*80}\")\n",
    "            print(f\"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{query}'\")\n",
    "            print(f\"{'='*80}\")\n",
    "        \n",
    "        # ========================================\n",
    "        # 1ë‹¨ê³„: Dense ì¿¼ë¦¬ ë²¡í„° (Clova)\n",
    "        # ========================================\n",
    "        if verbose:\n",
    "            print(\"\\n1ï¸âƒ£ Dense ë²¡í„° ìƒì„± (Clova)...\")\n",
    "        \n",
    "        dense_query = self.clova_embedder.embed_query(query)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  âœ… Dense ë²¡í„°: {len(dense_query)} ì°¨ì›\")\n",
    "        \n",
    "        # ========================================\n",
    "        # 2ë‹¨ê³„: Sparse ì¿¼ë¦¬ ë²¡í„° (Kiwi BM25)\n",
    "        # ========================================\n",
    "        if verbose:\n",
    "            print(\"\\n2ï¸âƒ£ Sparse ë²¡í„° ìƒì„± (Kiwi BM25)...\")\n",
    "        \n",
    "        sparse_query = self.bm25_encoder.encode_query(query)\n",
    "        \n",
    "        if verbose:\n",
    "            tokens = self.bm25_encoder._tokenize(query)\n",
    "            print(f\"  ğŸ“ í˜•íƒœì†Œ: {tokens}\")\n",
    "            print(f\"  âœ… Sparse ë²¡í„°: {len(sparse_query)} ê°œ (non-zero)\")\n",
    "        \n",
    "        # ========================================\n",
    "        # 3ë‹¨ê³„: Dense ê²€ìƒ‰\n",
    "        # ========================================\n",
    "        if verbose:\n",
    "            print(f\"\\n3ï¸âƒ£ Dense ê²€ìƒ‰ (ê°€ì¤‘ì¹˜: {dense_weight})...\")\n",
    "        \n",
    "        dense_results = self.client.search(\n",
    "            collection_name=self.collection_name,\n",
    "            query_vector=NamedVector(name=\"dense\", vector=dense_query),\n",
    "            limit=top_k * 3,\n",
    "            with_payload=True\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"  âœ… {len(dense_results)}ê°œ ê²°ê³¼\")\n",
    "        \n",
    "        # ========================================\n",
    "        # 4ë‹¨ê³„: Sparse ê²€ìƒ‰\n",
    "        # ========================================\n",
    "        if sparse_query:\n",
    "            if verbose:\n",
    "                print(f\"\\n4ï¸âƒ£ Sparse ê²€ìƒ‰ (ê°€ì¤‘ì¹˜: {sparse_weight})...\")\n",
    "            \n",
    "            sparse_query_vec = NamedSparseVector(\n",
    "                name=\"sparse\",\n",
    "                vector=SparseVector(\n",
    "                    indices=list(sparse_query.keys()),\n",
    "                    values=list(sparse_query.values())\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            sparse_results = self.client.search(\n",
    "                collection_name=self.collection_name,\n",
    "                query_vector=sparse_query_vec,\n",
    "                limit=top_k * 3,\n",
    "                with_payload=True\n",
    "            )\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  âœ… {len(sparse_results)}ê°œ ê²°ê³¼\")\n",
    "        else:\n",
    "            sparse_results = []\n",
    "            if verbose:\n",
    "                print(f\"\\n4ï¸âƒ£ Sparse ê²€ìƒ‰ ê±´ë„ˆëœ€ (ìœ íš¨ í† í° ì—†ìŒ)\")\n",
    "        \n",
    "        # ========================================\n",
    "        # 5ë‹¨ê³„: RRFë¡œ ê²°ê³¼ ê²°í•©\n",
    "        # ========================================\n",
    "        if verbose:\n",
    "            print(f\"\\n5ï¸âƒ£ RRFë¡œ ê²°ê³¼ ê²°í•©...\")\n",
    "        \n",
    "        rrf_scores = {}\n",
    "        k = 10\n",
    "        \n",
    "        for rank, point in enumerate(dense_results, 1):\n",
    "            rrf_scores[point.id] = rrf_scores.get(point.id, 0) + (dense_weight / (k + rank))\n",
    "        \n",
    "        for rank, point in enumerate(sparse_results, 1):\n",
    "            rrf_scores[point.id] = rrf_scores.get(point.id, 0) + (sparse_weight / (k + rank))\n",
    "        \n",
    "        sorted_ids = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]\n",
    "        \n",
    "        if not sorted_ids:\n",
    "            if verbose:\n",
    "                print(\"  âš ï¸  ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ\")\n",
    "            return []\n",
    "        \n",
    "        result_ids = [id for id, _ in sorted_ids]\n",
    "        final_results = self.client.retrieve(\n",
    "            collection_name=self.collection_name,\n",
    "            ids=result_ids,\n",
    "            with_payload=True\n",
    "        )\n",
    "        \n",
    "        score_map = dict(sorted_ids)\n",
    "        results_with_scores = []\n",
    "\n",
    "        for point in final_results:\n",
    "            result_dict = {\n",
    "                'id': point.id,\n",
    "                'score': score_map[point.id],\n",
    "                'payload': point.payload\n",
    "            }\n",
    "            results_with_scores.append(result_dict)\n",
    "\n",
    "        # score ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
    "        results_with_scores.sort(key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"  âœ… ìµœì¢… {len(results_with_scores)}ê°œ ê²°ê³¼\")\n",
    "            print(f\"{'='*80}\")\n",
    "\n",
    "        return results_with_scores \n",
    "    \n",
    "    def print_results(self, results, top_n: int = None):\n",
    "        \"\"\"ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥\"\"\"\n",
    "        if top_n:\n",
    "            results = results[:top_n]\n",
    "        \n",
    "        if not results:\n",
    "            print(\"\\nâŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼ (Top {len(results)}):\")\n",
    "        print(\"=\"*80)\n",
    "        \n",
    "        for i, result in enumerate(results, 1):\n",
    "            print(f\"\\n{i}. Score: {result['score']:.4f}\")\n",
    "            print(f\"   Document ID: {result['payload']['doc_id']}\")\n",
    "            print(f\"   ì§€ìì²´: {result['payload']['metadata'].get('ì§€ìì²´ê¸°ê´€ëª…', 'N/A')}\")\n",
    "            print(f\"   ë²•ê·œëª…: {result['payload']['metadata'].get('ìì¹˜ë²•ê·œëª…', 'N/A')}\")\n",
    "            \n",
    "            links = result['payload']['metadata'].get('links', [])\n",
    "            if links and links[0]:\n",
    "                print(f\"   ê´€ë ¨ ë²•ë ¹: {', '.join(list(links[0].keys())[:3])}\")\n",
    "            \n",
    "            print(f\"   ë‚´ìš©: {result['payload']['page_content'][:200]}...\")\n",
    "            print(\"-\"*80)\n",
    "    \n",
    "    def compare_weights(self, query: str, top_k: int = 3):\n",
    "        \"\"\"ë‹¤ì–‘í•œ ê°€ì¤‘ì¹˜ë¡œ ê²€ìƒ‰ ê²°ê³¼ ë¹„êµ\"\"\"\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"âš–ï¸  ê°€ì¤‘ì¹˜ ë¹„êµ: '{query}'\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        weight_combinations = [\n",
    "            (1.0, 0.0, \"Dense only\"),\n",
    "            (0.0, 1.0, \"Sparse only\"),\n",
    "            (0.8, 0.2, \"Dense ìš°ì„ \"),\n",
    "            (0.7, 0.3, \"Dense ì¤‘ì‹¬\"),\n",
    "            (0.5, 0.5, \"ê· í˜•\"),\n",
    "            (0.3, 0.7, \"Sparse ì¤‘ì‹¬\"),\n",
    "        ]\n",
    "        \n",
    "        for dense_w, sparse_w, desc in weight_combinations:\n",
    "            print(f\"\\n{desc} (D:{dense_w}, S:{sparse_w})\")\n",
    "            results = self.search(\n",
    "                query=query,\n",
    "                top_k=top_k,\n",
    "                dense_weight=dense_w,\n",
    "                sparse_weight=sparse_w,\n",
    "                verbose=False\n",
    "            )\n",
    "            \n",
    "            for i, result in enumerate(results, 1):\n",
    "                print(f\"  {i}. {result['score']:.4f} | {result['payload']['doc_id']}\")\n",
    "                \n",
    "# ============================================\n",
    "# 3. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜\n",
    "# ============================================\n",
    "\n",
    "def load_documents_from_jsonl(file_path: str) -> List[Document]:\n",
    "    \"\"\"JSONL íŒŒì¼ì—ì„œ Document ë¡œë“œ\"\"\"\n",
    "    documents = []\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            data = json.loads(line)\n",
    "            doc = Document(\n",
    "                page_content=data[\"page_content\"],\n",
    "                metadata=data[\"metadata\"],\n",
    "                id=data.get(\"id\", None)\n",
    "            )\n",
    "            documents.append(doc)\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ HybridSearchEngine ì´ˆê¸°í™” ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.embeddings import ClovaXEmbeddings\n",
    "\n",
    "# Clova ì„ë² ë” ì´ˆê¸°í™”\n",
    "clova_embedder = ClovaXEmbeddings(\n",
    "                model=\"bge-m3\",\n",
    "                api_key=os.getenv(\"CLOVASTUDIO_API_KEY\")\n",
    "                )\n",
    "\n",
    "# Qdrant í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "client = QdrantClient(\n",
    "    url=QDRANT_URL, \n",
    "    api_key=QDRANT_api_key,\n",
    ")\n",
    "# ê²€ìƒ‰ ì—”ì§„ ìƒì„±\n",
    "search_engine = HybridSearchEngine(\n",
    "    clova_embedder=clova_embedder,\n",
    "    client=client,\n",
    "    collection_name=\"legal_docs_hybrid\",\n",
    "    bm25_encoder_file=\"kiwi_bm25_encoder.pkl\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¬¸ì„œ ë¡œë“œ\n",
    "documents = load_documents_from_jsonl(\"documents_merged.jsonl\")\n",
    "\n",
    "# # ì¸ë±ì‹± (ìµœì´ˆ 1íšŒ)\n",
    "# search_engine.index(documents, force_rebuild=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "â• ë¬¸ì„œ ì¶”ê°€ ì‹œì‘\n",
      "================================================================================\n",
      "ğŸ“‚ BM25 ì¸ì½”ë” ë¡œë“œ ì¤‘...\n",
      "ğŸ“‚ BM25 ì¸ì½”ë” ë¡œë“œ: kiwi_bm25_encoder.json\n",
      "âœ… BM25 ì¸ì½”ë” ë¡œë“œ ì™„ë£Œ (Vocabulary: 2396)\n",
      "\n",
      "ğŸ” ì¤‘ë³µ ë¬¸ì„œ ì²´í¬ ì¤‘...\n",
      "  ğŸ“‹ ê¸°ì¡´ ë¬¸ì„œ ID: 486ê°œ\n",
      "  âœ… ì¤‘ë³µ ì œì™¸: 486ê°œ\n",
      "  â• ì¶”ê°€í•  ë¬¸ì„œ: 809ê°œ\n",
      "\n",
      "ğŸ“Š í˜„ì¬ ìƒíƒœ:\n",
      "  - ê¸°ì¡´ ë¬¸ì„œ ìˆ˜: 486ê°œ\n",
      "  - ì¶”ê°€í•  ë¬¸ì„œ ìˆ˜: 809ê°œ\n",
      "\n",
      "ğŸ“ 809ê°œ ë¬¸ì„œ ì¶”ê°€ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ì¶”ê°€: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 809/809 [17:14<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "âœ… ë¬¸ì„œ ì¶”ê°€ ì™„ë£Œ!\n",
      "================================================================================\n",
      "ğŸ“Š ìµœì¢… ìƒíƒœ:\n",
      "  - ì „ì²´ ë¬¸ì„œ ìˆ˜: 1295ê°œ\n",
      "  - ì‹¤ì œ ì¶”ê°€ëœ ë¬¸ì„œ: 809ê°œ\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ìƒˆ ë¬¸ì„œ ë¡œë“œ\n",
    "new_documents = load_documents_from_jsonl(\"documents_merged.jsonl\")\n",
    "\n",
    "# ê¸°ì¡´ ì»¬ë ‰ì…˜ì— ì¶”ê°€\n",
    "search_engine.add_documents(new_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: 'ê±´ì¶•ë¬¼ ì œì„¤ ì œë¹™ ì±…ì„ì€ ëˆ„êµ¬ì—ê²Œ ìˆë‚˜ìš”?'\n",
      "================================================================================\n",
      "\n",
      "1ï¸âƒ£ Dense ë²¡í„° ìƒì„± (Clova)...\n",
      "  âœ… Dense ë²¡í„°: 1024 ì°¨ì›\n",
      "\n",
      "2ï¸âƒ£ Sparse ë²¡í„° ìƒì„± (Kiwi BM25)...\n",
      "  ğŸ“ í˜•íƒœì†Œ: ['ê±´ì¶•ë¬¼', 'ì œì„¤', 'ì œë¹™', 'ì±…ì„', 'ìˆ']\n",
      "  âœ… Sparse ë²¡í„°: 5 ê°œ (non-zero)\n",
      "\n",
      "3ï¸âƒ£ Dense ê²€ìƒ‰ (ê°€ì¤‘ì¹˜: 0.7)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/6fdvg69n75b6lgybytxszz8c0000gn/T/ipykernel_8781/3372857715.py:496: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  dense_results = self.client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… 15ê°œ ê²°ê³¼\n",
      "\n",
      "4ï¸âƒ£ Sparse ê²€ìƒ‰ (ê°€ì¤‘ì¹˜: 0.3)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yn/6fdvg69n75b6lgybytxszz8c0000gn/T/ipykernel_8781/3372857715.py:521: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  sparse_results = self.client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  âœ… 15ê°œ ê²°ê³¼\n",
      "\n",
      "5ï¸âƒ£ RRFë¡œ ê²°ê³¼ ê²°í•©...\n",
      "  âœ… ìµœì¢… 5ê°œ ê²°ê³¼\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ (Top 3):\n",
      "================================================================================\n",
      "\n",
      "1. Score: 0.0786\n",
      "   Document ID: 2021460_chapter1_chunk2\n",
      "   ì§€ìì²´: ì „ë¼ë‚¨ë„ ê°•ì§„êµ°\n",
      "   ë²•ê·œëª…: ê°•ì§„êµ° ê±´ì¶•ë¬¼ ê´€ë¦¬ìì˜ ì œì„¤ ë° ì œë¹™ì±…ì„ì— ê´€í•œ ì¡°ë¡€\n",
      "   ë‚´ìš©: [ì „ë¼ë‚¨ë„ ê°•ì§„êµ° | ê°•ì§„êµ° ê±´ì¶•ë¬¼ ê´€ë¦¬ìì˜ ì œì„¤ ë° ì œë¹™ì±…ì„ì— ê´€í•œ ì¡°ë¡€]\n",
      "ì œ3ì¡°(ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ì±…ì„) ê±´ì¶•ë¬¼ê´€ë¦¬ìëŠ” ê´€ë¦¬í•˜ê³  ìˆëŠ” ê±´ì¶•ë¬¼ì˜ ëŒ€ì§€ì— ì ‘í•œ ë³´ë„Â·ì´ë©´ ë„ë¡œ ë° ë³´í–‰ì ì „ìš©ë„ë¡œì— ëŒ€í•œ ì œì„¤Â·ì œë¹™ì‘ì—…ì„ í•˜ì—¬ì•¼ í•œë‹¤.\n",
      "ì œ4ì¡°(ì œì„¤Â·ì œë¹™ì‘ì—…ì˜ ì±…ì„ìˆœìœ„) ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤Â·ì œë¹™ ì±…ì„ìˆœìœ„ëŠ” ë‹¤ìŒ ê° í˜¸ì™€ ê°™ë‹¤. ë‹¤ë§Œ, ê±´ì¶•ë¬¼ê´€ë¦¬ìê°„ ì„œë¡œ í•©ì˜ê°€ ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Score: 0.0726\n",
      "   Document ID: 2019610_chapter1_chunk2\n",
      "   ì§€ìì²´: ê²½ê¸°ë„ ê°€í‰êµ°\n",
      "   ë²•ê·œëª…: ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ ë° ì œë¹™ ì±…ì„ì— ê´€í•œ ì¡°ë¡€\n",
      "   ê´€ë ¨ ë²•ë ¹: ê¸°íƒ€\n",
      "   ë‚´ìš©: [ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ ë° ì œë¹™ ì±…ì„ì— ê´€í•œ ì¡°ë¡€]\n",
      "ì œ3ì¡°(ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ã†ì œë¹™ ì±…ì„) ê±´ì¶•ë¬¼ê´€ë¦¬ìëŠ” ê´€ë¦¬í•˜ê³  ìˆëŠ” ê±´ì¶•ë¬¼ì˜ ëŒ€ì§€ì— ì ‘í•œ ë³´ë„, ì´ë©´ë„ë¡œ, ë³´í–‰ìì „ìš©ë„ë¡œ, ì‹œì„¤ë¬¼ì˜ ì§€ë¶•ì— ëŒ€í•œ ì œì„¤ã†ì œë¹™ì‘ì—…ì„ í•˜ì—¬ì•¼ í•œë‹¤. <ì‹ ì„¤ 2017.7.31.>\n",
      "ì œ4ì¡°(ì œì„¤ã†ì œë¹™ì‘ì—…ì˜ ì±…ì„ìˆœìœ„) ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ã†ì œë¹™ ì±…ì„ìˆœìœ„ëŠ” ë‹¤ìŒ ê° ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Score: 0.0714\n",
      "   Document ID: 2020158_chapter1_chunk2\n",
      "   ì§€ìì²´: ê°•ì›íŠ¹ë³„ìì¹˜ë„ ê°•ë¦‰ì‹œ\n",
      "   ë²•ê·œëª…: ê°•ë¦‰ì‹œ ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ ë° ì œë¹™ ì±…ì„ì— ê´€í•œ ì¡°ë¡€\n",
      "   ë‚´ìš©: [ê°•ì›íŠ¹ë³„ìì¹˜ë„ ê°•ë¦‰ì‹œ | ê°•ë¦‰ì‹œ ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤ ë° ì œë¹™ ì±…ì„ì— ê´€í•œ ì¡°ë¡€]\n",
      "ì œ3ì¡°(ê±´ì¶•ë¬¼ê´€ë¦¬ìì˜ ì œì„¤Â·ì œë¹™ ì±…ì„ ë“±) â‘  ê±´ì¶•ë¬¼ê´€ë¦¬ìëŠ” ê´€ë¦¬í•˜ê³  ìˆëŠ” ê±´ì¶•ë¬¼ì˜ ëŒ€ì§€ì— ì ‘í•œ ë³´ë„Â·ì´ë©´ë„ë¡œ ë° ë³´í–‰ìì „ìš©ë„ë¡œ, ì‹œì„¤ë¬¼ì˜ ì§€ë¶•ì— ëŒ€í•œ  ì œì„¤Â·ì œë¹™ ì‘ì—…ì„ í•˜ì—¬ì•¼ í•œë‹¤. <ê°œì • 2017.10.11.>â‘¡ ì œ1í•­ì— ë”°ë¥¸ ì œì„¤Â·ì œë¹™ ì‘ì—…ì˜ ì±…ì„ìˆœìœ„ëŠ” ë‹¤ìŒ ê° í˜¸ì™€ ...\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ê²€ìƒ‰\n",
    "results = search_engine.search(\n",
    "    query=\"ê±´ì¶•ë¬¼ ì œì„¤ ì œë¹™ ì±…ì„ì€ ëˆ„êµ¬ì—ê²Œ ìˆë‚˜ìš”?\",\n",
    "    top_k=5,\n",
    "    dense_weight=0.7,\n",
    "    sparse_weight=0.3\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "search_engine.print_results(results, top_n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 42,\n",
       "  'score': 0.08863636363636362,\n",
       "  'payload': {'page_content': '[ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ê±´ì¶• ì¡°ë¡€]\\nì œ7ì¥ ë³´ì¹™\\nì œ37ì¡°(ì§€ì—­ê±´ì¶•ì•ˆì „ì„¼í„°ì˜ ì„¤ì¹˜Â·ìš´ì˜)â‘  êµ°ìˆ˜ëŠ” ë²• ì œ87ì¡°ì˜2ì— ë”°ë¼ ê±´ì¶•ë¬¼ ì•ˆì „ì— ê´€í•œ ê¸°ìˆ ì  ê²€í† ì™€ ê³µì‚¬ì¥ ë° ë¯¼ê°„ ê±´ì¶•ë¬¼ì˜ ì•ˆì „ê´€ë¦¬ë¥¼ ìœ„í•˜ì—¬ ì§€ì—­ê±´ì¶•ì•ˆì „ì„¼í„°(ì´í•˜ â€œê±´ì¶•ì•ˆì „ì„¼í„°â€ë¼ í•œë‹¤)ë¥¼ ì„¤ì¹˜í•˜ì—¬ ìš´ì˜í•  ìˆ˜ ìˆë‹¤.â‘¡ ì˜ ì œ119ì¡°ì˜3ì— ë”°ë¥¸ ê±´ì¶•ì•ˆì „ì„¼í„°ì˜ ì—…ë¬´ëŠ” ë‹¤ìŒ ê° í˜¸ì™€ ê°™ë‹¤.1. ê±´ì¶•ë¶„ì•¼ì˜ ì•ˆì „ì—…ë¬´ ë° ê±´ì¶•ê³µì‚¬ì¥ ì•ˆì „ê´€ë¦¬ ê³„íšìˆ˜ë¦½2. ì§€ì§„Â·í™”ì¬ ë“± ê±´ì¶•ë¬¼ ë¶€ë¬¸ ì¬ë‚œëŒ€ë¹„ ì•ˆì „ëŒ€ì±… ìˆ˜ë¦½3. ë¯¼ê°„ ê±´ì¶•ë¬¼ì˜ ì•ˆì „ê´€ë¦¬ ë° ì•ˆì „ì ê²€ ì§€ì›ì— ê´€í•œ ì‚¬í•­4. ê±´ì¶•ë¬¼ì˜ ì ê²€ ë° ê°œëŸ‰Â·ë³´ìˆ˜ì— ëŒ€í•œ ê¸°ìˆ ì§€ì›, ì •ë³´ì œê³µ5. ã€Œê±´ì¶•ë¬¼ê´€ë¦¬ë²•ã€ì— ì˜í•œ ê±´ì¶•ë¬¼ê´€ë¦¬ê³„íšì— ë”°ë¼ íš¨ìœ¨ì ìœ¼ë¡œ ê±´ì¶•ë¬¼ì„ ê´€ë¦¬ í•  ìˆ˜ ìˆë„ë¡ ê¸°ìˆ ì§€ì›, ì •ë³´ì œê³µ, ì•ˆì „ëŒ€ì±…ì˜ ìˆ˜ë¦½6. ìœ„ë°˜ê±´ì¶•ë¬¼ ê´€ë¦¬Â·ê°ë… ì—…ë¬´7. ê·¸ ë°–ì— êµ°ìˆ˜ê°€ ê±´ì¶•ë¬¼ì˜ ì•ˆì „ì„ ìœ„í•˜ì—¬ í•„ìš”í•˜ë‹¤ê³  ì¸ì •í•˜ëŠ” ì—…ë¬´<ì‹ ì„¤ 2021.8.4.>\\nì œ38ì¡°(ì‹œí–‰ê·œì¹™) ì´ ì¡°ë¡€ ì‹œí–‰ì— í•„ìš”í•œ ì‚¬í•­ì€ ê·œì¹™ìœ¼ë¡œ ì •í•œë‹¤.<ê°œì • 2014.4.18.>',\n",
       "   'metadata': {'ìì¹˜ë²•ê·œID': '2019611',\n",
       "    'ìì¹˜ë²•ê·œëª…': 'ê°€í‰êµ° ê±´ì¶• ì¡°ë¡€',\n",
       "    'ìì¹˜ë²•ê·œì¼ë ¨ë²ˆí˜¸': '2028113',\n",
       "    'ì§€ìì²´ê¸°ê´€ëª…': 'ê²½ê¸°ë„ ê°€í‰êµ°',\n",
       "    'ì‹œí–‰ì¼ì': '20250409',\n",
       "    'ì œê°œì •ì •ë³´': 'ì¼ë¶€ê°œì •',\n",
       "    'ìì¹˜ë²•ê·œì¢…ë¥˜': 'C0001',\n",
       "    'ê³µí¬ë²ˆí˜¸': '3296',\n",
       "    'ì „í™”ë²ˆí˜¸': '031-580-2395',\n",
       "    'ë‹´ë‹¹ë¶€ì„œëª…': 'ê±´ì„¤ë„ì‹œêµ­ ê±´ì¶•ê³¼',\n",
       "    'ìì¹˜ë²•ê·œë°œì˜ì¢…ë¥˜': '',\n",
       "    'ê³µí¬ì¼ì': '20250409',\n",
       "    'links': [{'ê±´ì¶•ë²•': ['ì œ87ì¡°ì˜2'], 'ê±´ì¶•ë²• ì‹œí–‰ë ¹': ['ì œ119ì¡°ì˜3'], 'ê±´ì¶•ë¬¼ê´€ë¦¬ë²•': []}],\n",
       "    'ì•½ì–´': {'ê±´ì¶•ì•ˆì „ì„¼í„°': 'ì§€ì—­ê±´ì¶•ì•ˆì „ì„¼í„°'},\n",
       "    'content': [{'ì¥ë²ˆí˜¸': 'ì œ7ì¥',\n",
       "      'ì¥ì œëª©': 'ë³´ì¹™',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ37ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ì§€ì—­ê±´ì¶•ì•ˆì „ì„¼í„°ì˜ ì„¤ì¹˜Â·ìš´ì˜'},\n",
       "     {'ì¥ë²ˆí˜¸': 'ì œ7ì¥',\n",
       "      'ì¥ì œëª©': 'ë³´ì¹™',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ38ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ì‹œí–‰ê·œì¹™'}],\n",
       "    'attachment': [{'ë³„í‘œì œëª©': 'ë³„í‘œ1',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924177&flNm=%EB%B3%84%ED%91%9C1',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0001',\n",
       "      'ë³„í‘œí‚¤': '19696447',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'},\n",
       "     {'ë³„í‘œì œëª©': 'ë³„í‘œ2',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924179&flNm=%EB%B3%84%ED%91%9C2',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0002',\n",
       "      'ë³„í‘œí‚¤': '19696449',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'},\n",
       "     {'ë³„í‘œì œëª©': 'ë³„í‘œ 3',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924181&flNm=%EB%B3%84%ED%91%9C+3',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0003',\n",
       "      'ë³„í‘œí‚¤': '19696451',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'},\n",
       "     {'ë³„í‘œì œëª©': '[ë³„í‘œ 4]',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924183&flNm=%5B%EB%B3%84%ED%91%9C+4%5D',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0004',\n",
       "      'ë³„í‘œí‚¤': '19696453',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'},\n",
       "     {'ë³„í‘œì œëª©': '[ë³„í‘œ 5]',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924185&flNm=%5B%EB%B3%84%ED%91%9C+5%5D',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0005',\n",
       "      'ë³„í‘œí‚¤': '19696455',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'},\n",
       "     {'ë³„í‘œì œëª©': 'ë³„í‘œ 6',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924187&flNm=%EB%B3%84%ED%91%9C+6',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0006',\n",
       "      'ë³„í‘œí‚¤': '19696457',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'},\n",
       "     {'ë³„í‘œì œëª©': '[ë³„ì§€ ì œ1í˜¸ì„œì‹]',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924189&flNm=%5B%EB%B3%84%EC%A7%80+%EC%A0%9C1%ED%98%B8%EC%84%9C%EC%8B%9D%5D',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0007',\n",
       "      'ë³„í‘œí‚¤': '19696459',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'},\n",
       "     {'ë³„í‘œì œëª©': 'ë³„ì§€ ì œ2í˜¸ì„œì‹',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924191&flNm=%EB%B3%84%EC%A7%80+%EC%A0%9C2%ED%98%B8%EC%84%9C%EC%8B%9D',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0008',\n",
       "      'ë³„í‘œí‚¤': '19696461',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'}]},\n",
       "   'doc_id': '2019611_chapter7_chunk4'}},\n",
       " {'id': 9,\n",
       "  'score': 0.0856060606060606,\n",
       "  'payload': {'page_content': '[ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ ì¡°ë¡€]\\nì œ11ì¡°(ê±´ì¶•ë¬¼ í•´ì²´ê³µì‚¬ê°ë¦¬ìì˜ êµì²´) ì˜ ì œ23ì¡°ì œ4í˜¸ì— ë”°ë¥¸ ê°ë¦¬ì êµì²´ ëŒ€ìƒì„ â€œì¡°ë¡€ë¡œ ì •í•˜ëŠ” ê²½ìš°â€ëŠ” ë‹¤ìŒ ê° í˜¸ì™€ ê°™ë‹¤.1. í•´ì²´ê³µì‚¬ê°ë¦¬ìê°€ ê°ë¦¬ì™€ ê´€ë ¨í•˜ì—¬ ê´€ë¦¬ì ë“±ì—ê²Œ ê³„ì•½í•œ ëŒ€ê°€ ì´ì™¸ì˜ ê¸ˆí’ˆì„ ìš”êµ¬ ë˜ëŠ” ìˆ˜ìˆ˜í•˜ëŠ” ê²½ìš°2. í•´ì²´ê³µì‚¬ê°ë¦¬ìì˜ ì§ë¬´íƒœë§Œã†í’ˆìœ„ì†ìƒ ë° ê·¸ ë°–ì˜ ì‚¬ìœ ë¡œ í•´ì²´ê³µì‚¬ê°ë¦¬ìë¡œ ì í•©í•˜ì§€ ì•„ë‹ˆí•˜ë‹¤ê³  êµ°ìˆ˜ê°€ ì¸ì •í•˜ëŠ” ê²½ìš°\\nì œ12ì¡°(ì§€ì—­ê±´ì¶•ë¬¼ê´€ë¦¬ì§€ì›ì„¼í„°ì˜ ì„¤ì¹˜ã†ìš´ì˜)â‘  êµ°ìˆ˜ëŠ” ë²• ì œ40ì¡°ì œ2í•­ì— ë”°ë¥¸ ì§€ì—­ê±´ì¶•ë¬¼ê´€ë¦¬ì§€ì›ì„¼í„°(ì´í•˜ â€œê±´ì¶•ë¬¼ê´€ë¦¬ì„¼í„°â€ë¼ í•œë‹¤)ë¥¼ ì„¤ì¹˜ã†ìš´ì˜í•  ìˆ˜ ìˆë‹¤.â‘¡ ê±´ì¶•ë¬¼ê´€ë¦¬ì„¼í„°ëŠ” ë²• ì œ39ì¡°ì œ3í•­ì— ë”°ë¥¸ ì—…ë¬´ì™€ ë‹¤ìŒ ê° í˜¸ì˜ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•œë‹¤.1. ì´ ë²•ì— ë”°ë¥¸ ì•ˆì „ì ê²€ ì˜ë¬´ ê´€ë¦¬ëŒ€ìƒì´ ì•„ë‹Œ ê±´ì¶•ë¬¼ì˜ ì•ˆì „ê´€ë¦¬ ë° ì•ˆì „ì ê²€ ì§€ì›ì— ê´€í•œ ì‚¬í•­2. ê·¸ ë°–ì— êµ°ìˆ˜ê°€ ê±´ì¶•ë¬¼ì˜ ì•ˆì „ì„ ìœ„í•˜ì—¬ í•„ìš”í•˜ë‹¤ê³  ì¸ì •í•˜ëŠ” ê²½ìš°\\nì œ13ì¡°(ì‹œí–‰ê·œì¹™) ì´ ì¡°ë¡€ì˜ ì‹œí–‰ì— í•„ìš”í•œ ì‚¬í•­ì€ ê·œì¹™ìœ¼ë¡œ ì •í•œë‹¤.',\n",
       "   'metadata': {'ìì¹˜ë²•ê·œID': '2205553',\n",
       "    'ìì¹˜ë²•ê·œëª…': 'ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ ì¡°ë¡€',\n",
       "    'ìì¹˜ë²•ê·œì¼ë ¨ë²ˆí˜¸': '1888393',\n",
       "    'ì§€ìì²´ê¸°ê´€ëª…': 'ê²½ê¸°ë„ ê°€í‰êµ°',\n",
       "    'ì‹œí–‰ì¼ì': '20231226',\n",
       "    'ì œê°œì •ì •ë³´': 'ì¼ë¶€ê°œì •',\n",
       "    'ìì¹˜ë²•ê·œì¢…ë¥˜': 'C0001',\n",
       "    'ê³µí¬ë²ˆí˜¸': '3174',\n",
       "    'ì „í™”ë²ˆí˜¸': '031-580-4773',\n",
       "    'ë‹´ë‹¹ë¶€ì„œëª…': 'ê±´ì„¤ë„ì‹œêµ­ ê±´ì¶•ê³¼',\n",
       "    'ìì¹˜ë²•ê·œë°œì˜ì¢…ë¥˜': '',\n",
       "    'ê³µí¬ì¼ì': '20231226',\n",
       "    'links': [{'ê±´ì¶•ë¬¼ê´€ë¦¬ë²• ì‹œí–‰ë ¹': ['ì œ23ì¡°ì œ4í˜¸'], 'ê±´ì¶•ë¬¼ê´€ë¦¬ë²•': ['ì œ39ì¡°ì œ3í•­', 'ì œ40ì¡°ì œ2í•­']}],\n",
       "    'ì•½ì–´': {'ê±´ì¶•ë¬¼ê´€ë¦¬ì„¼í„°': 'ë²• ì œ40ì¡°ì œ2í•­ì— ë”°ë¥¸ ì§€ì—­ê±´ì¶•ë¬¼ê´€ë¦¬ì§€ì›ì„¼í„°'},\n",
       "    'content': [{'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ11ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ê±´ì¶•ë¬¼ í•´ì²´ê³µì‚¬ê°ë¦¬ìì˜ êµì²´'},\n",
       "     {'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ12ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ì§€ì—­ê±´ì¶•ë¬¼ê´€ë¦¬ì§€ì›ì„¼í„°ì˜ ì„¤ì¹˜ã†ìš´ì˜'},\n",
       "     {'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ13ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ì‹œí–‰ê·œì¹™'}],\n",
       "    'attachment': {'ë³„í‘œì œëª©': 'ë³„ì§€ ì œ1í˜¸~ì œ2í˜¸ì„œì‹',\n",
       "     'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "     'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=138669609&flNm=%EB%B3%84%EC%A7%80+%EC%A0%9C1%ED%98%B8%7E%EC%A0%9C2%ED%98%B8%EC%84%9C%EC%8B%9D',\n",
       "     'ë³„í‘œë²ˆí˜¸': '0001',\n",
       "     'ë³„í‘œí‚¤': '17286525',\n",
       "     'ë³„í‘œë‚´ìš©': '',\n",
       "     'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "     'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'}},\n",
       "   'doc_id': '2205553_chapter1_chunk6'}},\n",
       " {'id': 108,\n",
       "  'score': 0.07051282051282051,\n",
       "  'payload': {'page_content': '[ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì› ì¡°ë¡€]\\nì œ5ì¡°(ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì‹œë²”ì‚¬ì—… ì‹¤ì‹œ) êµ°ìˆ˜ëŠ” ë²• ì œ24ì¡°ì— ë”°ë¼ ë…¹ìƒ‰ê±´ì¶•ë¬¼ì— ëŒ€í•œ ì£¼ë¯¼ì˜ ì¸ì‹ì„ ë†’ì´ê³  ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„±ì˜ ì´‰ì§„ì„ ìœ„í•˜ì—¬ ë‹¤ìŒ ê° í˜¸ì˜ ì‚¬ì—…ì„ ì‹œë²”ì‚¬ì—…ìœ¼ë¡œ ì§€ì •í•  ìˆ˜ ìˆë‹¤.1. ê³µê³µê¸°ê´€ì´ ì‹œí–‰í•˜ëŠ” ì‚¬ì—…2. ê¸°ì¡´ì£¼íƒì„ ë…¹ìƒ‰ê±´ì¶•ë¬¼ë¡œ ì „í™˜í•˜ëŠ” ì‚¬ì—…3. ê¸°ì¡´ ì£¼íƒ ì™¸ì˜ ê±´ì¶•ë¬¼ì„ ë…¹ìƒ‰ê±´ì¶•ë¬¼ë¡œ ì „í™˜í•˜ëŠ” ì‚¬ì—…ìœ¼ë¡œì„œã€Œë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ë²• ì‹œí–‰ë ¹ã€ ì œ17ì¡°ì—ì„œ ì •í•˜ëŠ” ì‚¬ì—…\\nì œ6ì¡°(ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›) â‘  êµ°ìˆ˜ëŠ” ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„±ì„ ìœ„í•˜ì—¬ ì˜ˆì‚°ì˜ ë²”ìœ„ì—ì„œ ë‹¤ìŒ ê° í˜¸ì˜ ì‚¬ì—…ì— ëŒ€í•˜ì—¬ ì¬ì • ì§€ì›ì„ í•  ìˆ˜ ìˆë‹¤.1. ì œ5ì¡°ì— ë”°ë¥¸ ì‹œë²”ì‚¬ì—…ì˜ ì‹œí–‰ì— ì†Œìš”ë˜ëŠ” ì‚¬ì—…ë¹„2. ë²• ì œ16ì¡° ë° ì œ17ì¡°ì˜ ì¸ì¦ì— ì†Œìš”ë˜ëŠ” ë¹„ìš©3. ê·¸ ë°–ì— êµ°ìˆ˜ê°€ ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„±ì„ ìœ„í•´ í•„ìš”í•˜ë‹¤ê³  ì¸ì •í•˜ëŠ” ì‚¬ì—…â‘¡ ì œ1í•­ì— ë”°ë¥¸ ì§€ì› ë²”ìœ„ëŠ” ì†Œìš”ë¹„ìš©ì˜ 2ë¶„ì˜ 1 ë²”ìœ„ì—ì„œ ìµœëŒ€ 1ì²œë§Œì›ê¹Œì§€ë¡œ í•œë‹¤.\\nì œ7ì¡°(ì§€ì›ì‹ ì²­) ì§€ì›ê¸ˆì„ ë°›ìœ¼ë ¤ëŠ” ê±´ì¶•ë¬¼ ì†Œìœ ì(ê±´ì¶•ë¬¼ë“±ê¸°ë“±ë³¸ìƒ ì†Œìœ ìë¥¼ ë§í•¨) ë“±ì€ ì‹ ì²­ì„œë¥¼ êµ°ìˆ˜ì—ê²Œ ì œì¶œí•˜ì—¬ì•¼ í•œë‹¤. ì´ ê²½ìš° ì œì¶œë°©ë²• ë° ì§€ì›ì‹œê¸° ë“±ì€ ê·œì¹™ìœ¼ë¡œ ì •í•œë‹¤.',\n",
       "   'metadata': {'ìì¹˜ë²•ê·œID': '2169395',\n",
       "    'ìì¹˜ë²•ê·œëª…': 'ê°€í‰êµ° ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì› ì¡°ë¡€',\n",
       "    'ìì¹˜ë²•ê·œì¼ë ¨ë²ˆí˜¸': '1253000',\n",
       "    'ì§€ìì²´ê¸°ê´€ëª…': 'ê²½ê¸°ë„ ê°€í‰êµ°',\n",
       "    'ì‹œí–‰ì¼ì': '20160928',\n",
       "    'ì œê°œì •ì •ë³´': 'ì œì •',\n",
       "    'ìì¹˜ë²•ê·œì¢…ë¥˜': 'C0001',\n",
       "    'ê³µí¬ë²ˆí˜¸': '2570',\n",
       "    'ì „í™”ë²ˆí˜¸': '031-580-2395',\n",
       "    'ë‹´ë‹¹ë¶€ì„œëª…': 'ê±´ì„¤ë„ì‹œêµ­ ê±´ì¶•ê³¼',\n",
       "    'ìì¹˜ë²•ê·œë°œì˜ì¢…ë¥˜': '',\n",
       "    'ê³µí¬ì¼ì': '20160928',\n",
       "    'links': [{'ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ë²•': ['ì œ16ì¡°', 'ì œ17ì¡°', 'ì œ24ì¡°'],\n",
       "      'ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ë²• ì‹œí–‰ë ¹': ['ì œ17ì¡°'],\n",
       "      'Attachment': ['ì œ5ì¡°']}],\n",
       "    'content': [{'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ5ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì‹œë²”ì‚¬ì—… ì‹¤ì‹œ'},\n",
       "     {'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ6ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›'},\n",
       "     {'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ7ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ì§€ì›ì‹ ì²­'}],\n",
       "    'attachment': []},\n",
       "   'doc_id': '2169395_chapter1_chunk3'}},\n",
       " {'id': 109,\n",
       "  'score': 0.05991902834008096,\n",
       "  'payload': {'page_content': '[ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì› ì¡°ë¡€]\\nì œ8ì¡°(ìœ„ì›íšŒ ì„¤ì¹˜ ë° ê¸°ëŠ¥) â‘  êµ°ìˆ˜ëŠ” ë‹¤ìŒ ê° í˜¸ì˜ ì‚¬í•­ì„ ì‹¬ì˜í•˜ê¸° ìœ„í•˜ì—¬ ê°€í‰êµ° ë…¹ìƒ‰ê±´ì¶•ë¬¼ì¡°ì„±ì‹¬ì˜ìœ„ì›íšŒ(ì´í•˜ â€œìœ„ì›íšŒâ€ë¼ í•œë‹¤)ë¥¼ ì„¤ì¹˜Â·ìš´ì˜í•œë‹¤.1. ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ëŒ€ìƒ ì‚¬ì—…ì˜ ì ì •ì„±2. ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì§€ì›ëŒ€ìƒ ì‚¬ì—…ì˜ ìš°ì„ ìˆœìœ„ ë° ì§€ì›ì—¬ë¶€ ê²°ì •ì— ê´€í•œ ì‚¬í•­3. ê·¸ ë°–ì— êµ°ìˆ˜ê°€ ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„±ê³¼ ê´€ë ¨í•˜ì—¬ ìë¬¸ ë“±ì„ ìš”ì²­í•˜ëŠ” ì‚¬í•­â‘¡ ìœ„ì›íšŒì˜ ìš´ì˜ì€ ã€Œê°€í‰êµ° ê±´ì¶• ì¡°ë¡€ã€ì— ë”°ë¥¸ ê°€í‰êµ° ê±´ì¶•ìœ„ì›íšŒì—ì„œ ëŒ€í–‰í•œë‹¤.\\nì œ9ì¡°(ìˆ˜ë‹¹ ë“±) ìœ„ì›íšŒì— ì¶œì„í•œ ìœ„ì› ì¤‘ ê³µë¬´ì›ì´ ì•„ë‹Œ ìœ„ì›ì— ëŒ€í•´ì„œëŠ” ì˜ˆì‚°ì˜ ë²”ìœ„ì—ì„œ ã€Œê°€í‰êµ° ìœ„ì›íšŒ ì‹¤ë¹„ë³€ìƒ ì¡°ë¡€ã€ë¡œ ì •í•˜ëŠ” ë°”ì— ë”°ë¼ ìˆ˜ë‹¹ê³¼ ì—¬ë¹„ë¥¼ ì§€ê¸‰í•  ìˆ˜ ìˆë‹¤\\nì œ10ì¡° (ì‹œí–‰ê·œì¹™) ì´ ì¡°ë¡€ì˜ ì‹œí–‰ì— í•„ìš”í•œ ì‚¬í•­ì€ ê·œì¹™ìœ¼ë¡œ ì •í•œë‹¤.',\n",
       "   'metadata': {'ìì¹˜ë²•ê·œID': '2169395',\n",
       "    'ìì¹˜ë²•ê·œëª…': 'ê°€í‰êµ° ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì› ì¡°ë¡€',\n",
       "    'ìì¹˜ë²•ê·œì¼ë ¨ë²ˆí˜¸': '1253000',\n",
       "    'ì§€ìì²´ê¸°ê´€ëª…': 'ê²½ê¸°ë„ ê°€í‰êµ°',\n",
       "    'ì‹œí–‰ì¼ì': '20160928',\n",
       "    'ì œê°œì •ì •ë³´': 'ì œì •',\n",
       "    'ìì¹˜ë²•ê·œì¢…ë¥˜': 'C0001',\n",
       "    'ê³µí¬ë²ˆí˜¸': '2570',\n",
       "    'ì „í™”ë²ˆí˜¸': '031-580-2395',\n",
       "    'ë‹´ë‹¹ë¶€ì„œëª…': 'ê±´ì„¤ë„ì‹œêµ­ ê±´ì¶•ê³¼',\n",
       "    'ìì¹˜ë²•ê·œë°œì˜ì¢…ë¥˜': '',\n",
       "    'ê³µí¬ì¼ì': '20160928',\n",
       "    'links': [{'ê°€í‰êµ° ê±´ì¶• ì¡°ë¡€': [], 'ê°€í‰êµ° ìœ„ì›íšŒ ì‹¤ë¹„ë³€ìƒ ì¡°ë¡€': []}],\n",
       "    'ì•½ì–´': {'ìœ„ì›íšŒ': 'ê°€í‰êµ° ë…¹ìƒ‰ê±´ì¶•ë¬¼ì¡°ì„±ì‹¬ì˜ìœ„ì›íšŒ'},\n",
       "    'content': [{'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ8ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ìœ„ì›íšŒ ì„¤ì¹˜ ë° ê¸°ëŠ¥'},\n",
       "     {'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ9ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ìˆ˜ë‹¹ ë“±'},\n",
       "     {'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ10ì¡° ',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ì‹œí–‰ê·œì¹™'}],\n",
       "    'attachment': []},\n",
       "   'doc_id': '2169395_chapter1_chunk4'}},\n",
       " {'id': 58,\n",
       "  'score': 0.049999999999999996,\n",
       "  'payload': {'page_content': '[ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° êµ°ê³„íš ì¡°ë¡€]\\nì œ3ì¥ êµ°ê´€ë¦¬ê³„íš<ê°œì • 2022.11.9.>\\nì œ1ì ˆ êµ°ê´€ë¦¬ê³„íšì˜ ìˆ˜ë¦½ì ˆì°¨<ê°œì • 2022.11.9.>\\nì œ12ì¡°(ë§¤ìˆ˜ì²­êµ¬ê°€ ìˆëŠ” í† ì§€ì•ˆì—ì„œ ì„¤ì¹˜ê°€ëŠ¥í•œ ê±´ì¶•ë¬¼ ë“±)â‘  ì˜ ì œ41ì¡°ì œ5í•­ì— ë”°ë¼ ë§¤ìˆ˜ì²­êµ¬ê°€ ìˆëŠ” í† ì§€ì— ì„¤ì¹˜í•  ìˆ˜ ìˆëŠ” ê±´ì¶•ë¬¼ì€ ë‹¤ìŒ ê° í˜¸ì˜ ì–´ëŠ í•˜ë‚˜ì— í•´ë‹¹í•˜ëŠ” ê±´ì¶•ë¬¼ë¡œì„œ ì² ê·¼ì½˜í¬ë¦¬íŠ¸ì¡° ë° ì² ê³¨Â·ì² ê·¼ì½˜í¬ë¦¬íŠ¸ì¡°ê°€ ì•„ë‹Œ ê±´ì¶•ë¬¼ë¡œ í•œë‹¤.<ê°œì • 2012.11.5.>1. ã€Œê±´ì¶•ë²• ì‹œí–‰ë ¹ã€ ë³„í‘œ 1 ì œ1í˜¸ê°€ëª©ì˜ ë‹¨ë…ì£¼íƒìœ¼ë¡œì„œ 3ì¸µ ì´í•˜ì¸ ê²ƒ<ê°œì • 2014.7.7.>2. ã€Œê±´ì¶•ë²• ì‹œí–‰ë ¹ã€ ë³„í‘œ 1 ì œ3í˜¸ì˜ ì œ1ì¢… ê·¼ë¦°ìƒí™œì‹œì„¤ë¡œì„œ 3ì¸µ ì´í•˜ì¸ ê²ƒ(ë¶„ì–‘ì„ ëª©ì ìœ¼ë¡œ í•˜ì§€ ì•„ë‹ˆí•˜ëŠ” ê²ƒì— í•œì •í•œë‹¤)<ê°œì • 2014.7.7.>3. ã€Œê±´ì¶•ë²• ì‹œí–‰ë ¹ã€ë³„í‘œ 1 ì œ4í˜¸ì˜ ì œ2ì¢… ê·¼ë¦°ìƒí™œì‹œì„¤(ê°™ì€ í˜¸ ê±°ëª©, ë”ëª© ë° ëŸ¬ëª©ì€ ì œì™¸í•œë‹¤)ë¡œì„œ 3ì¸µ ì´í•˜ì¸ ê²ƒ(ë¶„ì–‘ì„ ëª©ì ìœ¼ë¡œ í•˜ì§€ ì•„ë‹ˆí•˜ëŠ” ê²ƒì— í•œì •í•œë‹¤)<ì‹ ì„¤ 2009.11.10.><ê°œì • 2012.11.5.><ê°œì • 2014.7.7.>4. ê³µì‘ë¬¼<ì‹ ì„¤ 2009.11.10.>â‘¡ ì˜ ì œ41ì¡°ì œ5í•­ì— ë”°ë¼ ë§¤ìˆ˜ì²­êµ¬ê°€ ìˆëŠ” í† ì§€ì— ì„¤ì¹˜í•  ìˆ˜ ìˆëŠ”  ê³µì‘ë¬¼ì€ ì˜ ì œ51ì¡°ì œ1í•­2í˜¸ì— ë”°ë¥¸ ê³µì‘ë¬¼ ì¤‘ ì§€ìƒì— ì„¤ì¹˜í•˜ëŠ” ê²ƒìœ¼ë¡œ ë†’ì´ê°€ 10ë¯¸í„° ì´í•˜ì¸ ê²ƒì— í•œì •í•œë‹¤.<ê°œì • 2012.11.5.>',\n",
       "   'metadata': {'ìì¹˜ë²•ê·œID': '2019668',\n",
       "    'ìì¹˜ë²•ê·œëª…': 'ê°€í‰êµ° êµ°ê³„íš ì¡°ë¡€',\n",
       "    'ìì¹˜ë²•ê·œì¼ë ¨ë²ˆí˜¸': '2084677',\n",
       "    'ì§€ìì²´ê¸°ê´€ëª…': 'ê²½ê¸°ë„ ê°€í‰êµ°',\n",
       "    'ì‹œí–‰ì¼ì': '20251112',\n",
       "    'ì œê°œì •ì •ë³´': 'ì¼ë¶€ê°œì •',\n",
       "    'ìì¹˜ë²•ê·œì¢…ë¥˜': 'C0001',\n",
       "    'ê³µí¬ë²ˆí˜¸': '3338',\n",
       "    'ì „í™”ë²ˆí˜¸': '031-580-2350',\n",
       "    'ë‹´ë‹¹ë¶€ì„œëª…': 'ê±´ì„¤ë„ì‹œêµ­ ë„ì‹œê³¼',\n",
       "    'ìì¹˜ë²•ê·œë°œì˜ì¢…ë¥˜': '',\n",
       "    'ê³µí¬ì¼ì': '20251112',\n",
       "    'links': [{'êµ­í† ì˜ ê³„íš ë° ì´ìš©ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹': ['ì œ41ì¡°ì œ5í•­', 'ì œ51ì¡°ì œ1í•­2í˜¸'],\n",
       "      'ê±´ì¶•ë²• ì‹œí–‰ë ¹': [],\n",
       "      'Attachment': ['ë³„í‘œ 1 ì œ1í˜¸ê°€ëª©', 'ë³„í‘œ 1 ì œ3í˜¸', 'ë³„í‘œ 1 ì œ4í˜¸']}],\n",
       "    'content': [{'ì¥ë²ˆí˜¸': 'ì œ3ì¥',\n",
       "      'ì¥ì œëª©': 'êµ°ê´€ë¦¬ê³„íš<ê°œì • 2022.11.9.>',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ2ì ˆ',\n",
       "      'ì ˆì œëª©': 'êµ°ê³„íšì‹œì„¤<ê°œì • 2022.11.9.>',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ12ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ë§¤ìˆ˜ì²­êµ¬ê°€ ìˆëŠ” í† ì§€ì•ˆì—ì„œ ì„¤ì¹˜ê°€ëŠ¥í•œ ê±´ì¶•ë¬¼ ë“±'}],\n",
       "    'attachment': {'ë³„í‘œì œëª©': 'ë³„í‘œ 1 ~ ë³„í‘œ 25',\n",
       "     'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "     'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=158112899&flNm=%EB%B3%84%ED%91%9C+1+%7E+%EB%B3%84%ED%91%9C+25',\n",
       "     'ë³„í‘œë²ˆí˜¸': '0001',\n",
       "     'ë³„í‘œí‚¤': '21054901',\n",
       "     'ë³„í‘œë‚´ìš©': '',\n",
       "     'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "     'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'}},\n",
       "   'doc_id': '2019668_chapter3_chunk5'}}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 42,\n",
       "  'score': 0.08863636363636362,\n",
       "  'payload': {'page_content': '[ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ê±´ì¶• ì¡°ë¡€]\\nì œ7ì¥ ë³´ì¹™\\nì œ37ì¡°(ì§€ì—­ê±´ì¶•ì•ˆì „ì„¼í„°ì˜ ì„¤ì¹˜Â·ìš´ì˜)â‘  êµ°ìˆ˜ëŠ” ë²• ì œ87ì¡°ì˜2ì— ë”°ë¼ ê±´ì¶•ë¬¼ ì•ˆì „ì— ê´€í•œ ê¸°ìˆ ì  ê²€í† ì™€ ê³µì‚¬ì¥ ë° ë¯¼ê°„ ê±´ì¶•ë¬¼ì˜ ì•ˆì „ê´€ë¦¬ë¥¼ ìœ„í•˜ì—¬ ì§€ì—­ê±´ì¶•ì•ˆì „ì„¼í„°(ì´í•˜ â€œê±´ì¶•ì•ˆì „ì„¼í„°â€ë¼ í•œë‹¤)ë¥¼ ì„¤ì¹˜í•˜ì—¬ ìš´ì˜í•  ìˆ˜ ìˆë‹¤.â‘¡ ì˜ ì œ119ì¡°ì˜3ì— ë”°ë¥¸ ê±´ì¶•ì•ˆì „ì„¼í„°ì˜ ì—…ë¬´ëŠ” ë‹¤ìŒ ê° í˜¸ì™€ ê°™ë‹¤.1. ê±´ì¶•ë¶„ì•¼ì˜ ì•ˆì „ì—…ë¬´ ë° ê±´ì¶•ê³µì‚¬ì¥ ì•ˆì „ê´€ë¦¬ ê³„íšìˆ˜ë¦½2. ì§€ì§„Â·í™”ì¬ ë“± ê±´ì¶•ë¬¼ ë¶€ë¬¸ ì¬ë‚œëŒ€ë¹„ ì•ˆì „ëŒ€ì±… ìˆ˜ë¦½3. ë¯¼ê°„ ê±´ì¶•ë¬¼ì˜ ì•ˆì „ê´€ë¦¬ ë° ì•ˆì „ì ê²€ ì§€ì›ì— ê´€í•œ ì‚¬í•­4. ê±´ì¶•ë¬¼ì˜ ì ê²€ ë° ê°œëŸ‰Â·ë³´ìˆ˜ì— ëŒ€í•œ ê¸°ìˆ ì§€ì›, ì •ë³´ì œê³µ5. ã€Œê±´ì¶•ë¬¼ê´€ë¦¬ë²•ã€ì— ì˜í•œ ê±´ì¶•ë¬¼ê´€ë¦¬ê³„íšì— ë”°ë¼ íš¨ìœ¨ì ìœ¼ë¡œ ê±´ì¶•ë¬¼ì„ ê´€ë¦¬ í•  ìˆ˜ ìˆë„ë¡ ê¸°ìˆ ì§€ì›, ì •ë³´ì œê³µ, ì•ˆì „ëŒ€ì±…ì˜ ìˆ˜ë¦½6. ìœ„ë°˜ê±´ì¶•ë¬¼ ê´€ë¦¬Â·ê°ë… ì—…ë¬´7. ê·¸ ë°–ì— êµ°ìˆ˜ê°€ ê±´ì¶•ë¬¼ì˜ ì•ˆì „ì„ ìœ„í•˜ì—¬ í•„ìš”í•˜ë‹¤ê³  ì¸ì •í•˜ëŠ” ì—…ë¬´<ì‹ ì„¤ 2021.8.4.>\\nì œ38ì¡°(ì‹œí–‰ê·œì¹™) ì´ ì¡°ë¡€ ì‹œí–‰ì— í•„ìš”í•œ ì‚¬í•­ì€ ê·œì¹™ìœ¼ë¡œ ì •í•œë‹¤.<ê°œì • 2014.4.18.>',\n",
       "   'metadata': {'ìì¹˜ë²•ê·œID': '2019611',\n",
       "    'ìì¹˜ë²•ê·œëª…': 'ê°€í‰êµ° ê±´ì¶• ì¡°ë¡€',\n",
       "    'ìì¹˜ë²•ê·œì¼ë ¨ë²ˆí˜¸': '2028113',\n",
       "    'ì§€ìì²´ê¸°ê´€ëª…': 'ê²½ê¸°ë„ ê°€í‰êµ°',\n",
       "    'ì‹œí–‰ì¼ì': '20250409',\n",
       "    'ì œê°œì •ì •ë³´': 'ì¼ë¶€ê°œì •',\n",
       "    'ìì¹˜ë²•ê·œì¢…ë¥˜': 'C0001',\n",
       "    'ê³µí¬ë²ˆí˜¸': '3296',\n",
       "    'ì „í™”ë²ˆí˜¸': '031-580-2395',\n",
       "    'ë‹´ë‹¹ë¶€ì„œëª…': 'ê±´ì„¤ë„ì‹œêµ­ ê±´ì¶•ê³¼',\n",
       "    'ìì¹˜ë²•ê·œë°œì˜ì¢…ë¥˜': '',\n",
       "    'ê³µí¬ì¼ì': '20250409',\n",
       "    'links': [{'ê±´ì¶•ë²•': ['ì œ87ì¡°ì˜2'], 'ê±´ì¶•ë²• ì‹œí–‰ë ¹': ['ì œ119ì¡°ì˜3'], 'ê±´ì¶•ë¬¼ê´€ë¦¬ë²•': []}],\n",
       "    'ì•½ì–´': {'ê±´ì¶•ì•ˆì „ì„¼í„°': 'ì§€ì—­ê±´ì¶•ì•ˆì „ì„¼í„°'},\n",
       "    'content': [{'ì¥ë²ˆí˜¸': 'ì œ7ì¥',\n",
       "      'ì¥ì œëª©': 'ë³´ì¹™',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ37ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ì§€ì—­ê±´ì¶•ì•ˆì „ì„¼í„°ì˜ ì„¤ì¹˜Â·ìš´ì˜'},\n",
       "     {'ì¥ë²ˆí˜¸': 'ì œ7ì¥',\n",
       "      'ì¥ì œëª©': 'ë³´ì¹™',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ38ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ì‹œí–‰ê·œì¹™'}],\n",
       "    'attachment': [{'ë³„í‘œì œëª©': 'ë³„í‘œ1',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924177&flNm=%EB%B3%84%ED%91%9C1',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0001',\n",
       "      'ë³„í‘œí‚¤': '19696447',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'},\n",
       "     {'ë³„í‘œì œëª©': 'ë³„í‘œ2',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924179&flNm=%EB%B3%84%ED%91%9C2',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0002',\n",
       "      'ë³„í‘œí‚¤': '19696449',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'},\n",
       "     {'ë³„í‘œì œëª©': 'ë³„í‘œ 3',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924181&flNm=%EB%B3%84%ED%91%9C+3',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0003',\n",
       "      'ë³„í‘œí‚¤': '19696451',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'},\n",
       "     {'ë³„í‘œì œëª©': '[ë³„í‘œ 4]',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924183&flNm=%5B%EB%B3%84%ED%91%9C+4%5D',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0004',\n",
       "      'ë³„í‘œí‚¤': '19696453',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'},\n",
       "     {'ë³„í‘œì œëª©': '[ë³„í‘œ 5]',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924185&flNm=%5B%EB%B3%84%ED%91%9C+5%5D',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0005',\n",
       "      'ë³„í‘œí‚¤': '19696455',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'},\n",
       "     {'ë³„í‘œì œëª©': 'ë³„í‘œ 6',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924187&flNm=%EB%B3%84%ED%91%9C+6',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0006',\n",
       "      'ë³„í‘œí‚¤': '19696457',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'},\n",
       "     {'ë³„í‘œì œëª©': '[ë³„ì§€ ì œ1í˜¸ì„œì‹]',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924189&flNm=%5B%EB%B3%84%EC%A7%80+%EC%A0%9C1%ED%98%B8%EC%84%9C%EC%8B%9D%5D',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0007',\n",
       "      'ë³„í‘œí‚¤': '19696459',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'},\n",
       "     {'ë³„í‘œì œëª©': 'ë³„ì§€ ì œ2í˜¸ì„œì‹',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "      'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=150924191&flNm=%EB%B3%84%EC%A7%80+%EC%A0%9C2%ED%98%B8%EC%84%9C%EC%8B%9D',\n",
       "      'ë³„í‘œë²ˆí˜¸': '0008',\n",
       "      'ë³„í‘œí‚¤': '19696461',\n",
       "      'ë³„í‘œë‚´ìš©': '',\n",
       "      'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "      'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'}]},\n",
       "   'doc_id': '2019611_chapter7_chunk4'}},\n",
       " {'id': 9,\n",
       "  'score': 0.0856060606060606,\n",
       "  'payload': {'page_content': '[ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ ì¡°ë¡€]\\nì œ11ì¡°(ê±´ì¶•ë¬¼ í•´ì²´ê³µì‚¬ê°ë¦¬ìì˜ êµì²´) ì˜ ì œ23ì¡°ì œ4í˜¸ì— ë”°ë¥¸ ê°ë¦¬ì êµì²´ ëŒ€ìƒì„ â€œì¡°ë¡€ë¡œ ì •í•˜ëŠ” ê²½ìš°â€ëŠ” ë‹¤ìŒ ê° í˜¸ì™€ ê°™ë‹¤.1. í•´ì²´ê³µì‚¬ê°ë¦¬ìê°€ ê°ë¦¬ì™€ ê´€ë ¨í•˜ì—¬ ê´€ë¦¬ì ë“±ì—ê²Œ ê³„ì•½í•œ ëŒ€ê°€ ì´ì™¸ì˜ ê¸ˆí’ˆì„ ìš”êµ¬ ë˜ëŠ” ìˆ˜ìˆ˜í•˜ëŠ” ê²½ìš°2. í•´ì²´ê³µì‚¬ê°ë¦¬ìì˜ ì§ë¬´íƒœë§Œã†í’ˆìœ„ì†ìƒ ë° ê·¸ ë°–ì˜ ì‚¬ìœ ë¡œ í•´ì²´ê³µì‚¬ê°ë¦¬ìë¡œ ì í•©í•˜ì§€ ì•„ë‹ˆí•˜ë‹¤ê³  êµ°ìˆ˜ê°€ ì¸ì •í•˜ëŠ” ê²½ìš°\\nì œ12ì¡°(ì§€ì—­ê±´ì¶•ë¬¼ê´€ë¦¬ì§€ì›ì„¼í„°ì˜ ì„¤ì¹˜ã†ìš´ì˜)â‘  êµ°ìˆ˜ëŠ” ë²• ì œ40ì¡°ì œ2í•­ì— ë”°ë¥¸ ì§€ì—­ê±´ì¶•ë¬¼ê´€ë¦¬ì§€ì›ì„¼í„°(ì´í•˜ â€œê±´ì¶•ë¬¼ê´€ë¦¬ì„¼í„°â€ë¼ í•œë‹¤)ë¥¼ ì„¤ì¹˜ã†ìš´ì˜í•  ìˆ˜ ìˆë‹¤.â‘¡ ê±´ì¶•ë¬¼ê´€ë¦¬ì„¼í„°ëŠ” ë²• ì œ39ì¡°ì œ3í•­ì— ë”°ë¥¸ ì—…ë¬´ì™€ ë‹¤ìŒ ê° í˜¸ì˜ ì—…ë¬´ë¥¼ ìˆ˜í–‰í•œë‹¤.1. ì´ ë²•ì— ë”°ë¥¸ ì•ˆì „ì ê²€ ì˜ë¬´ ê´€ë¦¬ëŒ€ìƒì´ ì•„ë‹Œ ê±´ì¶•ë¬¼ì˜ ì•ˆì „ê´€ë¦¬ ë° ì•ˆì „ì ê²€ ì§€ì›ì— ê´€í•œ ì‚¬í•­2. ê·¸ ë°–ì— êµ°ìˆ˜ê°€ ê±´ì¶•ë¬¼ì˜ ì•ˆì „ì„ ìœ„í•˜ì—¬ í•„ìš”í•˜ë‹¤ê³  ì¸ì •í•˜ëŠ” ê²½ìš°\\nì œ13ì¡°(ì‹œí–‰ê·œì¹™) ì´ ì¡°ë¡€ì˜ ì‹œí–‰ì— í•„ìš”í•œ ì‚¬í•­ì€ ê·œì¹™ìœ¼ë¡œ ì •í•œë‹¤.',\n",
       "   'metadata': {'ìì¹˜ë²•ê·œID': '2205553',\n",
       "    'ìì¹˜ë²•ê·œëª…': 'ê°€í‰êµ° ê±´ì¶•ë¬¼ê´€ë¦¬ ì¡°ë¡€',\n",
       "    'ìì¹˜ë²•ê·œì¼ë ¨ë²ˆí˜¸': '1888393',\n",
       "    'ì§€ìì²´ê¸°ê´€ëª…': 'ê²½ê¸°ë„ ê°€í‰êµ°',\n",
       "    'ì‹œí–‰ì¼ì': '20231226',\n",
       "    'ì œê°œì •ì •ë³´': 'ì¼ë¶€ê°œì •',\n",
       "    'ìì¹˜ë²•ê·œì¢…ë¥˜': 'C0001',\n",
       "    'ê³µí¬ë²ˆí˜¸': '3174',\n",
       "    'ì „í™”ë²ˆí˜¸': '031-580-4773',\n",
       "    'ë‹´ë‹¹ë¶€ì„œëª…': 'ê±´ì„¤ë„ì‹œêµ­ ê±´ì¶•ê³¼',\n",
       "    'ìì¹˜ë²•ê·œë°œì˜ì¢…ë¥˜': '',\n",
       "    'ê³µí¬ì¼ì': '20231226',\n",
       "    'links': [{'ê±´ì¶•ë¬¼ê´€ë¦¬ë²• ì‹œí–‰ë ¹': ['ì œ23ì¡°ì œ4í˜¸'], 'ê±´ì¶•ë¬¼ê´€ë¦¬ë²•': ['ì œ39ì¡°ì œ3í•­', 'ì œ40ì¡°ì œ2í•­']}],\n",
       "    'ì•½ì–´': {'ê±´ì¶•ë¬¼ê´€ë¦¬ì„¼í„°': 'ë²• ì œ40ì¡°ì œ2í•­ì— ë”°ë¥¸ ì§€ì—­ê±´ì¶•ë¬¼ê´€ë¦¬ì§€ì›ì„¼í„°'},\n",
       "    'content': [{'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ11ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ê±´ì¶•ë¬¼ í•´ì²´ê³µì‚¬ê°ë¦¬ìì˜ êµì²´'},\n",
       "     {'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ12ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ì§€ì—­ê±´ì¶•ë¬¼ê´€ë¦¬ì§€ì›ì„¼í„°ì˜ ì„¤ì¹˜ã†ìš´ì˜'},\n",
       "     {'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ13ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ì‹œí–‰ê·œì¹™'}],\n",
       "    'attachment': {'ë³„í‘œì œëª©': 'ë³„ì§€ ì œ1í˜¸~ì œ2í˜¸ì„œì‹',\n",
       "     'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "     'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=138669609&flNm=%EB%B3%84%EC%A7%80+%EC%A0%9C1%ED%98%B8%7E%EC%A0%9C2%ED%98%B8%EC%84%9C%EC%8B%9D',\n",
       "     'ë³„í‘œë²ˆí˜¸': '0001',\n",
       "     'ë³„í‘œí‚¤': '17286525',\n",
       "     'ë³„í‘œë‚´ìš©': '',\n",
       "     'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "     'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'}},\n",
       "   'doc_id': '2205553_chapter1_chunk6'}},\n",
       " {'id': 108,\n",
       "  'score': 0.07051282051282051,\n",
       "  'payload': {'page_content': '[ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì› ì¡°ë¡€]\\nì œ5ì¡°(ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì‹œë²”ì‚¬ì—… ì‹¤ì‹œ) êµ°ìˆ˜ëŠ” ë²• ì œ24ì¡°ì— ë”°ë¼ ë…¹ìƒ‰ê±´ì¶•ë¬¼ì— ëŒ€í•œ ì£¼ë¯¼ì˜ ì¸ì‹ì„ ë†’ì´ê³  ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„±ì˜ ì´‰ì§„ì„ ìœ„í•˜ì—¬ ë‹¤ìŒ ê° í˜¸ì˜ ì‚¬ì—…ì„ ì‹œë²”ì‚¬ì—…ìœ¼ë¡œ ì§€ì •í•  ìˆ˜ ìˆë‹¤.1. ê³µê³µê¸°ê´€ì´ ì‹œí–‰í•˜ëŠ” ì‚¬ì—…2. ê¸°ì¡´ì£¼íƒì„ ë…¹ìƒ‰ê±´ì¶•ë¬¼ë¡œ ì „í™˜í•˜ëŠ” ì‚¬ì—…3. ê¸°ì¡´ ì£¼íƒ ì™¸ì˜ ê±´ì¶•ë¬¼ì„ ë…¹ìƒ‰ê±´ì¶•ë¬¼ë¡œ ì „í™˜í•˜ëŠ” ì‚¬ì—…ìœ¼ë¡œì„œã€Œë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ë²• ì‹œí–‰ë ¹ã€ ì œ17ì¡°ì—ì„œ ì •í•˜ëŠ” ì‚¬ì—…\\nì œ6ì¡°(ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›) â‘  êµ°ìˆ˜ëŠ” ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„±ì„ ìœ„í•˜ì—¬ ì˜ˆì‚°ì˜ ë²”ìœ„ì—ì„œ ë‹¤ìŒ ê° í˜¸ì˜ ì‚¬ì—…ì— ëŒ€í•˜ì—¬ ì¬ì • ì§€ì›ì„ í•  ìˆ˜ ìˆë‹¤.1. ì œ5ì¡°ì— ë”°ë¥¸ ì‹œë²”ì‚¬ì—…ì˜ ì‹œí–‰ì— ì†Œìš”ë˜ëŠ” ì‚¬ì—…ë¹„2. ë²• ì œ16ì¡° ë° ì œ17ì¡°ì˜ ì¸ì¦ì— ì†Œìš”ë˜ëŠ” ë¹„ìš©3. ê·¸ ë°–ì— êµ°ìˆ˜ê°€ ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„±ì„ ìœ„í•´ í•„ìš”í•˜ë‹¤ê³  ì¸ì •í•˜ëŠ” ì‚¬ì—…â‘¡ ì œ1í•­ì— ë”°ë¥¸ ì§€ì› ë²”ìœ„ëŠ” ì†Œìš”ë¹„ìš©ì˜ 2ë¶„ì˜ 1 ë²”ìœ„ì—ì„œ ìµœëŒ€ 1ì²œë§Œì›ê¹Œì§€ë¡œ í•œë‹¤.\\nì œ7ì¡°(ì§€ì›ì‹ ì²­) ì§€ì›ê¸ˆì„ ë°›ìœ¼ë ¤ëŠ” ê±´ì¶•ë¬¼ ì†Œìœ ì(ê±´ì¶•ë¬¼ë“±ê¸°ë“±ë³¸ìƒ ì†Œìœ ìë¥¼ ë§í•¨) ë“±ì€ ì‹ ì²­ì„œë¥¼ êµ°ìˆ˜ì—ê²Œ ì œì¶œí•˜ì—¬ì•¼ í•œë‹¤. ì´ ê²½ìš° ì œì¶œë°©ë²• ë° ì§€ì›ì‹œê¸° ë“±ì€ ê·œì¹™ìœ¼ë¡œ ì •í•œë‹¤.',\n",
       "   'metadata': {'ìì¹˜ë²•ê·œID': '2169395',\n",
       "    'ìì¹˜ë²•ê·œëª…': 'ê°€í‰êµ° ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì› ì¡°ë¡€',\n",
       "    'ìì¹˜ë²•ê·œì¼ë ¨ë²ˆí˜¸': '1253000',\n",
       "    'ì§€ìì²´ê¸°ê´€ëª…': 'ê²½ê¸°ë„ ê°€í‰êµ°',\n",
       "    'ì‹œí–‰ì¼ì': '20160928',\n",
       "    'ì œê°œì •ì •ë³´': 'ì œì •',\n",
       "    'ìì¹˜ë²•ê·œì¢…ë¥˜': 'C0001',\n",
       "    'ê³µí¬ë²ˆí˜¸': '2570',\n",
       "    'ì „í™”ë²ˆí˜¸': '031-580-2395',\n",
       "    'ë‹´ë‹¹ë¶€ì„œëª…': 'ê±´ì„¤ë„ì‹œêµ­ ê±´ì¶•ê³¼',\n",
       "    'ìì¹˜ë²•ê·œë°œì˜ì¢…ë¥˜': '',\n",
       "    'ê³µí¬ì¼ì': '20160928',\n",
       "    'links': [{'ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ë²•': ['ì œ16ì¡°', 'ì œ17ì¡°', 'ì œ24ì¡°'],\n",
       "      'ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ë²• ì‹œí–‰ë ¹': ['ì œ17ì¡°'],\n",
       "      'Attachment': ['ì œ5ì¡°']}],\n",
       "    'content': [{'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ5ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì‹œë²”ì‚¬ì—… ì‹¤ì‹œ'},\n",
       "     {'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ6ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›'},\n",
       "     {'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ7ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ì§€ì›ì‹ ì²­'}],\n",
       "    'attachment': []},\n",
       "   'doc_id': '2169395_chapter1_chunk3'}},\n",
       " {'id': 109,\n",
       "  'score': 0.05991902834008096,\n",
       "  'payload': {'page_content': '[ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì› ì¡°ë¡€]\\nì œ8ì¡°(ìœ„ì›íšŒ ì„¤ì¹˜ ë° ê¸°ëŠ¥) â‘  êµ°ìˆ˜ëŠ” ë‹¤ìŒ ê° í˜¸ì˜ ì‚¬í•­ì„ ì‹¬ì˜í•˜ê¸° ìœ„í•˜ì—¬ ê°€í‰êµ° ë…¹ìƒ‰ê±´ì¶•ë¬¼ì¡°ì„±ì‹¬ì˜ìœ„ì›íšŒ(ì´í•˜ â€œìœ„ì›íšŒâ€ë¼ í•œë‹¤)ë¥¼ ì„¤ì¹˜Â·ìš´ì˜í•œë‹¤.1. ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì›ëŒ€ìƒ ì‚¬ì—…ì˜ ì ì •ì„±2. ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì§€ì›ëŒ€ìƒ ì‚¬ì—…ì˜ ìš°ì„ ìˆœìœ„ ë° ì§€ì›ì—¬ë¶€ ê²°ì •ì— ê´€í•œ ì‚¬í•­3. ê·¸ ë°–ì— êµ°ìˆ˜ê°€ ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„±ê³¼ ê´€ë ¨í•˜ì—¬ ìë¬¸ ë“±ì„ ìš”ì²­í•˜ëŠ” ì‚¬í•­â‘¡ ìœ„ì›íšŒì˜ ìš´ì˜ì€ ã€Œê°€í‰êµ° ê±´ì¶• ì¡°ë¡€ã€ì— ë”°ë¥¸ ê°€í‰êµ° ê±´ì¶•ìœ„ì›íšŒì—ì„œ ëŒ€í–‰í•œë‹¤.\\nì œ9ì¡°(ìˆ˜ë‹¹ ë“±) ìœ„ì›íšŒì— ì¶œì„í•œ ìœ„ì› ì¤‘ ê³µë¬´ì›ì´ ì•„ë‹Œ ìœ„ì›ì— ëŒ€í•´ì„œëŠ” ì˜ˆì‚°ì˜ ë²”ìœ„ì—ì„œ ã€Œê°€í‰êµ° ìœ„ì›íšŒ ì‹¤ë¹„ë³€ìƒ ì¡°ë¡€ã€ë¡œ ì •í•˜ëŠ” ë°”ì— ë”°ë¼ ìˆ˜ë‹¹ê³¼ ì—¬ë¹„ë¥¼ ì§€ê¸‰í•  ìˆ˜ ìˆë‹¤\\nì œ10ì¡° (ì‹œí–‰ê·œì¹™) ì´ ì¡°ë¡€ì˜ ì‹œí–‰ì— í•„ìš”í•œ ì‚¬í•­ì€ ê·œì¹™ìœ¼ë¡œ ì •í•œë‹¤.',\n",
       "   'metadata': {'ìì¹˜ë²•ê·œID': '2169395',\n",
       "    'ìì¹˜ë²•ê·œëª…': 'ê°€í‰êµ° ë…¹ìƒ‰ê±´ì¶•ë¬¼ ì¡°ì„± ì§€ì› ì¡°ë¡€',\n",
       "    'ìì¹˜ë²•ê·œì¼ë ¨ë²ˆí˜¸': '1253000',\n",
       "    'ì§€ìì²´ê¸°ê´€ëª…': 'ê²½ê¸°ë„ ê°€í‰êµ°',\n",
       "    'ì‹œí–‰ì¼ì': '20160928',\n",
       "    'ì œê°œì •ì •ë³´': 'ì œì •',\n",
       "    'ìì¹˜ë²•ê·œì¢…ë¥˜': 'C0001',\n",
       "    'ê³µí¬ë²ˆí˜¸': '2570',\n",
       "    'ì „í™”ë²ˆí˜¸': '031-580-2395',\n",
       "    'ë‹´ë‹¹ë¶€ì„œëª…': 'ê±´ì„¤ë„ì‹œêµ­ ê±´ì¶•ê³¼',\n",
       "    'ìì¹˜ë²•ê·œë°œì˜ì¢…ë¥˜': '',\n",
       "    'ê³µí¬ì¼ì': '20160928',\n",
       "    'links': [{'ê°€í‰êµ° ê±´ì¶• ì¡°ë¡€': [], 'ê°€í‰êµ° ìœ„ì›íšŒ ì‹¤ë¹„ë³€ìƒ ì¡°ë¡€': []}],\n",
       "    'ì•½ì–´': {'ìœ„ì›íšŒ': 'ê°€í‰êµ° ë…¹ìƒ‰ê±´ì¶•ë¬¼ì¡°ì„±ì‹¬ì˜ìœ„ì›íšŒ'},\n",
       "    'content': [{'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ8ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ìœ„ì›íšŒ ì„¤ì¹˜ ë° ê¸°ëŠ¥'},\n",
       "     {'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ9ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ìˆ˜ë‹¹ ë“±'},\n",
       "     {'ì¥ë²ˆí˜¸': 'ì œ0ì¥',\n",
       "      'ì¥ì œëª©': 'ì—†ìŒ',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ0ì ˆ',\n",
       "      'ì ˆì œëª©': 'ì—†ìŒ',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ10ì¡° ',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ì‹œí–‰ê·œì¹™'}],\n",
       "    'attachment': []},\n",
       "   'doc_id': '2169395_chapter1_chunk4'}},\n",
       " {'id': 58,\n",
       "  'score': 0.049999999999999996,\n",
       "  'payload': {'page_content': '[ê²½ê¸°ë„ ê°€í‰êµ° | ê°€í‰êµ° êµ°ê³„íš ì¡°ë¡€]\\nì œ3ì¥ êµ°ê´€ë¦¬ê³„íš<ê°œì • 2022.11.9.>\\nì œ1ì ˆ êµ°ê´€ë¦¬ê³„íšì˜ ìˆ˜ë¦½ì ˆì°¨<ê°œì • 2022.11.9.>\\nì œ12ì¡°(ë§¤ìˆ˜ì²­êµ¬ê°€ ìˆëŠ” í† ì§€ì•ˆì—ì„œ ì„¤ì¹˜ê°€ëŠ¥í•œ ê±´ì¶•ë¬¼ ë“±)â‘  ì˜ ì œ41ì¡°ì œ5í•­ì— ë”°ë¼ ë§¤ìˆ˜ì²­êµ¬ê°€ ìˆëŠ” í† ì§€ì— ì„¤ì¹˜í•  ìˆ˜ ìˆëŠ” ê±´ì¶•ë¬¼ì€ ë‹¤ìŒ ê° í˜¸ì˜ ì–´ëŠ í•˜ë‚˜ì— í•´ë‹¹í•˜ëŠ” ê±´ì¶•ë¬¼ë¡œì„œ ì² ê·¼ì½˜í¬ë¦¬íŠ¸ì¡° ë° ì² ê³¨Â·ì² ê·¼ì½˜í¬ë¦¬íŠ¸ì¡°ê°€ ì•„ë‹Œ ê±´ì¶•ë¬¼ë¡œ í•œë‹¤.<ê°œì • 2012.11.5.>1. ã€Œê±´ì¶•ë²• ì‹œí–‰ë ¹ã€ ë³„í‘œ 1 ì œ1í˜¸ê°€ëª©ì˜ ë‹¨ë…ì£¼íƒìœ¼ë¡œì„œ 3ì¸µ ì´í•˜ì¸ ê²ƒ<ê°œì • 2014.7.7.>2. ã€Œê±´ì¶•ë²• ì‹œí–‰ë ¹ã€ ë³„í‘œ 1 ì œ3í˜¸ì˜ ì œ1ì¢… ê·¼ë¦°ìƒí™œì‹œì„¤ë¡œì„œ 3ì¸µ ì´í•˜ì¸ ê²ƒ(ë¶„ì–‘ì„ ëª©ì ìœ¼ë¡œ í•˜ì§€ ì•„ë‹ˆí•˜ëŠ” ê²ƒì— í•œì •í•œë‹¤)<ê°œì • 2014.7.7.>3. ã€Œê±´ì¶•ë²• ì‹œí–‰ë ¹ã€ë³„í‘œ 1 ì œ4í˜¸ì˜ ì œ2ì¢… ê·¼ë¦°ìƒí™œì‹œì„¤(ê°™ì€ í˜¸ ê±°ëª©, ë”ëª© ë° ëŸ¬ëª©ì€ ì œì™¸í•œë‹¤)ë¡œì„œ 3ì¸µ ì´í•˜ì¸ ê²ƒ(ë¶„ì–‘ì„ ëª©ì ìœ¼ë¡œ í•˜ì§€ ì•„ë‹ˆí•˜ëŠ” ê²ƒì— í•œì •í•œë‹¤)<ì‹ ì„¤ 2009.11.10.><ê°œì • 2012.11.5.><ê°œì • 2014.7.7.>4. ê³µì‘ë¬¼<ì‹ ì„¤ 2009.11.10.>â‘¡ ì˜ ì œ41ì¡°ì œ5í•­ì— ë”°ë¼ ë§¤ìˆ˜ì²­êµ¬ê°€ ìˆëŠ” í† ì§€ì— ì„¤ì¹˜í•  ìˆ˜ ìˆëŠ”  ê³µì‘ë¬¼ì€ ì˜ ì œ51ì¡°ì œ1í•­2í˜¸ì— ë”°ë¥¸ ê³µì‘ë¬¼ ì¤‘ ì§€ìƒì— ì„¤ì¹˜í•˜ëŠ” ê²ƒìœ¼ë¡œ ë†’ì´ê°€ 10ë¯¸í„° ì´í•˜ì¸ ê²ƒì— í•œì •í•œë‹¤.<ê°œì • 2012.11.5.>',\n",
       "   'metadata': {'ìì¹˜ë²•ê·œID': '2019668',\n",
       "    'ìì¹˜ë²•ê·œëª…': 'ê°€í‰êµ° êµ°ê³„íš ì¡°ë¡€',\n",
       "    'ìì¹˜ë²•ê·œì¼ë ¨ë²ˆí˜¸': '2084677',\n",
       "    'ì§€ìì²´ê¸°ê´€ëª…': 'ê²½ê¸°ë„ ê°€í‰êµ°',\n",
       "    'ì‹œí–‰ì¼ì': '20251112',\n",
       "    'ì œê°œì •ì •ë³´': 'ì¼ë¶€ê°œì •',\n",
       "    'ìì¹˜ë²•ê·œì¢…ë¥˜': 'C0001',\n",
       "    'ê³µí¬ë²ˆí˜¸': '3338',\n",
       "    'ì „í™”ë²ˆí˜¸': '031-580-2350',\n",
       "    'ë‹´ë‹¹ë¶€ì„œëª…': 'ê±´ì„¤ë„ì‹œêµ­ ë„ì‹œê³¼',\n",
       "    'ìì¹˜ë²•ê·œë°œì˜ì¢…ë¥˜': '',\n",
       "    'ê³µí¬ì¼ì': '20251112',\n",
       "    'links': [{'êµ­í† ì˜ ê³„íš ë° ì´ìš©ì— ê´€í•œ ë²•ë¥  ì‹œí–‰ë ¹': ['ì œ41ì¡°ì œ5í•­', 'ì œ51ì¡°ì œ1í•­2í˜¸'],\n",
       "      'ê±´ì¶•ë²• ì‹œí–‰ë ¹': [],\n",
       "      'Attachment': ['ë³„í‘œ 1 ì œ1í˜¸ê°€ëª©', 'ë³„í‘œ 1 ì œ3í˜¸', 'ë³„í‘œ 1 ì œ4í˜¸']}],\n",
       "    'content': [{'ì¥ë²ˆí˜¸': 'ì œ3ì¥',\n",
       "      'ì¥ì œëª©': 'êµ°ê´€ë¦¬ê³„íš<ê°œì • 2022.11.9.>',\n",
       "      'ì ˆë²ˆí˜¸': 'ì œ2ì ˆ',\n",
       "      'ì ˆì œëª©': 'êµ°ê³„íšì‹œì„¤<ê°œì • 2022.11.9.>',\n",
       "      'ì¡°ë¬¸ë²ˆí˜¸': 'ì œ12ì¡°',\n",
       "      'ì¡°ë¬¸ì œëª©': 'ë§¤ìˆ˜ì²­êµ¬ê°€ ìˆëŠ” í† ì§€ì•ˆì—ì„œ ì„¤ì¹˜ê°€ëŠ¥í•œ ê±´ì¶•ë¬¼ ë“±'}],\n",
       "    'attachment': {'ë³„í‘œì œëª©': 'ë³„í‘œ 1 ~ ë³„í‘œ 25',\n",
       "     'ë³„í‘œì²¨ë¶€íŒŒì¼êµ¬ë¶„': 'hwp',\n",
       "     'ë³„í‘œì²¨ë¶€íŒŒì¼ëª…': 'http://www.law.go.kr/flDownload.do?gubun=ELIS&flSeq=158112899&flNm=%EB%B3%84%ED%91%9C+1+%7E+%EB%B3%84%ED%91%9C+25',\n",
       "     'ë³„í‘œë²ˆí˜¸': '0001',\n",
       "     'ë³„í‘œí‚¤': '21054901',\n",
       "     'ë³„í‘œë‚´ìš©': '',\n",
       "     'ë³„í‘œêµ¬ë¶„': 'ì„œì‹',\n",
       "     'ë³„í‘œê°€ì§€ë²ˆí˜¸': '00'}},\n",
       "   'doc_id': '2019668_chapter3_chunk5'}}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ë‹µë³€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

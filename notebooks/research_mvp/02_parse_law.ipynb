{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 02. 조문 파싱 (Self-contained)\n",
        "\n",
        "파서 구현을 셀에 직접 포함합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c17fa913",
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "from dataclasses import dataclass, field\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def normalize_to_list(value):\n",
        "    if value is None:\n",
        "        return []\n",
        "    if isinstance(value, dict):\n",
        "        return [value]\n",
        "    if isinstance(value, list):\n",
        "        return value\n",
        "    return []\n",
        "\n",
        "\n",
        "def normalize_paragraph_num(raw: str) -> str:\n",
        "    circled_map = {\"①\": \"1\", \"②\": \"2\", \"③\": \"3\", \"④\": \"4\", \"⑤\": \"5\", \"⑥\": \"6\", \"⑦\": \"7\", \"⑧\": \"8\", \"⑨\": \"9\", \"⑩\": \"10\", \"⑪\": \"11\", \"⑫\": \"12\", \"⑬\": \"13\", \"⑭\": \"14\", \"⑮\": \"15\"}\n",
        "    raw = (raw or \"\").strip()\n",
        "    return circled_map.get(raw, raw)\n",
        "\n",
        "\n",
        "def classify_law_type(law_name: str) -> str:\n",
        "    if \"시행규칙\" in law_name:\n",
        "        return \"시행규칙\"\n",
        "    if \"시행령\" in law_name:\n",
        "        return \"시행령\"\n",
        "    return \"법률\"\n",
        "\n",
        "\n",
        "def parse_article_numbers(article: dict, header: str) -> tuple[str, str]:\n",
        "    main = str(article.get(\"조문번호\", \"\") or \"\").strip()\n",
        "    sub = str(article.get(\"조문가지번호\", \"\") or \"\").strip()\n",
        "\n",
        "    # API 필드가 비어있는 경우 헤더(예: 제4조의2)에서 보정\n",
        "    if not main or (not sub and \"의\" in header):\n",
        "        m = re.search(r\"제\\s*(\\d+)\\s*조(?:\\s*의\\s*(\\d+))?\", header)\n",
        "        if m:\n",
        "            if not main:\n",
        "                main = m.group(1) or \"\"\n",
        "            if not sub:\n",
        "                sub = m.group(2) or \"\"\n",
        "\n",
        "    return main, sub\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ArticleChunk:\n",
        "    law_name: str\n",
        "    law_id: str\n",
        "    law_type: str\n",
        "    article_num: str\n",
        "    article_sub: str = \"\"\n",
        "    article_title: str = \"\"\n",
        "    content: str = \"\"\n",
        "    content_resolved: str = \"\"\n",
        "    paragraphs: list[dict] = field(default_factory=list)\n",
        "    internal_refs: list = field(default_factory=list)\n",
        "    external_refs: list = field(default_factory=list)\n",
        "    parent_law_refs: list = field(default_factory=list)\n",
        "    abbreviations: dict = field(default_factory=dict)\n",
        "    effective_date: str = \"\"\n",
        "    change_type: str = \"\"\n",
        "\n",
        "\n",
        "def parse_article(article: dict, law_name: str, law_id: str):\n",
        "    if article.get(\"조문여부\") != \"조문\":\n",
        "        return None\n",
        "\n",
        "    content_parts = []\n",
        "    header = str(article.get(\"조문내용\", \"\")).strip()\n",
        "    if header:\n",
        "        content_parts.append(header)\n",
        "\n",
        "    article_num, article_sub = parse_article_numbers(article, header)\n",
        "\n",
        "    paragraphs = []\n",
        "    for para in normalize_to_list(article.get(\"항\")):\n",
        "        # para_num = normalize_paragraph_num(para.get(\"항번호\", \"\"))\n",
        "        para_num = para.get(\"항번호\", \"\")\n",
        "        para_content = str(para.get(\"항내용\", \"\")).strip()\n",
        "        if para_content:\n",
        "            content_parts.append(para_content)\n",
        "\n",
        "        subs = []\n",
        "        for sub in normalize_to_list(para.get(\"호\")):\n",
        "            sub_num = str(sub.get(\"호번호\", \"\")).strip().rstrip(\".\")\n",
        "            sub_content = str(sub.get(\"호내용\", \"\")).strip()\n",
        "            if sub_content:\n",
        "                content_parts.append(sub_content)\n",
        "\n",
        "            items = []\n",
        "            for item in normalize_to_list(sub.get(\"목\")):\n",
        "                item_num = str(item.get(\"목번호\", \"\")).strip().rstrip(\".\")\n",
        "                item_content = str(item.get(\"목내용\", \"\")).strip()\n",
        "                if item_content:\n",
        "                    content_parts.append(item_content)\n",
        "                items.append({\"num\": item_num, \"content\": item_content})\n",
        "\n",
        "            subs.append({\"num\": sub_num, \"content\": sub_content, \"items\": items})\n",
        "\n",
        "        paragraphs.append({\"num\": para_num, \"content\": para_content, \"subs\": subs})\n",
        "\n",
        "    return ArticleChunk(\n",
        "        law_name=law_name,\n",
        "        law_id=str(law_id),\n",
        "        law_type=classify_law_type(law_name),\n",
        "        article_num=article_num,\n",
        "        article_sub=article_sub,\n",
        "        article_title=str(article.get(\"조문제목\", \"\")).strip(),\n",
        "        content=\"\\n\".join([x for x in content_parts if x]),\n",
        "        paragraphs=paragraphs,\n",
        "        effective_date=str(article.get(\"조문시행일자\", \"\")),\n",
        "        change_type=str(article.get(\"조문제개정유형\", \"\")),\n",
        "    )\n",
        "\n",
        "\n",
        "def parse_law_data(data: dict):\n",
        "    law_info = data[\"법령\"][\"기본정보\"]\n",
        "    law_name = law_info[\"법령명_한글\"]\n",
        "    law_id = str(law_info[\"법령ID\"])\n",
        "    articles_raw = normalize_to_list(data[\"법령\"][\"조문\"].get(\"조문단위\"))\n",
        "\n",
        "    chunks = []\n",
        "    for article in articles_raw:\n",
        "        c = parse_article(article, law_name, law_id)\n",
        "        if c:\n",
        "            chunks.append(c)\n",
        "    return chunks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "056795af",
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_dir = Path('data/processed/raw')\n",
        "files = sorted(raw_dir.glob('*.json'))\n",
        "payload = json.loads(files[1].read_text(encoding='utf-8'))\n",
        "chunks = parse_law_data(payload)\n",
        "print('chunk count:', len(chunks))\n",
        "print(chunks[0].law_name, chunks[0].article_num, chunks[0].article_sub, chunks[0].article_title)\n",
        "print('head:', chunks[0].content[:180])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b8d9308",
      "metadata": {},
      "outputs": [],
      "source": [
        "chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d396f948",
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import asdict\n",
        "\n",
        "\n",
        "def chunk_to_dict(chunk: ArticleChunk) -> dict:\n",
        "    return asdict(chunk)\n",
        "\n",
        "\n",
        "def sanitize_filename(name: str) -> str:\n",
        "    keep = []\n",
        "    for ch in name:\n",
        "        if ch.isalnum() or ch in ['_', '-', ' ', '.']:\n",
        "            keep.append(ch)\n",
        "        else:\n",
        "            keep.append('_')\n",
        "    return ''.join(keep).strip().replace(' ', '_')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66912169",
      "metadata": {},
      "outputs": [],
      "source": [
        "# chunks를 JSON으로 저장해서 구성 검증\n",
        "out_dir = Path('data/processed/chunks')\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "chunk_dicts = [chunk_to_dict(c) for c in chunks]\n",
        "\n",
        "if chunks:\n",
        "    law_id = chunks[0].law_id\n",
        "    law_name = chunks[0].law_name.replace(' ', '_')\n",
        "    filename = f'{law_id}_{sanitize_filename(law_name)}_chunks.json'\n",
        "else:\n",
        "    filename = 'chunks.json'\n",
        "\n",
        "out_path = out_dir / filename\n",
        "out_path.write_text(json.dumps(chunk_dicts, ensure_ascii=False, indent=2), encoding='utf-8')\n",
        "print('saved:', out_path)\n",
        "print('saved chunk count:', len(chunk_dicts))\n",
        "\n",
        "# 빠른 점검용 샘플\n",
        "chunk_dicts[0] if chunk_dicts else {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec685958",
      "metadata": {},
      "outputs": [],
      "source": [
        "chunk_dicts[4] if chunk_dicts else {}"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "natna",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}